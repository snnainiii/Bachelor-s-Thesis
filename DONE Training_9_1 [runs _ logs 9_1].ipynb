{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5148,"status":"ok","timestamp":1732854905260,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"yAkDTa9f6upj","outputId":"bfa7a5d6-a033-4bf7-de21-afae3f66af18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"lo13H_4ktcUj"},"source":["# **MODEL**"]},{"cell_type":"markdown","metadata":{"id":"oCCWsob1G6pD"},"source":["## **UTILS**"]},{"cell_type":"markdown","metadata":{"id":"IBw080uuHOeE"},"source":["### **UTILS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WA1YmeHVHQXn"},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","\n","\n","def cvtColor(image):\n","    if len(np.shape(image)) == 3 and np.shape(image)[2] == 3:\n","        return image\n","    else:\n","        image = image.convert('RGB')\n","        return image\n","\n","\n","def resize_image(image, size, letterbox_image):\n","    iw, ih  = image.size\n","    w, h    = size\n","    if letterbox_image:\n","        scale   = min(w/iw, h/ih)\n","        nw      = int(iw*scale)\n","        nh      = int(ih*scale)\n","\n","        image   = image.resize((nw,nh), Image.BICUBIC)\n","        new_image = Image.new('RGB', size, (128,128,128))\n","        new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n","    else:\n","        new_image = image.resize((w, h), Image.BICUBIC)\n","    return new_image\n","\n","def get_classes(classes_path):\n","    with open(classes_path, encoding='utf-8') as f:\n","        class_names = f.readlines()\n","    class_names = [c.strip() for c in class_names]\n","    return class_names, len(class_names)\n","\n","def preprocess_input(image):\n","    image /= 255.0\n","    image -= np.array([0.485, 0.456, 0.406])\n","    image /= np.array([0.229, 0.224, 0.225])\n","    return image\n","\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def show_config(**kwargs):\n","    print('Configurations:')\n","    print('-' * 70)\n","    print('|%25s | %40s|' % ('keys', 'values'))\n","    print('-' * 70)\n","    for key, value in kwargs.items():\n","        print('|%25s | %40s|' % (str(key), str(value)))\n","    print('-' * 70)"]},{"cell_type":"markdown","metadata":{"id":"svk-erXxHWAS"},"source":["### **UTILS_BBOX**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pWLXeNGHYpf"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torchvision.ops import nms, boxes\n","\n","def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape, letterbox_image):\n","\n","    box_yx = box_xy[..., ::-1]\n","    box_hw = box_wh[..., ::-1]\n","    input_shape = np.array(input_shape)\n","    image_shape = np.array(image_shape)\n","\n","    if letterbox_image:\n","\n","        new_shape = np.round(image_shape * np.min(input_shape/image_shape))\n","        offset  = (input_shape - new_shape)/2./input_shape\n","        scale   = input_shape/new_shape\n","\n","        box_yx  = (box_yx - offset) * scale\n","        box_hw *= scale\n","\n","    box_mins    = box_yx - (box_hw / 2.)\n","    box_maxes   = box_yx + (box_hw / 2.)\n","    boxes  = np.concatenate([box_mins[..., 0:1], box_mins[..., 1:2], box_maxes[..., 0:1], box_maxes[..., 1:2]], axis=-1)\n","    boxes *= np.concatenate([image_shape, image_shape], axis=-1)\n","    return boxes\n","\n","def decode_outputs(outputs, input_shape):\n","    grids   = []\n","    strides = []\n","    hw      = [x.shape[-2:] for x in outputs]\n","\n","    outputs = torch.cat([x.flatten(start_dim=2) for x in outputs], dim=2).permute(0, 2, 1)\n","\n","    outputs[:, :, 4:] = torch.sigmoid(outputs[:, :, 4:])\n","    for h, w in hw:\n","\n","        grid_y, grid_x  = torch.meshgrid([torch.arange(h), torch.arange(w)])\n","\n","        grid            = torch.stack((grid_x, grid_y), 2).view(1, -1, 2)\n","        shape           = grid.shape[:2]\n","\n","        grids.append(grid)\n","        strides.append(torch.full((shape[0], shape[1], 1), input_shape[0] / h))\n","\n","    grids               = torch.cat(grids, dim=1).type(outputs.type())\n","    strides             = torch.cat(strides, dim=1).type(outputs.type())\n","\n","    outputs[..., :2]    = (outputs[..., :2] + grids) * strides\n","    outputs[..., 2:4]   = torch.exp(outputs[..., 2:4]) * strides\n","\n","    outputs[..., [0,2]] = outputs[..., [0,2]] / input_shape[1]\n","    outputs[..., [1,3]] = outputs[..., [1,3]] / input_shape[0]\n","    return outputs\n","\n","\n","def non_max_suppression(prediction, num_classes, input_shape, image_shape, letterbox_image, conf_thres=0.5, nms_thres=0.4):\n","\n","    box_corner          = prediction.new(prediction.shape)\n","    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n","    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n","    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n","    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n","    prediction[:, :, :4] = box_corner[:, :, :4]\n","\n","    output = [None for _ in range(len(prediction))]\n","\n","    for i, image_pred in enumerate(prediction):\n","\n","        class_conf, class_pred = torch.max(image_pred[:, 5:5 + num_classes], 1, keepdim=True)\n","\n","        conf_mask = (image_pred[:, 4] * class_conf[:, 0] >= conf_thres).squeeze()\n","\n","        if not image_pred.size(0):\n","            continue\n","\n","        detections = torch.cat((image_pred[:, :5], class_conf, class_pred.float()), 1)\n","        detections = detections[conf_mask]\n","\n","        nms_out_index = boxes.batched_nms(\n","            detections[:, :4],\n","            detections[:, 4] * detections[:, 5],\n","            detections[:, 6],\n","            nms_thres,\n","        )\n","\n","        output[i]   = detections[nms_out_index]\n","\n","\n","        if output[i] is not None:\n","            output[i]           = output[i].cpu().numpy()\n","            box_xy, box_wh      = (output[i][:, 0:2] + output[i][:, 2:4])/2, output[i][:, 2:4] - output[i][:, 0:2]\n","            output[i][:, :4]    = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape, letterbox_image)\n","    return output\n"]},{"cell_type":"markdown","metadata":{"id":"mCrxAMh8Hb3_"},"source":["###**UTILS_MAP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"htwIUMw6HfkA"},"outputs":[],"source":["import glob\n","import json\n","import math\n","import operator\n","import os\n","import shutil\n","import sys\n","from google.colab.patches import cv2_imshow\n","\n","try:\n","    from pycocotools.coco import COCO\n","    from pycocotools.cocoeval import COCOeval\n","except:\n","    pass\n","import cv2\n","import matplotlib\n","\n","matplotlib.use('Agg')\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","'''\n","    0,0 ------> x (width)\n","     |\n","     |  (Left,Top)\n","     |      *_________\n","     |      |         |\n","            |         |\n","     y      |_________|\n","  (height)            *\n","                (Right,Bottom)\n","'''\n","\n","\n","def log_average_miss_rate(precision, fp_cumsum, num_images):\n","    \"\"\"\n","        log-average miss rate:\n","            Calculated by averaging miss rates at 9 evenly spaced FPPI points\n","            between 10e-2 and 10e0, in log-space.\n","\n","        output:\n","                lamr | log-average miss rate\n","                mr | miss rate\n","                fppi | false positives per image\n","\n","        references:\n","            [1] Dollar, Piotr, et al. \"Pedestrian Detection: An Evaluation of the\n","               State of the Art.\" Pattern Analysis and Machine Intelligence, IEEE\n","               Transactions on 34.4 (2012): 743 - 761.\n","    \"\"\"\n","\n","    if precision.size == 0:\n","        lamr = 0\n","        mr = 1\n","        fppi = 0\n","        return lamr, mr, fppi\n","\n","    fppi = fp_cumsum / float(num_images)\n","    mr = (1 - precision)\n","\n","    fppi_tmp = np.insert(fppi, 0, -1.0)\n","    mr_tmp = np.insert(mr, 0, 1.0)\n","\n","    ref = np.logspace(-2.0, 0.0, num=9)\n","    for i, ref_i in enumerate(ref):\n","        j = np.where(fppi_tmp <= ref_i)[-1][-1]\n","        ref[i] = mr_tmp[j]\n","\n","    lamr = math.exp(np.mean(np.log(np.maximum(1e-10, ref))))\n","\n","    return lamr, mr, fppi\n","\n","\n","\"\"\"\n"," throw error and exit\n","\"\"\"\n","\n","\n","def error(msg):\n","    print(msg)\n","    sys.exit(0)\n","\n","\n","\"\"\"\n"," check if the number is a float between 0.0 and 1.0\n","\"\"\"\n","\n","\n","# def is_float_between_0_and_1(value):\n","#     try:\n","#         val = float(value)\n","#         if val > 0.0 and val < 1.0:\n","#             return True\n","#         else:\n","#             return False\n","#     except ValueError:\n","#         return False\n","\n","\n","\"\"\"\n"," Calculate the AP given the recall and precision array\n","    1st) We compute a version of the measured precision/recall curve with\n","         precision monotonically decreasing\n","    2nd) We compute the AP as the area under this curve by numerical integration.\n","\"\"\"\n","\n","\n","def voc_ap(rec, prec):\n","    \"\"\"\n","    --- Official matlab code VOC2012---\n","    mrec=[0 ; rec ; 1];\n","    mpre=[0 ; prec ; 0];\n","    for i=numel(mpre)-1:-1:1\n","            mpre(i)=max(mpre(i),mpre(i+1));\n","    end\n","    i=find(mrec(2:end)~=mrec(1:end-1))+1;\n","    ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n","    \"\"\"\n","    rec.insert(0, 0.0)  # insert 0.0 at begining of list\n","    rec.append(1.0)  # insert 1.0 at end of list\n","    mrec = rec[:]\n","    prec.insert(0, 0.0)  # insert 0.0 at begining of list\n","    prec.append(0.0)  # insert 0.0 at end of list\n","    mpre = prec[:]\n","    \"\"\"\n","     This part makes the precision monotonically decreasing\n","        (goes from the end to the beginning)\n","        matlab: for i=numel(mpre)-1:-1:1\n","                    mpre(i)=max(mpre(i),mpre(i+1));\n","    \"\"\"\n","    for i in range(len(mpre) - 2, -1, -1):\n","        mpre[i] = max(mpre[i], mpre[i + 1])\n","    \"\"\"\n","     This part creates a list of indexes where the recall changes\n","        matlab: i=find(mrec(2:end)~=mrec(1:end-1))+1;\n","    \"\"\"\n","    i_list = []\n","    for i in range(1, len(mrec)):\n","        if mrec[i] != mrec[i - 1]:\n","            i_list.append(i)  # if it was matlab would be i + 1\n","    \"\"\"\n","     The Average Precision (AP) is the area under the curve\n","        (numerical integration)\n","        matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n","    \"\"\"\n","    ap = 0.0\n","    for i in i_list:\n","        ap += ((mrec[i] - mrec[i - 1]) * mpre[i])\n","    return ap, mrec, mpre\n","\n","\n","\"\"\"\n"," Convert the lines of a file to a list\n","\"\"\"\n","\n","\n","def file_lines_to_list(path):\n","    # open txt file lines to a list\n","    with open(path) as f:\n","        content = f.readlines()\n","    # remove whitespace characters like `\\n` at the end of each line\n","    content = [x.strip() for x in content]\n","    return content\n","\n","\n","\"\"\"\n"," Draws text in image\n","\"\"\"\n","\n","\n","def draw_text_in_image(img, text, pos, color, line_width):\n","    font = cv2.FONT_HERSHEY_PLAIN\n","    fontScale = 1\n","    lineType = 1\n","    bottomLeftCornerOfText = pos\n","    cv2.putText(img, text,\n","                bottomLeftCornerOfText,\n","                font,\n","                fontScale,\n","                color,\n","                lineType)\n","    text_width, _ = cv2.getTextSize(text, font, fontScale, lineType)[0]\n","    return img, (line_width + text_width)\n","\n","\n","\"\"\"\n"," Plot - adjust axes\n","\"\"\"\n","\n","\n","def adjust_axes(r, t, fig, axes):\n","    # get text width for re-scaling\n","    bb = t.get_window_extent(renderer=r)\n","    text_width_inches = bb.width / fig.dpi\n","    # get axis width in inches\n","    current_fig_width = fig.get_figwidth()\n","    new_fig_width = current_fig_width + text_width_inches\n","    propotion = new_fig_width / current_fig_width\n","    # get axis limit\n","    x_lim = axes.get_xlim()\n","    axes.set_xlim([x_lim[0], x_lim[1] * propotion])\n","\n","\n","\"\"\"\n"," Draw plot using Matplotlib\n","\"\"\"\n","\n","\n","def draw_plot_func(dictionary, n_classes, window_title, plot_title, x_label, output_path, to_show, plot_color,\n","                   true_p_bar):\n","    # sort the dictionary by decreasing value, into a list of tuples\n","\n","    plt.rc('font', family='DejaVu Sans', size=15)\n","    sorted_dic_by_value = sorted(dictionary.items(), key=operator.itemgetter(1))\n","    # unpacking the list of tuples into two lists\n","    sorted_keys, sorted_values = zip(*sorted_dic_by_value)\n","    #\n","    if true_p_bar != \"\":\n","        \"\"\"\n","         Special case to draw in:\n","            - green -> TP: True Positives (object detected and matches ground-truth)\n","            - red -> FP: False Positives (object detected but does not match ground-truth)\n","            - orange -> FN: False Negatives (object not detected but present in the ground-truth)\n","        \"\"\"\n","        fp_sorted = []\n","        tp_sorted = []\n","        for key in sorted_keys:\n","            fp_sorted.append(dictionary[key] - true_p_bar[key])\n","            tp_sorted.append(true_p_bar[key])\n","        plt.barh(range(n_classes), fp_sorted, align='center', color='crimson', label='False Positive')\n","        plt.barh(range(n_classes), tp_sorted, align='center', color='forestgreen', label='True Positive',\n","                 left=fp_sorted)\n","        # add legend\n","        plt.legend(loc='lower right')\n","        \"\"\"\n","         Write number on side of bar\n","        \"\"\"\n","        fig = plt.gcf()  # gcf - get current figure\n","        axes = plt.gca()\n","        r = fig.canvas.get_renderer()\n","        for i, val in enumerate(sorted_values):\n","            fp_val = fp_sorted[i]\n","            tp_val = tp_sorted[i]\n","            fp_str_val = \" \" + str(fp_val)\n","            tp_str_val = fp_str_val + \" \" + str(tp_val)\n","            # trick to paint multicolor with offset:\n","            # first paint everything and then repaint the first number\n","            t = plt.text(val, i, tp_str_val, color='forestgreen', va='center', fontweight='bold')\n","            plt.text(val, i, fp_str_val, color='crimson', va='center', fontweight='bold')\n","            if i == (len(sorted_values) - 1):  # largest bar\n","                adjust_axes(r, t, fig, axes)\n","    else:\n","        plt.barh(range(n_classes), sorted_values, color=plot_color)\n","        \"\"\"\n","         Write number on side of bar\n","        \"\"\"\n","        fig = plt.gcf()  # gcf - get current figure\n","        axes = plt.gca()\n","        axes.set_xlim([0.0, 1.02])\n","        r = fig.canvas.get_renderer()\n","        for i, val in enumerate(sorted_values):\n","            str_val = \" \" + str(val)  # add a space before\n","            if val < 1.0:\n","                str_val = \" {0:.3f}\".format(val)\n","            t = plt.text(val, i, str_val, color=\"black\", va='center')\n","            # re-set axes to show number inside the figure\n","            if i == (len(sorted_values) - 1):  # largest bar\n","                adjust_axes(r, t, fig, axes)\n","    # set window title\n","    fig.suptitle(window_title)\n","    # fig.canvas.set_window_title(window_title)\n","    # write classes in y axis\n","    tick_font_size = 12\n","    plt.yticks(range(n_classes), sorted_keys, fontsize=tick_font_size)\n","    \"\"\"\n","     Re-scale height accordingly\n","    \"\"\"\n","    init_height = fig.get_figheight()\n","    # comput the matrix height in points and inches\n","    dpi = fig.dpi\n","    height_pt = n_classes * (tick_font_size * 1.4)  # 1.4 (some spacing)\n","    height_in = height_pt / dpi\n","    # compute the required figure height\n","    top_margin = 0.15  # in percentage of the figure height\n","    bottom_margin = 0.05  # in percentage of the figure height\n","    figure_height = height_in / (1 - top_margin - bottom_margin)\n","    # set new height\n","    if figure_height > init_height:\n","        fig.set_figheight(figure_height)\n","\n","    # set plot title\n","    plt.title(plot_title, fontsize=14)\n","    # set axis titles\n","    # plt.xlabel('classes')\n","    plt.xlabel(x_label)\n","    # adjust size of window\n","    fig.tight_layout()\n","    # save the plot\n","    fig.savefig(output_path)\n","    # show image\n","    if to_show:\n","        plt.show()\n","    # close the plot\n","    plt.close()\n","\n","def get_map(MINOVERLAP, draw_plot, score_threhold=0.5, path='./map_out'):\n","    GT_PATH = os.path.join(path, 'ground-truth')\n","    CSV_PATH = os.path.join(path, str(MINOVERLAP))\n","    DR_PATH = os.path.join(path, 'detection-results')\n","    IMG_PATH = os.path.join(path, 'images-optional')\n","    TEMP_FILES_PATH = os.path.join(path, '.temp_files')\n","    RESULTS_FILES_PATH = os.path.join(path, 'results_%0.1f' % MINOVERLAP)\n","    df_dic = {}\n","    show_animation = True\n","    if os.path.exists(IMG_PATH):\n","        for dirpath, dirnames, files in os.walk(IMG_PATH):\n","            if not files:\n","                show_animation = False\n","    else:\n","        show_animation = False\n","\n","    if not os.path.exists(TEMP_FILES_PATH):\n","        os.makedirs(TEMP_FILES_PATH)\n","\n","    if not os.path.exists(CSV_PATH):\n","        os.makedirs(CSV_PATH)\n","    if os.path.exists(RESULTS_FILES_PATH):\n","        shutil.rmtree(RESULTS_FILES_PATH)\n","    else:\n","        os.makedirs(RESULTS_FILES_PATH)\n","    if draw_plot:\n","        try:\n","            matplotlib.use('TkAgg')\n","        except:\n","            pass\n","        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"AP\"))\n","        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"F1\"))\n","        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"Recall\"))\n","        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"Precision\"))\n","    if show_animation:\n","        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"images\", \"detections_one_by_one\"))\n","\n","    ground_truth_files_list = glob.glob(GT_PATH + '/*.txt')\n","    if len(ground_truth_files_list) == 0:\n","        error(\"Error: No ground-truth files found!\")\n","    ground_truth_files_list.sort()\n","    gt_counter_per_class = {}\n","    counter_images_per_class = {}\n","\n","    for txt_file in ground_truth_files_list:\n","        file_id = txt_file.split(\".txt\", 1)[0]\n","        file_id = os.path.basename(os.path.normpath(file_id))\n","        temp_path = os.path.join(DR_PATH, (file_id + \".txt\"))\n","        if not os.path.exists(temp_path):\n","            error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n","            error(error_msg)\n","        lines_list = file_lines_to_list(txt_file)\n","        bounding_boxes = []\n","        is_difficult = False\n","        already_seen_classes = []\n","        for line in lines_list:\n","            try:\n","                if \"difficult\" in line:\n","                    class_name, left, top, right, bottom, _difficult = line.split()\n","                    is_difficult = True\n","                else:\n","                    class_name, left, top, right, bottom = line.split()\n","            except:\n","                if \"difficult\" in line:\n","                    line_split = line.split()\n","                    _difficult = line_split[-1]\n","                    bottom = line_split[-2]\n","                    right = line_split[-3]\n","                    top = line_split[-4]\n","                    left = line_split[-5]\n","                    class_name = \"\"\n","                    for name in line_split[:-5]:\n","                        class_name += name + \" \"\n","                    class_name = class_name[:-1]\n","                    is_difficult = True\n","                else:\n","                    line_split = line.split()\n","                    bottom = line_split[-1]\n","                    right = line_split[-2]\n","                    top = line_split[-3]\n","                    left = line_split[-4]\n","                    class_name = \"\"\n","                    for name in line_split[:-4]:\n","                        class_name += name + \" \"\n","                    class_name = class_name[:-1]\n","\n","            bbox = left + \" \" + top + \" \" + right + \" \" + bottom\n","            if is_difficult:\n","                bounding_boxes.append({\"class_name\": class_name, \"bbox\": bbox, \"used\": False, \"difficult\": True})\n","                is_difficult = False\n","            else:\n","                bounding_boxes.append({\"class_name\": class_name, \"bbox\": bbox, \"used\": False})\n","                if class_name in gt_counter_per_class:\n","                    gt_counter_per_class[class_name] += 1\n","                else:\n","                    gt_counter_per_class[class_name] = 1\n","\n","                if class_name not in already_seen_classes:\n","                    if class_name in counter_images_per_class:\n","                        counter_images_per_class[class_name] += 1\n","                    else:\n","                        counter_images_per_class[class_name] = 1\n","                    already_seen_classes.append(class_name)\n","\n","        with open(TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\", 'w') as outfile:\n","            json.dump(bounding_boxes, outfile)\n","\n","    gt_classes = list(gt_counter_per_class.keys())\n","    gt_classes = sorted(gt_classes)\n","    n_classes = len(gt_classes)\n","\n","    dr_files_list = glob.glob(DR_PATH + '/*.txt')\n","    dr_files_list.sort()\n","    for class_index, class_name in enumerate(gt_classes):\n","        bounding_boxes = []\n","        for txt_file in dr_files_list:\n","            file_id = txt_file.split(\".txt\", 1)[0]\n","            file_id = os.path.basename(os.path.normpath(file_id))\n","            temp_path = os.path.join(GT_PATH, (file_id + \".txt\"))\n","            if class_index == 0:\n","                if not os.path.exists(temp_path):\n","                    error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n","                    error(error_msg)\n","            lines = file_lines_to_list(txt_file)\n","            for line in lines:\n","                try:\n","                    tmp_class_name, confidence, left, top, right, bottom = line.split()\n","                except:\n","                    line_split = line.split()\n","                    bottom = line_split[-1]\n","                    right = line_split[-2]\n","                    top = line_split[-3]\n","                    left = line_split[-4]\n","                    confidence = line_split[-5]\n","                    tmp_class_name = \"\"\n","                    for name in line_split[:-5]:\n","                        tmp_class_name += name + \" \"\n","                    tmp_class_name = tmp_class_name[:-1]\n","\n","                if tmp_class_name == class_name:\n","                    bbox = left + \" \" + top + \" \" + right + \" \" + bottom\n","                    bounding_boxes.append({\"confidence\": confidence, \"file_id\": file_id, \"bbox\": bbox})\n","\n","        bounding_boxes.sort(key=lambda x: float(x['confidence']), reverse=True)\n","        with open(TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\", 'w') as outfile:\n","            json.dump(bounding_boxes, outfile)\n","\n","    sum_AP = 0.0\n","    ap_dictionary = {}\n","    lamr_dictionary = {}\n","    with open(RESULTS_FILES_PATH + \"/results.txt\", 'w') as results_file:\n","        results_file.write(\"# AP and precision/recall per class\\n\")\n","        count_true_positives = {}\n","\n","        for class_index, class_name in enumerate(gt_classes):\n","            count_true_positives[class_name] = 0\n","            dr_file = TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\"\n","            dr_data = json.load(open(dr_file))\n","\n","            nd = len(dr_data)\n","            tp = [0] * nd\n","            fp = [0] * nd\n","            score = [0] * nd\n","            score_threhold_idx = 0\n","            for idx, detection in enumerate(dr_data):\n","                file_id = detection[\"file_id\"]\n","                score[idx] = float(detection[\"confidence\"])\n","                if score[idx] >= score_threhold:\n","                    score_threhold_idx = idx\n","\n","                # Memuat gambar untuk setiap deteksi\n","                ground_truth_img = glob.glob1(IMG_PATH, file_id + \".*\")\n","                if len(ground_truth_img) == 0:\n","                    error(\"Error. Image not found with id: \" + file_id)\n","                else:\n","                    img = cv2.imread(IMG_PATH + \"/\" + ground_truth_img[0])\n","\n","                    # Inisialisasi img_cumulative\n","                    img_cumulative_path = os.path.join(RESULTS_FILES_PATH, \"images\", ground_truth_img[0])\n","                    if os.path.isfile(img_cumulative_path):\n","                        img_cumulative = cv2.imread(img_cumulative_path)\n","                    else:\n","                        img_cumulative = img.copy()\n","\n","                    # Menambahkan border di bagian bawah gambar\n","                    bottom_border = 60\n","                    BLACK = [0, 0, 0]\n","                    img = cv2.copyMakeBorder(img, 0, bottom_border, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n","\n","                    # Gambar kotak pembatas dan teks\n","                    bb = [float(x) for x in detection[\"bbox\"].split()]\n","                    bb = [int(i) for i in bb]\n","                    cv2.rectangle(img, (bb[0], bb[1]), (bb[2], bb[3]), (0, 255, 0), 2)\n","                    cv2.rectangle(img_cumulative, (bb[0], bb[1]), (bb[2], bb[3]), (0, 255, 0), 2)\n","\n","                    # Menambahkan teks kelas dan confidence score\n","                    confidence_score = float(detection[\"confidence\"]) * 100\n","                    text = f\"{class_name} {confidence_score:.2f}%\"\n","                    cv2.putText(img, text, (bb[0], bb[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1, cv2.LINE_AA)\n","                    cv2.putText(img_cumulative, text, (bb[0], bb[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1, cv2.LINE_AA)\n","\n","                    # Simpan atau tampilkan gambar\n","                    output_img_path = os.path.join(RESULTS_FILES_PATH, \"images\", f\"{file_id}_detection.jpg\")\n","                    cv2.imwrite(output_img_path, img)\n","                    cv2_imshow(img)  # Ganti cv2.imshow dengan cv2_imshow\n","\n","                gt_file = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n","                ground_truth_data = json.load(open(gt_file))\n","                ovmax = -1\n","                gt_match = -1\n","                bb = [float(x) for x in detection[\"bbox\"].split()]\n","                for obj in ground_truth_data:\n","                    if obj[\"class_name\"] == class_name:\n","                        bbgt = [float(x) for x in obj[\"bbox\"].split()]\n","                        bi = [max(bb[0], bbgt[0]), max(bb[1], bbgt[1]), min(bb[2], bbgt[2]), min(bb[3], bbgt[3])]\n","                        iw = bi[2] - bi[0] + 1\n","                        ih = bi[3] - bi[1] + 1\n","                        if iw > 0 and ih > 0:\n","                            ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n","                                                                              + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n","                            ov = iw * ih / ua\n","                            if ov > ovmax:\n","                                ovmax = ov\n","                                gt_match = obj\n","\n","                if show_animation:\n","                    status = \"NO MATCH FOUND!\"\n","\n","                min_overlap = MINOVERLAP\n","                if ovmax >= min_overlap:\n","                    if \"difficult\" not in gt_match:\n","                        if not bool(gt_match[\"used\"]):\n","                            tp[idx] = 1\n","                            gt_match[\"used\"] = True\n","                            count_true_positives[class_name] += 1\n","                            with open(gt_file, 'w') as f:\n","                                f.write(json.dumps(ground_truth_data))\n","                            if show_animation:\n","                                status = \"MATCH!\"\n","                        else:\n","                            fp[idx] = 1\n","                            if show_animation:\n","                                status = \"REPEATED MATCH!\"\n","                else:\n","                    fp[idx] = 1\n","                    if ovmax > 0:\n","                        status = \"INSUFFICIENT OVERLAP\"\n","\n","                \"\"\"\n","                Draw image to show animation\n","                \"\"\"\n","                if show_animation:\n","                    height, widht = img.shape[:2]\n","                    white = (255, 255, 255)\n","                    light_blue = (255, 200, 100)\n","                    green = (0, 255, 0)\n","                    light_red = (30, 30, 255)\n","                    margin = 10\n","                    # 1nd line\n","                    v_pos = int(height - margin - (bottom_border / 2.0))\n","                    text = \"Image: \" + ground_truth_img[0] + \" \"\n","                    img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n","                    text = \"Class [\" + str(class_index) + \"/\" + str(n_classes) + \"]: \" + class_name + \" \"\n","                    img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), light_blue,\n","                                                         line_width)\n","                    if ovmax != -1:\n","                        color = light_red\n","                        if status == \"INSUFFICIENT OVERLAP\":\n","                            text = \"IoU: {0:.2f}% \".format(ovmax * 100) + \"< {0:.2f}% \".format(min_overlap * 100)\n","                        else:\n","                            text = \"IoU: {0:.2f}% \".format(ovmax * 100) + \">= {0:.2f}% \".format(min_overlap * 100)\n","                            color = green\n","                        img, _ = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n","                    # 2nd line\n","                    v_pos += int(bottom_border / 2.0)\n","                    rank_pos = str(idx + 1)\n","                    text = \"Detection #rank: \" + rank_pos + \" confidence: {0:.2f}% \".format(\n","                        float(detection[\"confidence\"]) * 100)\n","                    img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n","                    color = light_red\n","                    if status == \"MATCH!\":\n","                        color = green\n","                    text = \"Result: \" + status + \" \"\n","                    img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n","\n","                    font = cv2.FONT_HERSHEY_SIMPLEX\n","                    if ovmax > 0:\n","                        bbgt = [int(round(float(x))) for x in gt_match[\"bbox\"].split()]\n","                        cv2.rectangle(img, (bbgt[0], bbgt[1]), (bbgt[2], bbgt[3]), light_blue, 2)\n","                        cv2.rectangle(img_cumulative, (bbgt[0], bbgt[1]), (bbgt[2], bbgt[3]), light_blue, 2)\n","                        cv2.putText(img_cumulative, class_name, (bbgt[0], bbgt[1] - 5), font, 0.6, light_blue, 1,\n","                                    cv2.LINE_AA)\n","\n","                    # Menggambar bounding box\n","                    bb = [int(i) for i in bb]\n","                    cv2.rectangle(img, (bb[0], bb[1]), (bb[2], bb[3]), color, 2)\n","                    cv2.rectangle(img_cumulative, (bb[0], bb[1]), (bb[2], bb[3]), color, 2)\n","\n","                    # Menambahkan teks kelas dan confidence score\n","                    confidence_score = float(detection[\"confidence\"]) * 100  # Mengonversi ke persentase\n","                    text = f\"{class_name} {confidence_score:.2f}%\"\n","                    cv2.putText(img_cumulative, text, (bb[0], bb[1] - 5), font, 0.6, color, 1, cv2.LINE_AA)\n","                    # cv2_imshow(img)\n","                    # cv2.waitKey(1)\n","                    output_img_path = RESULTS_FILES_PATH + \"/images/detections_one_by_one/\" + class_name + \"_detection\" + str(\n","                        idx) + \".jpg\"\n","                    cv2.imwrite(output_img_path, img)\n","                    cv2.imwrite(img_cumulative_path, img_cumulative)\n","\n","            cumsum = 0\n","            for idx, val in enumerate(fp):\n","                fp[idx] += cumsum\n","                cumsum += val\n","\n","            cumsum = 0\n","            for idx, val in enumerate(tp):\n","                tp[idx] += cumsum\n","                cumsum += val\n","\n","            rec = tp[:]\n","            for idx, val in enumerate(tp):\n","                rec[idx] = float(tp[idx]) / np.maximum(gt_counter_per_class[class_name], 1)\n","\n","            prec = tp[:]\n","            for idx, val in enumerate(tp):\n","                prec[idx] = float(tp[idx]) / np.maximum((fp[idx] + tp[idx]), 1)\n","\n","            ap, mrec, mprec = voc_ap(rec[:], prec[:])\n","            F1 = np.array(rec) * np.array(prec) * 2 / np.where((np.array(prec) + np.array(rec)) == 0, 1,\n","                                                               (np.array(prec) + np.array(rec)))\n","\n","            sum_AP += ap\n","            text = \"{0:.2f}%\".format(\n","                ap * 100) + \" = \" + class_name + \" AP \"  # class_name + \" AP = {0:.2f}%\".format(ap*100)\n","\n","            if len(prec) > 0:\n","                F1_text = \"{0:.2f}\".format(F1[score_threhold_idx]) + \" = \" + class_name + \" F1 \"\n","                Recall_text = \"{0:.2f}%\".format(rec[score_threhold_idx] * 100) + \" = \" + class_name + \" Recall \"\n","                Precision_text = \"{0:.2f}%\".format(prec[score_threhold_idx] * 100) + \" = \" + class_name + \" Precision \"\n","            else:\n","                F1_text = \"0.00\" + \" = \" + class_name + \" F1 \"\n","                Recall_text = \"0.00%\" + \" = \" + class_name + \" Recall \"\n","                Precision_text = \"0.00%\" + \" = \" + class_name + \" Precision \"\n","\n","            rounded_prec = ['%.2f' % elem for elem in prec]\n","            rounded_rec = ['%.2f' % elem for elem in rec]\n","            results_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall :\" + str(rounded_rec) + \"\\n\\n\")\n","\n","            if len(prec) > 0:\n","                print(text + \"\\t||\\tscore_threhold=\" + str(score_threhold) + \" : \" + \"F1=\" + \"{0:.2f}\".format(\n","                    F1[score_threhold_idx]) \\\n","                      + \" ; Recall=\" + \"{0:.2f}%\".format(\n","                    rec[score_threhold_idx] * 100) + \" ; Precision=\" + \"{0:.2f}%\".format(\n","                    prec[score_threhold_idx] * 100))\n","            else:\n","                print(text + \"\\t||\\tscore_threhold=\" + str(\n","                    score_threhold) + \" : \" + \"F1=0.00% ; Recall=0.00% ; Precision=0.00%\")\n","            ap_dictionary[class_name] = ap\n","\n","            n_images = counter_images_per_class[class_name]\n","            lamr, mr, fppi = log_average_miss_rate(np.array(rec), np.array(fp), n_images)\n","            lamr_dictionary[class_name] = lamr\n","\n","            if draw_plot:\n","                plt.plot(rec, prec, '-o')\n","                area_under_curve_x = mrec[:-1] + [mrec[-2]] + [mrec[-1]]\n","                area_under_curve_y = mprec[:-1] + [0.0] + [mprec[-1]]\n","                plt.fill_between(area_under_curve_x, 0, area_under_curve_y, alpha=0.2, edgecolor='r')\n","\n","                fig = plt.gcf()\n","                plt.suptitle('AP ' + class_name)\n","\n","                plt.title('class: ' + text)\n","                plt.xlabel('Recall')\n","                plt.ylabel('Precision')\n","                axes = plt.gca()\n","                axes.set_xlim([0.0, 1.0])\n","                axes.set_ylim([0.0, 1.05])\n","                fig.savefig(RESULTS_FILES_PATH + \"/AP/\" + class_name + \".png\")\n","                plt.cla()\n","\n","                plt.plot(score, F1, \"-\", color='orangered')\n","                plt.title('class: ' + F1_text + \"\\nscore_threhold=\" + str(score_threhold))\n","                plt.xlabel('Score_Threhold')\n","                plt.ylabel('F1')\n","                axes = plt.gca()\n","                axes.set_xlim([0.0, 1.0])\n","                axes.set_ylim([0.0, 1.05])\n","                fig.savefig(RESULTS_FILES_PATH + \"/F1/\" + class_name + \".png\")\n","                plt.cla()\n","\n","                plt.plot(score, rec, \"-H\", color='gold')\n","                plt.title('class: ' + Recall_text + \"\\nscore_threhold=\" + str(score_threhold))\n","                plt.xlabel('Score_Threhold')\n","                plt.ylabel('Recall')\n","                axes = plt.gca()\n","                axes.set_xlim([0.0, 1.0])\n","                axes.set_ylim([0.0, 1.05])\n","                fig.savefig(RESULTS_FILES_PATH + \"/Recall/\" + class_name + \".png\")\n","                plt.cla()\n","\n","                plt.plot(score, prec, \"-s\", color='palevioletred')\n","                plt.title('class: ' + Precision_text + \"\\nscore_threhold=\" + str(score_threhold))\n","                plt.xlabel('Score_Threhold')\n","                plt.ylabel('Precision')\n","                axes = plt.gca()\n","                axes.set_xlim([0.0, 1.0])\n","                axes.set_ylim([0.0, 1.05])\n","                fig.savefig(RESULTS_FILES_PATH + \"/Precision/\" + class_name + \".png\")\n","                plt.cla()\n","\n","                df = pd.DataFrame()\n","                df[\"Confidence\"] = score\n","                df[\"Recall\"] = rec\n","                df[\"Precision\"] = prec\n","                df[\"F1\"] = F1\n","                df_dic[class_name] = df\n","                df.to_csv(os.path.join(CSV_PATH, class_name + \".csv\"), encoding=\"utf-8\", index=False,\n","                          sep=\",\")\n","\n","        if show_animation:\n","            cv2.destroyAllWindows()\n","        if n_classes == 0:\n","            print(\"未检测到任何种类，请检查标签信息与get_map.py中的classes_path是否修改。\")\n","            return 0\n","        results_file.write(\"\\n# mAP of all classes\\n\")\n","        mAP = sum_AP / n_classes\n","        text = \"mAP = {0:.2f}%\".format(mAP * 100)\n","        results_file.write(text + \"\\n\")\n","        print(text)\n","\n","    shutil.rmtree(TEMP_FILES_PATH)\n","\n","    \"\"\"\n","    Count total of detection-results\n","    \"\"\"\n","    det_counter_per_class = {}\n","    for txt_file in dr_files_list:\n","        lines_list = file_lines_to_list(txt_file)\n","        for line in lines_list:\n","            class_name = line.split()[0]\n","            if class_name in det_counter_per_class:\n","                det_counter_per_class[class_name] += 1\n","            else:\n","                det_counter_per_class[class_name] = 1\n","    dr_classes = list(det_counter_per_class.keys())\n","\n","    \"\"\"\n","    Write number of ground-truth objects per class to results.txt\n","    \"\"\"\n","    with open(RESULTS_FILES_PATH + \"/results.txt\", 'a') as results_file:\n","        results_file.write(\"\\n# Number of ground-truth objects per class\\n\")\n","        for class_name in sorted(gt_counter_per_class):\n","            results_file.write(class_name + \": \" + str(gt_counter_per_class[class_name]) + \"\\n\")\n","\n","    \"\"\"\n","    Finish counting true positives\n","    \"\"\"\n","    for class_name in dr_classes:\n","        if class_name not in gt_classes:\n","            count_true_positives[class_name] = 0\n","\n","    \"\"\"\n","    Write number of detected objects per class to results.txt\n","    \"\"\"\n","    with open(RESULTS_FILES_PATH + \"/results.txt\", 'a') as results_file:\n","        results_file.write(\"\\n# Number of detected objects per class\\n\")\n","        for class_name in sorted(dr_classes):\n","            n_det = det_counter_per_class[class_name]\n","            text = class_name + \": \" + str(n_det)\n","            text += \" (tp:\" + str(count_true_positives[class_name]) + \"\"\n","            text += \", fp:\" + str(n_det - count_true_positives[class_name]) + \")\\n\"\n","            results_file.write(text)\n","\n","    \"\"\"\n","    Plot the total number of occurences of each class in the ground-truth\n","    \"\"\"\n","    if draw_plot:\n","        window_title = \"ground-truth-info\"\n","        plot_title = \"ground-truth\\n\"\n","        plot_title += \"(\" + str(len(ground_truth_files_list)) + \" files and \" + str(n_classes) + \" classes)\"\n","        x_label = \"Number of objects per class\"\n","        output_path = RESULTS_FILES_PATH + \"/ground-truth-info.png\"\n","        to_show = False\n","        plot_color = 'forestgreen'\n","        draw_plot_func(\n","            gt_counter_per_class,\n","            n_classes,\n","            window_title,\n","            plot_title,\n","            x_label,\n","            output_path,\n","            to_show,\n","            plot_color,\n","            '',\n","        )\n","\n","    # \"\"\"\n","    # Plot the total number of occurences of each class in the \"detection-results\" folder\n","    # \"\"\"\n","    # if draw_plot:\n","    #     window_title = \"detection-results-info\"\n","    #     # Plot title\n","    #     plot_title = \"detection-results\\n\"\n","    #     plot_title += \"(\" + str(len(dr_files_list)) + \" files and \"\n","    #     count_non_zero_values_in_dictionary = sum(int(x) > 0 for x in list(det_counter_per_class.values()))\n","    #     plot_title += str(count_non_zero_values_in_dictionary) + \" detected classes)\"\n","    #     # end Plot title\n","    #     x_label = \"Number of objects per class\"\n","    #     output_path = RESULTS_FILES_PATH + \"/detection-results-info.png\"\n","    #     to_show = False\n","    #     plot_color = 'forestgreen'\n","    #     true_p_bar = count_true_positives\n","    #     draw_plot_func(\n","    #         det_counter_per_class,\n","    #         len(det_counter_per_class),\n","    #         window_title,\n","    #         plot_title,\n","    #         x_label,\n","    #         output_path,\n","    #         to_show,\n","    #         plot_color,\n","    #         true_p_bar\n","    #         )\n","\n","    \"\"\"\n","    Draw log-average miss rate plot (Show lamr of all classes in decreasing order)\n","    \"\"\"\n","    if draw_plot:\n","        window_title = \"lamr\"\n","        plot_title = \"log-average miss rate\"\n","        x_label = \"log-average miss rate\"\n","        output_path = RESULTS_FILES_PATH + \"/lamr.png\"\n","        to_show = False\n","        plot_color = 'royalblue'\n","        draw_plot_func(\n","            lamr_dictionary,\n","            n_classes,\n","            window_title,\n","            plot_title,\n","            x_label,\n","            output_path,\n","            to_show,\n","            plot_color,\n","            \"\"\n","        )\n","\n","    \"\"\"\n","    Draw mAP plot (Show AP's of all classes in decreasing order)\n","    \"\"\"\n","    if draw_plot:\n","        window_title = \"mAP\"\n","        plot_title = \"mAP = {0:.3f}\".format(mAP)\n","        x_label = \"AP\"\n","        output_path = RESULTS_FILES_PATH + \"/mAP.pdf\"\n","        to_show = True\n","        plot_color = 'royalblue'\n","        fig = plt.figure(figsize=(7, 6), dpi=150)\n","        draw_plot_func(\n","            ap_dictionary,\n","            n_classes,\n","            window_title,\n","            plot_title,\n","            x_label,\n","            output_path,\n","            to_show,\n","            plot_color,\n","            \"\"\n","        )\n","    return mAP, df_dic\n","\n","\n","################################ PREPROCESSING GT #############################\n","def preprocess_gt(gt_path, class_names):\n","    image_ids = os.listdir(gt_path)\n","    results = {}\n","\n","    images = []\n","    bboxes = []\n","    for i, image_id in enumerate(image_ids):\n","        lines_list = file_lines_to_list(os.path.join(gt_path, image_id))\n","        boxes_per_image = []\n","        image = {}\n","        image_id = os.path.splitext(image_id)[0]\n","        image['file_name'] = image_id + '.jpg'\n","        image['width'] = 1\n","        image['height'] = 1\n","\n","        image['id'] = str(image_id)\n","\n","        for line in lines_list:\n","            difficult = 0\n","            if \"difficult\" in line:\n","                line_split = line.split()\n","                left, top, right, bottom, _difficult = line_split[-5:]\n","                class_name = \"\"\n","                for name in line_split[:-5]:\n","                    class_name += name + \" \"\n","                class_name = class_name[:-1]\n","                difficult = 1\n","            else:\n","                line_split = line.split()\n","                left, top, right, bottom = line_split[-4:]\n","                class_name = \"\"\n","                for name in line_split[:-4]:\n","                    class_name += name + \" \"\n","                class_name = class_name[:-1]\n","\n","            left, top, right, bottom = float(left), float(top), float(right), float(bottom)\n","            if class_name not in class_names:\n","                continue\n","            cls_id = class_names.index(class_name) + 1\n","            bbox = [left, top, right - left, bottom - top, difficult, str(image_id), cls_id,\n","                    (right - left) * (bottom - top) - 10.0]\n","            boxes_per_image.append(bbox)\n","        images.append(image)\n","        bboxes.extend(boxes_per_image)\n","    results['images'] = images\n","\n","    categories = []\n","    for i, cls in enumerate(class_names):\n","        category = {}\n","        category['supercategory'] = cls\n","        category['name'] = cls\n","        category['id'] = i + 1\n","        categories.append(category)\n","    results['categories'] = categories\n","\n","    annotations = []\n","    for i, box in enumerate(bboxes):\n","        annotation = {}\n","        annotation['area'] = box[-1]\n","        annotation['category_id'] = box[-2]\n","        annotation['image_id'] = box[-3]\n","        annotation['iscrowd'] = box[-4]\n","        annotation['bbox'] = box[:4]\n","        annotation['id'] = i\n","        annotations.append(annotation)\n","    results['annotations'] = annotations\n","    return results\n","\n","################################ PREPROCESSING DR #############################\n","def preprocess_dr(dr_path, class_names):\n","    image_ids = os.listdir(dr_path)\n","    results = []\n","    for image_id in image_ids:\n","        lines_list = file_lines_to_list(os.path.join(dr_path, image_id))\n","        image_id = os.path.splitext(image_id)[0]\n","        for line in lines_list:\n","            line_split = line.split()\n","            confidence, left, top, right, bottom = line_split[-5:]\n","            class_name = \"\"\n","            for name in line_split[:-5]:\n","                class_name += name + \" \"\n","            class_name = class_name[:-1]\n","            # left, top, right, bottom = float(left), float(top), float(right), float(bottom)\n","            left, top, right, bottom = float(left), float(top), float(right), float(bottom)\n","            left = max(0, left)\n","            top = max(0, top)\n","            right = max(0, right)\n","            bottom = max(0, bottom)\n","            result = {}\n","            result[\"image_id\"] = str(image_id)\n","            if class_name not in class_names:\n","                continue\n","            result[\"category_id\"] = class_names.index(class_name) + 1\n","            result[\"bbox\"] = [left, top, right - left, bottom - top]\n","            result[\"score\"] = float(confidence)\n","            results.append(result)\n","    return results\n","\n","\n","# def get_coco_map(class_names, path):\n","#     GT_PATH = os.path.join(path, 'ground-truth')\n","#     DR_PATH = os.path.join(path, 'detection-results')\n","#     COCO_PATH = os.path.join(path, 'coco_eval')\n","\n","#     if not os.path.exists(COCO_PATH):\n","#         os.makedirs(COCO_PATH)\n","\n","#     GT_JSON_PATH = os.path.join(COCO_PATH, 'instances_gt.json')\n","#     DR_JSON_PATH = os.path.join(COCO_PATH, 'instances_dr.json')\n","\n","#     with open(GT_JSON_PATH, \"w\") as f:\n","#         results_gt = preprocess_gt(GT_PATH, class_names)\n","#         json.dump(results_gt, f, indent=4)\n","\n","#     with open(DR_JSON_PATH, \"w\") as f:\n","#         results_dr = preprocess_dr(DR_PATH, class_names)\n","#         json.dump(results_dr, f, indent=4)\n","#         if len(results_dr) == 0:\n","#             return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","#     cocoGt = COCO(GT_JSON_PATH)\n","#     cocoDt = cocoGt.loadRes(DR_JSON_PATH)\n","#     cocoEval = COCOeval(cocoGt, cocoDt, 'bbox')\n","#     cocoEval.evaluate()\n","#     cocoEval.accumulate()\n","#     cocoEval.summarize()\n","\n","#     # Menampilkan AP untuk setiap kelas dalam bentuk persen\n","#     print(\"\\nAverage Precision (AP) for each class (in %):\")\n","#     for i, class_name in enumerate(class_names):\n","#         ap = cocoEval.stats[1 + i] * 100  # AP untuk IoU=0.50 dalam persen\n","#         print(f\"AP for {class_name}: {ap:.2f}%\")\n","\n","#     # Menampilkan mAP dalam bentuk persen\n","#     mAP = cocoEval.stats[0] * 100  # mAP untuk IoU=0.50:0.95 dalam persen\n","#     print(f\"\\nMean Average Precision (mAP): {mAP:.2f}%\")\n","\n","#     return cocoEval.stats\n","\n","def get_coco_map(class_names, path):\n","    GT_PATH = os.path.join(path, 'ground-truth')\n","    DR_PATH = os.path.join(path, 'detection-results')\n","    COCO_PATH = os.path.join(path, 'coco_eval')\n","\n","    if not os.path.exists(COCO_PATH):\n","        os.makedirs(COCO_PATH)\n","\n","    GT_JSON_PATH = os.path.join(COCO_PATH, 'instances_gt.json')\n","    DR_JSON_PATH = os.path.join(COCO_PATH, 'instances_dr.json')\n","\n","    with open(GT_JSON_PATH, \"w\") as f:\n","        results_gt = preprocess_gt(GT_PATH, class_names)\n","        json.dump(results_gt, f, indent=4)\n","\n","    with open(DR_JSON_PATH, \"w\") as f:\n","        results_dr = preprocess_dr(DR_PATH, class_names)\n","        json.dump(results_dr, f, indent=4)\n","        if len(results_dr) == 0:\n","            return {\"AP50\": 0, \"mAP\": 0}\n","\n","    cocoGt = COCO(GT_JSON_PATH)\n","    cocoDt = cocoGt.loadRes(DR_JSON_PATH)\n","    cocoEval = COCOeval(cocoGt, cocoDt, 'bbox')\n","    cocoEval.evaluate()\n","    cocoEval.accumulate()\n","    cocoEval.summarize()\n","\n","    # Ambil hasil mAP untuk IoU=0.50 dan IoU=0.50:0.95\n","    AP50 = cocoEval.stats[1] * 100  # mAP untuk IoU=0.50 dalam persen\n","    mAP = cocoEval.stats[0] * 100  # mAP untuk IoU=0.50:0.95 dalam persen\n","\n","    print(f\"\\nmAP untuk IoU=0.50: {AP50:.2f}%\")\n","    print(f\"mAP untuk IoU=0.50:0.95: {mAP:.2f}%\")\n","\n","    return {\"AP50\": AP50, \"mAP\": mAP}\n"]},{"cell_type":"markdown","metadata":{"id":"IXQpEB21H-vu"},"source":["###**UTILS_FIT**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4be1fvFZIAlr"},"outputs":[],"source":["import os\n","\n","import torch\n","from tqdm import tqdm\n","\n","# from utils.utils import get_lr\n","\n","\n","def fit_one_epoch(model_train, model, ema, yolo_loss, loss_history, eval_callback, optimizer, epoch, epoch_step,\n","                  epoch_step_val, gen, gen_val, Epoch, cuda, fp16, scaler, save_period, save_dir, local_rank=0):\n","    loss = 0\n","    val_loss = 0\n","\n","    if local_rank == 0:\n","        print('Start Train')\n","        pbar = tqdm(total=epoch_step, desc=f'Epoch {epoch + 1}/{Epoch}', postfix=dict, mininterval=0.3)\n","    model_train.train()\n","    for iteration, batch in enumerate(gen):\n","        if iteration >= epoch_step:\n","            break\n","\n","        images, targets = batch[0], batch[1]\n","        with torch.no_grad():\n","            if cuda:\n","                images = images.cuda(local_rank)\n","                targets = [ann.cuda(local_rank) for ann in targets]\n","\n","        optimizer.zero_grad()\n","        if not fp16:\n","\n","            outputs = model_train(images)\n","\n","            loss_value = yolo_loss(outputs, targets)\n","\n","            loss_value.backward()\n","            optimizer.step()\n","        else:\n","            from torch.cuda.amp import autocast\n","            with autocast():\n","                outputs = model_train(images)\n","\n","                loss_value = yolo_loss(outputs, targets)\n","\n","            scaler.scale(loss_value).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        if ema:\n","            ema.update(model_train)\n","\n","        loss += loss_value.item()\n","\n","        if local_rank == 0:\n","            pbar.set_postfix(**{'loss': loss / (iteration + 1),\n","                                'lr': get_lr(optimizer)})\n","            pbar.update(1)\n","\n","    if local_rank == 0:\n","        pbar.close()\n","        print('Finish Train')\n","        print('Start Validation')\n","        pbar = tqdm(total=epoch_step_val, desc=f'Epoch {epoch + 1}/{Epoch}', postfix=dict, mininterval=0.3)\n","\n","    if ema:\n","        model_train_eval = ema.ema\n","    else:\n","        model_train_eval = model_train.eval()\n","\n","    for iteration, batch in enumerate(gen_val):\n","        if iteration >= epoch_step_val:\n","            break\n","        images, targets = batch[0], batch[1]\n","        with torch.no_grad():\n","            if cuda:\n","                images = images.cuda(local_rank)\n","                targets = [ann.cuda(local_rank) for ann in targets]\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model_train_eval(images)\n","\n","            loss_value = yolo_loss(outputs, targets)\n","\n","        val_loss += loss_value.item()\n","        if local_rank == 0:\n","            pbar.set_postfix(**{'val_loss': val_loss / (iteration + 1)})\n","            pbar.update(1)\n","\n","    if local_rank == 0:\n","        pbar.close()\n","        print('Finish Validation')\n","        loss_history.append_loss(epoch + 1, loss / epoch_step, val_loss / epoch_step_val)\n","        eval_callback.on_epoch_end(epoch + 1, model_train_eval)\n","        print('Epoch:' + str(epoch + 1) + '/' + str(Epoch))\n","        print('Total Loss: %.3f || Val Loss: %.3f ' % (loss / epoch_step, val_loss / epoch_step_val))\n","\n","        if ema:\n","            save_state_dict = ema.ema.state_dict()\n","        else:\n","            save_state_dict = model.state_dict()\n","\n","        if (epoch + 1) % save_period == 0 or epoch + 1 == Epoch:\n","            torch.save(save_state_dict, os.path.join(save_dir, \"ep%03d-loss%.3f-val_loss%.3f.pth\" % (\n","            epoch + 1, loss / epoch_step, val_loss / epoch_step_val)))\n","\n","        if len(loss_history.val_loss) <= 1 or (val_loss / epoch_step_val) <= min(loss_history.val_loss):\n","            print('Save best model to best_epoch_weights.pth')\n","            torch.save(save_state_dict, os.path.join(save_dir, \"best_epoch_weights.pth\"))\n","\n","        torch.save(save_state_dict, os.path.join(save_dir, \"last_epoch_weights.pth\"))\n"]},{"cell_type":"markdown","metadata":{"id":"Mhp8H8AcHBuL"},"source":["\n","\n","###**CALLBACK**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRcOGSuVG9n8"},"outputs":[],"source":["import os\n","\n","import torch\n","import matplotlib\n","matplotlib.use('Agg')\n","import scipy.signal\n","from matplotlib import pyplot as plt\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import shutil\n","import numpy as np\n","\n","from PIL import Image\n","from tqdm import tqdm\n","# from .utils import cvtColor, preprocess_input, resize_image\n","# from .utils_bbox import decode_outputs, non_max_suppression\n","# from .utils_map import get_coco_map, get_map\n","\n","\n","class LossHistory():\n","    def __init__(self, log_dir, model, input_shape):\n","        self.log_dir    = log_dir\n","        self.losses     = []\n","        self.val_loss   = []\n","\n","        os.makedirs(self.log_dir)\n","        self.writer     = SummaryWriter(self.log_dir)\n","        try:\n","            dummy_input     = torch.randn(2, 3, input_shape[0], input_shape[1])\n","            self.writer.add_graph(model, dummy_input)\n","        except:\n","            pass\n","\n","    def append_loss(self, epoch, loss, val_loss):\n","        if not os.path.exists(self.log_dir):\n","            os.makedirs(self.log_dir)\n","\n","        self.losses.append(loss)\n","        self.val_loss.append(val_loss)\n","\n","        with open(os.path.join(self.log_dir, \"epoch_loss.txt\"), 'a') as f:\n","            f.write(str(loss))\n","            f.write(\"\\n\")\n","        with open(os.path.join(self.log_dir, \"epoch_val_loss.txt\"), 'a') as f:\n","            f.write(str(val_loss))\n","            f.write(\"\\n\")\n","\n","        self.writer.add_scalar('loss', loss, epoch)\n","        self.writer.add_scalar('val_loss', val_loss, epoch)\n","        self.loss_plot()\n","\n","    def loss_plot(self):\n","        iters = range(len(self.losses))\n","\n","        plt.figure()\n","        plt.plot(iters, self.losses, 'red', linewidth = 2, label='train loss')\n","        plt.plot(iters, self.val_loss, 'coral', linewidth = 2, label='val loss')\n","        try:\n","            if len(self.losses) < 25:\n","                num = 5\n","            else:\n","                num = 15\n","\n","            plt.plot(iters, scipy.signal.savgol_filter(self.losses, num, 3), 'green', linestyle = '--', linewidth = 2, label='smooth train loss')\n","            plt.plot(iters, scipy.signal.savgol_filter(self.val_loss, num, 3), '#8B4513', linestyle = '--', linewidth = 2, label='smooth val loss')\n","        except:\n","            pass\n","\n","        plt.grid(True)\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.legend(loc=\"upper right\")\n","\n","        plt.savefig(os.path.join(self.log_dir, \"epoch_loss.png\"))\n","\n","        plt.cla()\n","        plt.close(\"all\")\n","\n","class EvalCallback():\n","    def __init__(self, net, input_shape, class_names, num_classes, val_lines, log_dir, cuda, \\\n","            map_out_path=\".temp_map_out\", max_boxes=100, confidence=0.05, nms_iou=0.5, letterbox_image=True, MINOVERLAP=0.5, eval_flag=True, period=1):\n","        super(EvalCallback, self).__init__()\n","\n","        self.net                = net\n","        self.input_shape        = input_shape\n","        self.class_names        = class_names\n","        self.num_classes        = num_classes\n","        self.val_lines          = val_lines\n","        self.log_dir            = log_dir\n","        self.cuda               = cuda\n","        self.map_out_path       = map_out_path\n","        self.max_boxes          = max_boxes\n","        self.confidence         = confidence\n","        self.nms_iou            = nms_iou\n","        self.letterbox_image    = letterbox_image\n","        self.MINOVERLAP         = MINOVERLAP\n","        self.eval_flag          = eval_flag\n","        self.period             = period\n","\n","        self.maps       = [0]\n","        self.epoches    = [0]\n","        if self.eval_flag:\n","            with open(os.path.join(self.log_dir, \"epoch_map.txt\"), 'a') as f:\n","                f.write(str(0))\n","                f.write(\"\\n\")\n","\n","    def get_map_txt(self, image_id, image, class_names, map_out_path):\n","        f = open(os.path.join(map_out_path, \"detection-results/\"+image_id+\".txt\"),\"w\")\n","        image_shape = np.array(np.shape(image)[0:2])\n","\n","        image       = cvtColor(image)\n","\n","        image_data  = resize_image(image, (self.input_shape[1],self.input_shape[0]), self.letterbox_image)\n","\n","        image_data  = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, dtype='float32')), (2, 0, 1)), 0)\n","\n","        with torch.no_grad():\n","            images = torch.from_numpy(image_data)\n","            if self.cuda:\n","                images = images.cuda()\n","\n","            outputs = self.net(images)\n","            outputs = decode_outputs(outputs, self.input_shape)\n","\n","            results = non_max_suppression(outputs, self.num_classes, self.input_shape,\n","                        image_shape, self.letterbox_image, conf_thres = self.confidence, nms_thres = self.nms_iou)\n","\n","            if results[0] is None:\n","                return\n","\n","            top_label   = np.array(results[0][:, 6], dtype = 'int32')\n","            top_conf    = results[0][:, 4] * results[0][:, 5]\n","            top_boxes   = results[0][:, :4]\n","\n","        top_100     = np.argsort(top_conf)[::-1][:self.max_boxes]\n","        top_boxes   = top_boxes[top_100]\n","        top_conf    = top_conf[top_100]\n","        top_label   = top_label[top_100]\n","\n","        for i, c in list(enumerate(top_label)):\n","            predicted_class = self.class_names[int(c)]\n","            box             = top_boxes[i]\n","            score           = str(top_conf[i])\n","\n","            top, left, bottom, right = box\n","            if predicted_class not in class_names:\n","                continue\n","\n","            f.write(\"%s %s %s %s %s %s\\n\" % (predicted_class, score[:6], str(int(left)), str(int(top)), str(int(right)),str(int(bottom))))\n","\n","        f.close()\n","        return\n","\n","    def on_epoch_end(self, epoch, model_eval):\n","        if epoch % self.period == 0 and self.eval_flag:\n","            self.net = model_eval\n","            if not os.path.exists(self.map_out_path):\n","                os.makedirs(self.map_out_path)\n","            if not os.path.exists(os.path.join(self.map_out_path, \"ground-truth\")):\n","                os.makedirs(os.path.join(self.map_out_path, \"ground-truth\"))\n","            if not os.path.exists(os.path.join(self.map_out_path, \"detection-results\")):\n","                os.makedirs(os.path.join(self.map_out_path, \"detection-results\"))\n","            print(\"Get map.\")\n","            for annotation_line in tqdm(self.val_lines):\n","                line        = annotation_line.split()\n","                image_id    = os.path.basename(line[0]).split('.')[0]\n","\n","                image       = Image.open(line[0])\n","\n","                gt_boxes    = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n","\n","                self.get_map_txt(image_id, image, self.class_names, self.map_out_path)\n","\n","                with open(os.path.join(self.map_out_path, \"ground-truth/\"+image_id+\".txt\"), \"w\") as new_f:\n","                    for box in gt_boxes:\n","                        left, top, right, bottom, obj = box\n","                        obj_name = self.class_names[obj]\n","                        new_f.write(\"%s %s %s %s %s\\n\" % (obj_name, left, top, right, bottom))\n","\n","            print(\"Calculate Map.\")\n","            try:\n","                temp_map = get_coco_map(class_names = self.class_names, path = self.map_out_path)[1]\n","            except:\n","                temp_map = get_map(self.MINOVERLAP, True, path = self.map_out_path)\n","            self.maps.append(temp_map)\n","            self.epoches.append(epoch)\n","\n","            with open(os.path.join(self.log_dir, \"epoch_map.txt\"), 'a') as f:\n","                f.write(str(temp_map))\n","                f.write(\"\\n\")\n","\n","            plt.figure()\n","            plt.plot(self.epoches, self.maps, 'red', linewidth = 2, label='train map')\n","\n","            plt.grid(True)\n","            plt.xlabel('Epoch')\n","            plt.ylabel('Map %s'%str(self.MINOVERLAP))\n","            plt.title('A Map Curve')\n","            plt.legend(loc=\"upper right\")\n","\n","            plt.savefig(os.path.join(self.log_dir, \"epoch_map.png\"))\n","            plt.cla()\n","            plt.close(\"all\")\n","\n","            print(\"Get map done.\")\n","            shutil.rmtree(self.map_out_path)"]},{"cell_type":"markdown","metadata":{"id":"IOS6yaVAHsYP"},"source":["###**DATALOADER**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QW275keEHuNw"},"outputs":[],"source":["from random import sample, shuffle\n","\n","import cv2\n","import numpy as np\n","import torch\n","from PIL import Image\n","from torch.utils.data.dataset import Dataset\n","\n","# from utils.utils import cvtColor, preprocess_input\n","\n","\n","class YoloDataset(Dataset):\n","    def __init__(self, annotation_lines, input_shape, num_classes, epoch_length, \\\n","                        mosaic, mixup, mosaic_prob, mixup_prob, train, special_aug_ratio = 0.7):\n","        super(YoloDataset, self).__init__()\n","        self.annotation_lines   = annotation_lines\n","        self.input_shape        = input_shape\n","        self.num_classes        = num_classes\n","        self.epoch_length       = epoch_length\n","        self.mosaic             = mosaic\n","        self.mosaic_prob        = mosaic_prob\n","        self.mixup              = mixup\n","        self.mixup_prob         = mixup_prob\n","        self.train              = train\n","        self.special_aug_ratio  = special_aug_ratio\n","\n","        self.epoch_now          = -1\n","        self.length             = len(self.annotation_lines)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, index):\n","        index = index % self.length\n","\n","        if self.mosaic and self.rand() < self.mosaic_prob and self.epoch_now < self.epoch_length * self.special_aug_ratio:\n","            lines = sample(self.annotation_lines, 3)\n","            lines.append(self.annotation_lines[index])\n","            # shuffle_data = shuffle(lines)\n","            # shuffle_flag = shuffle(lines)\n","            shuffle(lines)\n","            image, box  = self.get_random_data_with_Mosaic(lines, self.input_shape)\n","\n","            if self.mixup and self.rand() < self.mixup_prob:\n","                lines           = sample(self.annotation_lines, 1)\n","                image_2, box_2  = self.get_random_data(lines[0], self.input_shape, random = self.train)\n","                image, box      = self.get_random_data_with_MixUp(image, box, image_2, box_2)\n","        else:\n","            image, box      = self.get_random_data(self.annotation_lines[index], self.input_shape, random = self.train)\n","\n","        image       = np.transpose(preprocess_input(np.array(image, dtype=np.float32)), (2, 0, 1))\n","        box         = np.array(box, dtype=np.float32)\n","        if len(box) != 0:\n","            box[:, 2:4] = box[:, 2:4] - box[:, 0:2]\n","            box[:, 0:2] = box[:, 0:2] + box[:, 2:4] / 2\n","        return image, box\n","\n","    def rand(self, a=0, b=1):\n","        return np.random.rand()*(b-a) + a\n","\n","    def get_random_data(self, annotation_line, input_shape, jitter=.3, hue=.1, sat=0.7, val=0.4, random=True):\n","        line    = annotation_line.split()\n","\n","        image   = Image.open(line[0])\n","        image   = cvtColor(image)\n","\n","        iw, ih  = image.size\n","        h, w    = input_shape\n","\n","        box     = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n","\n","        if not random:\n","            scale = min(w/iw, h/ih)\n","            nw = int(iw*scale)\n","            nh = int(ih*scale)\n","            dx = (w-nw)//2\n","            dy = (h-nh)//2\n","\n","            image       = image.resize((nw,nh), Image.BICUBIC)\n","            new_image   = Image.new('RGB', (w,h), (128,128,128))\n","            new_image.paste(image, (dx, dy))\n","            image_data  = np.array(new_image, np.float32)\n","#\n","            if len(box)>0:\n","                np.random.shuffle(box)\n","                box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n","                box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n","                box[:, 0:2][box[:, 0:2]<0] = 0\n","                box[:, 2][box[:, 2]>w] = w\n","                box[:, 3][box[:, 3]>h] = h\n","                box_w = box[:, 2] - box[:, 0]\n","                box_h = box[:, 3] - box[:, 1]\n","                box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n","\n","            return image_data, box\n","\n","        new_ar = iw/ih * self.rand(1-jitter,1+jitter) / self.rand(1-jitter,1+jitter)\n","        scale = self.rand(.25, 2)\n","        if new_ar < 1:\n","            nh = int(scale*h)\n","            nw = int(nh*new_ar)\n","        else:\n","            nw = int(scale*w)\n","            nh = int(nw/new_ar)\n","        image = image.resize((nw,nh), Image.BICUBIC)\n","\n","\n","        dx = int(self.rand(0, w-nw))\n","        dy = int(self.rand(0, h-nh))\n","        new_image = Image.new('RGB', (w,h), (128,128,128))\n","        new_image.paste(image, (dx, dy))\n","        image = new_image\n","\n","\n","        flip = self.rand()<.5\n","        if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n","\n","        image_data      = np.array(image, np.uint8)\n","\n","        r               = np.random.uniform(-1, 1, 3) * [hue, sat, val] + 1\n","\n","        hue, sat, val   = cv2.split(cv2.cvtColor(image_data, cv2.COLOR_RGB2HSV))\n","        dtype           = image_data.dtype\n","\n","        x       = np.arange(0, 256, dtype=r.dtype)\n","        lut_hue = ((x * r[0]) % 180).astype(dtype)\n","        lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)\n","        lut_val = np.clip(x * r[2], 0, 255).astype(dtype)\n","\n","        image_data = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))\n","        image_data = cv2.cvtColor(image_data, cv2.COLOR_HSV2RGB)\n","\n","\n","        if len(box)>0:\n","            np.random.shuffle(box)\n","            box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n","            box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n","            if flip: box[:, [0,2]] = w - box[:, [2,0]]\n","            box[:, 0:2][box[:, 0:2]<0] = 0\n","            box[:, 2][box[:, 2]>w] = w\n","            box[:, 3][box[:, 3]>h] = h\n","            box_w = box[:, 2] - box[:, 0]\n","            box_h = box[:, 3] - box[:, 1]\n","            box = box[np.logical_and(box_w>1, box_h>1)]\n","\n","        return image_data, box\n","\n","    def merge_bboxes(self, bboxes, cutx, cuty):\n","        merge_bbox = []\n","        for i in range(len(bboxes)):\n","            for box in bboxes[i]:\n","                tmp_box = []\n","                x1, y1, x2, y2 = box[0], box[1], box[2], box[3]\n","\n","                if i == 0:\n","                    if y1 > cuty or x1 > cutx:\n","                        continue\n","                    if y2 >= cuty and y1 <= cuty:\n","                        y2 = cuty\n","                    if x2 >= cutx and x1 <= cutx:\n","                        x2 = cutx\n","\n","                if i == 1:\n","                    if y2 < cuty or x1 > cutx:\n","                        continue\n","                    if y2 >= cuty and y1 <= cuty:\n","                        y1 = cuty\n","                    if x2 >= cutx and x1 <= cutx:\n","                        x2 = cutx\n","\n","                if i == 2:\n","                    if y2 < cuty or x2 < cutx:\n","                        continue\n","                    if y2 >= cuty and y1 <= cuty:\n","                        y1 = cuty\n","                    if x2 >= cutx and x1 <= cutx:\n","                        x1 = cutx\n","\n","                if i == 3:\n","                    if y1 > cuty or x2 < cutx:\n","                        continue\n","                    if y2 >= cuty and y1 <= cuty:\n","                        y2 = cuty\n","                    if x2 >= cutx and x1 <= cutx:\n","                        x1 = cutx\n","                tmp_box.append(x1)\n","                tmp_box.append(y1)\n","                tmp_box.append(x2)\n","                tmp_box.append(y2)\n","                tmp_box.append(box[-1])\n","                merge_bbox.append(tmp_box)\n","        return merge_bbox\n","\n","    def get_random_data_with_Mosaic(self, annotation_line, input_shape, jitter=0.3, hue=.1, sat=0.7, val=0.4):\n","        h, w = input_shape\n","        min_offset_x = self.rand(0.3, 0.7)\n","        min_offset_y = self.rand(0.3, 0.7)\n","\n","        image_datas = []\n","        box_datas   = []\n","        index       = 0\n","        for line in annotation_line:\n","\n","            line_content = line.split()\n","\n","            image = Image.open(line_content[0])\n","            image = cvtColor(image)\n","\n","\n","            iw, ih = image.size\n","\n","            box = np.array([np.array(list(map(int,box.split(',')))) for box in line_content[1:]])\n","\n","            flip = self.rand()<.5\n","            if flip and len(box)>0:\n","                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n","                box[:, [0,2]] = iw - box[:, [2,0]]\n","\n","\n","            new_ar = iw/ih * self.rand(1-jitter,1+jitter) / self.rand(1-jitter,1+jitter)\n","            scale = self.rand(.4, 1)\n","            if new_ar < 1:\n","                nh = int(scale*h)\n","                nw = int(nh*new_ar)\n","            else:\n","                nw = int(scale*w)\n","                nh = int(nw/new_ar)\n","            image = image.resize((nw, nh), Image.BICUBIC)\n","\n","\n","            if index == 0:\n","                dx = int(w*min_offset_x) - nw\n","                dy = int(h*min_offset_y) - nh\n","            elif index == 1:\n","                dx = int(w*min_offset_x) - nw\n","                dy = int(h*min_offset_y)\n","            elif index == 2:\n","                dx = int(w*min_offset_x)\n","                dy = int(h*min_offset_y)\n","            elif index == 3:\n","                dx = int(w*min_offset_x)\n","                dy = int(h*min_offset_y) - nh\n","\n","            new_image = Image.new('RGB', (w,h), (128,128,128))\n","            new_image.paste(image, (dx, dy))\n","            image_data = np.array(new_image)\n","\n","            index = index + 1\n","            box_data = []\n","\n","            if len(box)>0:\n","                np.random.shuffle(box)\n","                box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n","                box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n","                box[:, 0:2][box[:, 0:2]<0] = 0\n","                box[:, 2][box[:, 2]>w] = w\n","                box[:, 3][box[:, 3]>h] = h\n","                box_w = box[:, 2] - box[:, 0]\n","                box_h = box[:, 3] - box[:, 1]\n","                box = box[np.logical_and(box_w>1, box_h>1)]\n","                box_data = np.zeros((len(box),5))\n","                box_data[:len(box)] = box\n","\n","            image_datas.append(image_data)\n","            box_datas.append(box_data)\n","\n","\n","        cutx = int(w * min_offset_x)\n","        cuty = int(h * min_offset_y)\n","\n","        new_image = np.zeros([h, w, 3])\n","        new_image[:cuty, :cutx, :] = image_datas[0][:cuty, :cutx, :]\n","        new_image[cuty:, :cutx, :] = image_datas[1][cuty:, :cutx, :]\n","        new_image[cuty:, cutx:, :] = image_datas[2][cuty:, cutx:, :]\n","        new_image[:cuty, cutx:, :] = image_datas[3][:cuty, cutx:, :]\n","\n","        new_image       = np.array(new_image, np.uint8)\n","\n","        r               = np.random.uniform(-1, 1, 3) * [hue, sat, val] + 1\n","\n","        hue, sat, val   = cv2.split(cv2.cvtColor(new_image, cv2.COLOR_RGB2HSV))\n","        dtype           = new_image.dtype\n","\n","        x       = np.arange(0, 256, dtype=r.dtype)\n","        lut_hue = ((x * r[0]) % 180).astype(dtype)\n","        lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)\n","        lut_val = np.clip(x * r[2], 0, 255).astype(dtype)\n","\n","        new_image = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))\n","        new_image = cv2.cvtColor(new_image, cv2.COLOR_HSV2RGB)\n","\n","        new_boxes = self.merge_bboxes(box_datas, cutx, cuty)\n","\n","        return new_image, new_boxes\n","\n","    def get_random_data_with_MixUp(self, image_1, box_1, image_2, box_2):\n","        new_image = np.array(image_1, np.float32) * 0.5 + np.array(image_2, np.float32) * 0.5\n","        if len(box_1) == 0:\n","            new_boxes = box_2\n","        elif len(box_2) == 0:\n","            new_boxes = box_1\n","        else:\n","            new_boxes = np.concatenate([box_1, box_2], axis=0)\n","        return new_image, new_boxes\n","\n","# DataLoader中collate_fn使用\n","def yolo_dataset_collate(batch):\n","    images = []\n","    bboxes = []\n","    for img, box in batch:\n","        images.append(img)\n","        bboxes.append(box)\n","    images = torch.from_numpy(np.array(images)).type(torch.FloatTensor)\n","    bboxes = [torch.from_numpy(ann).type(torch.FloatTensor) for ann in bboxes]\n","    return images, bboxes\n"]},{"cell_type":"markdown","metadata":{"id":"yWv9huXWGuXN"},"source":["## **NETS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoLnuEOJypgJ"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/skripsiAini/')"]},{"cell_type":"markdown","metadata":{"id":"Bs6adOE2vDOe"},"source":["### **darknet**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732854911918,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"7xDJxWM1tdOV","outputId":"53a290df-2744-456b-aa2f-9043f4fb98f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["CSPDarknet(\n","  (stem): Focus(\n","    (conv): BaseConv(\n","      (conv): Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","  )\n","  (dark2): Sequential(\n","    (0): BaseConv(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (1): CSPLayer(\n","      (conv1): BaseConv(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv2): BaseConv(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv3): BaseConv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (2): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dark3): Sequential(\n","    (0): BaseConv(\n","      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (1): CSPLayer(\n","      (conv1): BaseConv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv2): BaseConv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv3): BaseConv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (2): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (3): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (4): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (5): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (6): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (7): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (8): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dark4): Sequential(\n","    (0): BaseConv(\n","      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (1): CSPLayer(\n","      (conv1): BaseConv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv2): BaseConv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv3): BaseConv(\n","        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (2): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (3): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (4): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (5): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (6): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (7): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (8): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dark5): Sequential(\n","    (0): BaseConv(\n","      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (1): SPPBottleneck(\n","      (conv1): BaseConv(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): ModuleList(\n","        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n","        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n","      )\n","      (conv2): BaseConv(\n","        (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","    )\n","    (2): CSPLayer(\n","      (conv1): BaseConv(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv2): BaseConv(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (conv3): BaseConv(\n","        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (2): Bottleneck(\n","          (conv1): BaseConv(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (conv2): BaseConv(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","  )\n",")\n"]}],"source":["import torch\n","from torch import nn\n","\n","# Definisi fungsi aktivasi SiLU (Sigmoid Linear Unit)\n","class SiLU(nn.Module):\n","    @staticmethod\n","    def forward(x):\n","        return x * torch.sigmoid(x)\n","\n","# Fungsi untuk memilih jenis aktivasi\n","def get_activation(name=\"silu\", inplace=True):\n","    if name == \"silu\":\n","        module = SiLU() # Menggunakan SiLU sebagai aktivasi\n","    elif name == \"relu\":\n","        module = nn.ReLU(inplace=inplace) # Menggunakan ReLU sebagai aktivasi\n","    elif name == \"lrelu\":\n","        module = nn.LeakyReLU(0.1, inplace=inplace) # Menggunakan LeakyReLU sebagai aktivasi\n","    else:\n","        raise AttributeError(\"Unsupported act type: {}\".format(name))\n","    return module\n","\n","# Fokus Layer, digunakan untuk mengambil fitur patch dari citra input\n","class Focus(nn.Module):\n","    def __init__(self, in_channels, out_channels, ksize=1, stride=1, act=\"silu\"):\n","        super().__init__()\n","        self.conv = BaseConv(in_channels * 4, out_channels, ksize, stride, act=act)\n","\n","    # Membagi citra menjadi empat bagian kecil (patch)\n","    def forward(self, x):\n","        patch_top_left  = x[...,  ::2,  ::2]\n","        patch_bot_left  = x[..., 1::2,  ::2]\n","        patch_top_right = x[...,  ::2, 1::2]\n","        patch_bot_right = x[..., 1::2, 1::2]\n","        x = torch.cat((patch_top_left, patch_bot_left, patch_top_right, patch_bot_right,), dim=1,)\n","        return self.conv(x)\n","\n","# Convolution dasar dengan batch normalization dan aktivasi\n","class BaseConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, ksize, stride, groups=1, bias=False, act=\"silu\"):\n","        super().__init__()\n","        pad         = (ksize - 1) // 2 # Padding untuk menjaga dimensi output\n","        self.conv   = nn.Conv2d(in_channels, out_channels, kernel_size=ksize, stride=stride, padding=pad, groups=groups, bias=bias)\n","        self.bn     = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.03) # Batch Normalization\n","        self.act    = get_activation(act, inplace=True) # Memilih aktivasi sesuai parameter\n","\n","    def forward(self, x):\n","        return self.act(self.bn(self.conv(x))) # Forward pass dengan konvolusi, batchnorm, dan aktivasi\n","\n","    def fuseforward(self, x):\n","        return self.act(self.conv(x)) # Forward pass tanpa batchnorm\n","\n","# Depthwise Convolution, digunakan untuk optimasi parameter\n","class DWConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, ksize, stride=1, act=\"silu\"):\n","        super().__init__()\n","        # Depthwise Convolution\n","        self.dconv = BaseConv(in_channels, in_channels, ksize=ksize, stride=stride, groups=in_channels, act=act,)\n","        # Pointwise Convolution\n","        self.pconv = BaseConv(in_channels, out_channels, ksize=1, stride=1, groups=1, act=act)\n","\n","    def forward(self, x):\n","        x = self.dconv(x) # Depthwise convolution\n","        return self.pconv(x) # Pointwise convolution\n","\n","# Spatial Pyramid Pooling (SPP) untuk mengambil fitur multi-scale\n","class SPPBottleneck(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_sizes=(5, 9, 13), activation=\"silu\"):\n","        super().__init__()\n","        hidden_channels = in_channels // 2\n","        self.conv1      = BaseConv(in_channels, hidden_channels, 1, stride=1, act=activation)\n","        # MaxPool dengan berbagai ukuran kernel untuk ekstraksi fitur multi-skala\n","        self.m          = nn.ModuleList([nn.MaxPool2d(kernel_size=ks, stride=1, padding=ks // 2) for ks in kernel_sizes])\n","        conv2_channels  = hidden_channels * (len(kernel_sizes) + 1)\n","        self.conv2      = BaseConv(conv2_channels, out_channels, 1, stride=1, act=activation)\n","\n","    def forward(self, x):\n","        x = self.conv1(x) # Proses konvolusi pertama\n","        x = torch.cat([x] + [m(x) for m in self.m], dim=1) # Gabungkan hasil dari berbagai skala\n","        x = self.conv2(x) # Proses konvolusi kedua\n","        return x\n","\n","# Bottleneck biasa, digunakan untuk menyusun blok dalam model\n","class Bottleneck(nn.Module):\n","    # Standard bottleneck\n","    def __init__(self, in_channels, out_channels, shortcut=True, expansion=0.5, depthwise=False, act=\"silu\",):\n","        super().__init__()\n","        hidden_channels = int(out_channels * expansion)\n","        Conv = DWConv if depthwise else BaseConv # Pilih antara depthwise atau konvolusi biasa\n","\n","        self.conv1 = BaseConv(in_channels, hidden_channels, 1, stride=1, act=act) # Konvolusi pertama\n","\n","        self.conv2 = Conv(hidden_channels, out_channels, 3, stride=1, act=act) # Konvolusi kedua\n","        self.use_add = shortcut and in_channels == out_channels # Shortcut jika ukuran input dan output sama\n","\n","    def forward(self, x):\n","        y = self.conv2(self.conv1(x)) # Forward pass melalui kedua konvolusi\n","        if self.use_add:\n","            y = y + x # Menambahkan residual connection jika diperlukan\n","        return y\n","\n","# CSPLayer (Cross-Stage Partial Layer) untuk menggabungkan fitur dari beberapa tahap\n","class CSPLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels, n=1, shortcut=True, expansion=0.5, depthwise=False, act=\"silu\",):\n","        # ch_in, ch_out, number, shortcut, groups, expansion\n","        super().__init__()\n","        hidden_channels = int(out_channels * expansion)\n","\n","        self.conv1  = BaseConv(in_channels, hidden_channels, 1, stride=1, act=act)\n","\n","        self.conv2  = BaseConv(in_channels, hidden_channels, 1, stride=1, act=act)\n","\n","        self.conv3  = BaseConv(2 * hidden_channels, out_channels, 1, stride=1, act=act)\n","\n","        module_list = [Bottleneck(hidden_channels, hidden_channels, shortcut, 1.0, depthwise, act=act) for _ in range(n)]\n","        self.m      = nn.Sequential(*module_list)\n","\n","    def forward(self, x):\n","\n","        x_1 = self.conv1(x) # Hasil konvolusi pertama\n","\n","        x_2 = self.conv2(x) # Hasil konvolusi kedua\n","\n","\n","        x_1 = self.m(x_1) # Proses melalui blok bottleneck berturut-turut\n","\n","        x = torch.cat((x_1, x_2), dim=1) # Gabungkan hasil dari kedua bagian\n","\n","        return self.conv3(x) # Output akhir setelah konvolusi ketiga\n","\n","# Definisi arsitektur CSPDarknet\n","class CSPDarknet(nn.Module):\n","    def __init__(self, dep_mul, wid_mul, out_features=(\"dark3\", \"dark4\", \"dark5\"), depthwise=False, act=\"silu\",):\n","        super().__init__()\n","        assert out_features, \"please provide output features of Darknet\"\n","        self.out_features = out_features\n","        Conv = DWConv if depthwise else BaseConv # Pilih jenis konvolusi\n","\n","        base_channels   = int(wid_mul * 64)  # 64 # Jumlah saluran dasar\n","        base_depth      = max(round(dep_mul * 3), 1)  # 3 # Kedalaman jaringan dasar\n","\n","        # Fokus pada input untuk mengekstrak fitur\n","        self.stem = Focus(3, base_channels, ksize=3, act=act)\n","\n","        # Lapisan dark2\n","        self.dark2 = nn.Sequential(\n","            Conv(base_channels, base_channels * 2, 3, 2, act=act), # Konvolusi 3x3 dengan stride 2\n","            CSPLayer(base_channels * 2, base_channels * 2, n=base_depth, depthwise=depthwise, act=act),\n","        )\n","\n","        # Lapisan dark3\n","        self.dark3 = nn.Sequential(\n","            Conv(base_channels * 2, base_channels * 4, 3, 2, act=act),\n","            CSPLayer(base_channels * 4, base_channels * 4, n=base_depth * 3, depthwise=depthwise, act=act),\n","        )\n","\n","        # Lapisan dark4\n","        self.dark4 = nn.Sequential(\n","            Conv(base_channels * 4, base_channels * 8, 3, 2, act=act),\n","            CSPLayer(base_channels * 8, base_channels * 8, n=base_depth * 3, depthwise=depthwise, act=act),\n","        )\n","\n","        # Lapisan dark5\n","        self.dark5 = nn.Sequential(\n","            Conv(base_channels * 8, base_channels * 16, 3, 2, act=act),\n","            SPPBottleneck(base_channels * 16, base_channels * 16, activation=act),\n","            CSPLayer(base_channels * 16, base_channels * 16, n=base_depth, shortcut=False, depthwise=depthwise, act=act),\n","        )\n","\n","    def forward(self, x):\n","        outputs = {}\n","        x = self.stem(x) # Proses awal dengan Focus layer\n","        outputs[\"stem\"] = x\n","\n","        x = self.dark2(x) # Proses melalui lapisan dark2\n","        outputs[\"dark2\"] = x\n","\n","        x = self.dark3(x) # Proses melalui lapisan dark3\n","        outputs[\"dark3\"] = x\n","\n","        x = self.dark4(x) # Proses melalui lapisan dark4\n","        outputs[\"dark4\"] = x\n","\n","        x = self.dark5(x) # Proses melalui lapisan dark5\n","        outputs[\"dark5\"] = x\n","        return {k: v for k, v in outputs.items() if k in self.out_features}\n","\n","# Jika dijalankan sebagai skrip utama, akan mencetak arsitektur CSPDarknet\n","if __name__ == '__main__':\n","    print(CSPDarknet(1, 1))"]},{"cell_type":"markdown","metadata":{"id":"8mfduYHGvQDv"},"source":["### **yolo**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_RsXCNDvTaV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","# from darknet import BaseConv, CSPDarknet, CSPLayer, DWConv\n","\n","# Definisi YOLOXHead: kelas ini berfungsi untuk mendefinisikan kepala (head) dari model YOLOX.\n","class YOLOXHead(nn.Module):\n","    def __init__(self, num_classes, width = 1.0, in_channels = [256, 512, 1024], act = \"silu\", depthwise = False,):\n","        super().__init__()\n","        # Memilih jenis convolution, apakah depthwise atau biasa\n","        Conv            = DWConv if depthwise else BaseConv\n","\n","        # Menyiapkan layer untuk klasifikasi, prediksi koordinat (bounding box), dan prediksi objek\n","        self.cls_convs  = nn.ModuleList()\n","        self.reg_convs  = nn.ModuleList()\n","        self.cls_preds  = nn.ModuleList()\n","        self.reg_preds  = nn.ModuleList()\n","        self.obj_preds  = nn.ModuleList()\n","        self.stems      = nn.ModuleList()\n","\n","        # Iterasi untuk setiap channel input dan membangun jaringan\n","        for i in range(len(in_channels)):\n","            self.stems.append(BaseConv(in_channels = int(in_channels[i] * width), out_channels = int(256 * width), ksize = 1, stride = 1, act = act))\n","             # Layer konvolusi untuk klasifikasi objek (cls)\n","            self.cls_convs.append(nn.Sequential(*[\n","                Conv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act = act),\n","                Conv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act = act),\n","            ]))\n","\n","            # Prediksi kelas (jumlah kelas objek)\n","            self.cls_preds.append(\n","                nn.Conv2d(in_channels = int(256 * width), out_channels = num_classes, kernel_size = 1, stride = 1, padding = 0)\n","            )\n","\n","            # Layer konvolusi untuk regresi (koordinat bounding box)\n","            self.reg_convs.append(nn.Sequential(*[\n","                Conv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act = act),\n","                Conv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act = act)\n","            ]))\n","\n","            # Prediksi koordinat (bounding box)\n","            self.reg_preds.append(\n","                nn.Conv2d(in_channels = int(256 * width), out_channels = 4, kernel_size = 1, stride = 1, padding = 0)\n","            )\n","\n","            # Prediksi keberadaan objek\n","            self.obj_preds.append(\n","                nn.Conv2d(in_channels = int(256 * width), out_channels = 1, kernel_size = 1, stride = 1, padding = 0)\n","            )\n","\n","    def forward(self, inputs):\n","        # Output berupa hasil dari setiap fitur input\n","        outputs = []\n","        for k, x in enumerate(inputs):\n","            # Melalui stem untuk mendapatkan representasi awal\n","            x       = self.stems[k](x)\n","\n","            # Mendapatkan fitur klasifikasi\n","            cls_feat    = self.cls_convs[k](x)\n","            cls_output  = self.cls_preds[k](cls_feat)\n","\n","            # Mendapatkan fitur regresi\n","            reg_feat    = self.reg_convs[k](x)\n","            reg_output  = self.reg_preds[k](reg_feat)\n","\n","            # Prediksi objek (apakah objek ada atau tidak)\n","            obj_output  = self.obj_preds[k](reg_feat)\n","\n","            # Menggabungkan hasil regresi, objek, dan klasifikasi\n","            output      = torch.cat([reg_output, obj_output, cls_output], 1)\n","            outputs.append(output)\n","        return outputs\n","\n","# Definisi YOLOPAFPN: kelas ini adalah backbone dari YOLOX menggunakan arsitektur PAFPN (Path Aggregation Network)\n","class YOLOPAFPN(nn.Module):\n","    def __init__(self, depth = 1.0, width = 1.0, in_features = (\"dark3\", \"dark4\", \"dark5\"), in_channels = [256, 512, 1024], depthwise = False, act = \"silu\"):\n","        super().__init__()\n","\n","        # Memilih jenis convolution: depthwise atau biasa\n","        Conv                = DWConv if depthwise else BaseConv\n","\n","        # Backbone menggunakan arsitektur CSPDarknet\n","        self.backbone       = CSPDarknet(depth, width, depthwise = depthwise, act = act)\n","        self.in_features    = in_features\n","\n","        # Upsample untuk meningkatkan resolusi fitur\n","        self.upsample       = nn.Upsample(scale_factor=2, mode=\"nearest\")\n","\n","        #-------------------------------------------#\n","        #   20, 20, 1024 -> 20, 20, 512\n","        #-------------------------------------------#\n","        # Layer lateral untuk mengubah ukuran channel dan menghubungkan fitur dari berbagai level\n","        self.lateral_conv0  = BaseConv(int(in_channels[2] * width), int(in_channels[1] * width), 1, 1, act=act)\n","\n","        # CSPLayer untuk agregasi fitur pada berbagai resolusi\n","        #-------------------------------------------#\n","        #   40, 40, 1024 -> 40, 40, 512\n","        #-------------------------------------------#\n","        self.C3_p4 = CSPLayer(\n","            int(2 * in_channels[1] * width),\n","            int(in_channels[1] * width),\n","            round(3 * depth),\n","            False,\n","            depthwise = depthwise,\n","            act = act,\n","        )\n","\n","        # Mengurangi channel untuk level lebih rendah\n","        #-------------------------------------------#\n","        #   40, 40, 512 -> 40, 40, 256\n","        #-------------------------------------------#\n","        self.reduce_conv1   = BaseConv(int(in_channels[1] * width), int(in_channels[0] * width), 1, 1, act=act)\n","        #-------------------------------------------#\n","        #   80, 80, 512 -> 80, 80, 256\n","        #-------------------------------------------#\n","        # CSPLayer untuk agregasi pada level yang lebih rendah\n","        self.C3_p3 = CSPLayer(\n","            int(2 * in_channels[0] * width),\n","            int(in_channels[0] * width),\n","            round(3 * depth),\n","            False,\n","            depthwise = depthwise,\n","            act = act,\n","        )\n","\n","        #-------------------------------------------#\n","        #   80, 80, 256 -> 40, 40, 256\n","        #-------------------------------------------#\n","        self.bu_conv2       = Conv(int(in_channels[0] * width), int(in_channels[0] * width), 3, 2, act=act)\n","        #-------------------------------------------#\n","        #   40, 40, 256 -> 40, 40, 512\n","        #-------------------------------------------#\n","        # CSPLayer pada level yang lebih tinggi\n","        self.C3_n3 = CSPLayer(\n","            int(2 * in_channels[0] * width),\n","            int(in_channels[1] * width),\n","            round(3 * depth),\n","            False,\n","            depthwise = depthwise,\n","            act = act,\n","        )\n","\n","        #-------------------------------------------#\n","        #   40, 40, 512 -> 20, 20, 512\n","        #-------------------------------------------#\n","        self.bu_conv1       = Conv(int(in_channels[1] * width), int(in_channels[1] * width), 3, 2, act=act)\n","        #-------------------------------------------#\n","        #   20, 20, 1024 -> 20, 20, 1024\n","        #-------------------------------------------#\n","        # CSPLayer untuk level tertinggi\n","        self.C3_n4 = CSPLayer(\n","            int(2 * in_channels[1] * width),\n","            int(in_channels[2] * width),\n","            round(3 * depth),\n","            False,\n","            depthwise = depthwise,\n","            act = act,\n","        )\n","\n","    def forward(self, input):\n","        # Mengambil fitur dari backbone\n","        out_features            = self.backbone.forward(input)\n","        [feat1, feat2, feat3]   = [out_features[f] for f in self.in_features]\n","\n","        # Proses pengolahan fitur dari berbagai resolusi dan level\n","\n","        #-------------------------------------------#\n","        #   20, 20, 1024 -> 20, 20, 512\n","        #-------------------------------------------#\n","        P5          = self.lateral_conv0(feat3)\n","        #-------------------------------------------#\n","        #  20, 20, 512 -> 40, 40, 512\n","        #-------------------------------------------#\n","        P5_upsample = self.upsample(P5)\n","        #-------------------------------------------#\n","        #  40, 40, 512 + 40, 40, 512 -> 40, 40, 1024\n","        #-------------------------------------------#\n","        P5_upsample = torch.cat([P5_upsample, feat2], 1)\n","        #-------------------------------------------#\n","        #   40, 40, 1024 -> 40, 40, 512\n","        #-------------------------------------------#\n","        P5_upsample = self.C3_p4(P5_upsample)\n","\n","        #-------------------------------------------#\n","        #   40, 40, 512 -> 40, 40, 256\n","        #-------------------------------------------#\n","        P4          = self.reduce_conv1(P5_upsample)\n","        #-------------------------------------------#\n","        #   40, 40, 256 -> 80, 80, 256\n","        #-------------------------------------------#\n","        P4_upsample = self.upsample(P4)\n","        #-------------------------------------------#\n","        #   80, 80, 256 + 80, 80, 256 -> 80, 80, 512\n","        #-------------------------------------------#\n","        P4_upsample = torch.cat([P4_upsample, feat1], 1)\n","        #-------------------------------------------#\n","        #   80, 80, 512 -> 80, 80, 256\n","        #-------------------------------------------#\n","        P3_out      = self.C3_p3(P4_upsample)\n","\n","        #-------------------------------------------#\n","        #   80, 80, 256 -> 40, 40, 256\n","        #-------------------------------------------#\n","        P3_downsample   = self.bu_conv2(P3_out)\n","        #-------------------------------------------#\n","        #   40, 40, 256 + 40, 40, 256 -> 40, 40, 512\n","        #-------------------------------------------#\n","        P3_downsample   = torch.cat([P3_downsample, P4], 1)\n","        #-------------------------------------------#\n","        #   40, 40, 256 -> 40, 40, 512\n","        #-------------------------------------------#\n","        P4_out          = self.C3_n3(P3_downsample)\n","\n","        #-------------------------------------------#\n","        #   40, 40, 512 -> 20, 20, 512\n","        #-------------------------------------------#\n","        P4_downsample   = self.bu_conv1(P4_out)\n","        #-------------------------------------------#\n","        #   20, 20, 512 + 20, 20, 512 -> 20, 20, 1024\n","        #-------------------------------------------#\n","        P4_downsample   = torch.cat([P4_downsample, P5], 1)\n","        #-------------------------------------------#\n","        #   20, 20, 1024 -> 20, 20, 1024\n","        #-------------------------------------------#\n","        P5_out          = self.C3_n4(P4_downsample)\n","\n","        # Mengembalikan hasil fitur dari 3 level\n","        return (P3_out, P4_out, P5_out)\n","\n","# Definisi YoloBody: kelas utama yang menyatukan backbone dan kepala model\n","class YoloBody(nn.Module):\n","    def __init__(self, num_classes, phi):\n","        super().__init__()\n","\n","        # Parameter phi untuk menentukan ukuran model (nano, tiny, s, m, l, x)\n","        depth_dict = {'nano': 0.33, 'tiny': 0.33, 's' : 0.33, 'm' : 0.67, 'l' : 1.00, 'x' : 1.33,}\n","        width_dict = {'nano': 0.25, 'tiny': 0.375, 's' : 0.50, 'm' : 0.75, 'l' : 1.00, 'x' : 1.25,}\n","\n","        # Mengatur kedalaman dan lebar berdasarkan phi\n","        depth, width    = depth_dict[phi], width_dict[phi]\n","        depthwise       = True if phi == 'nano' else False\n","\n","        # Membuat backbone dan head model YOLOX\n","        self.backbone   = YOLOPAFPN(depth, width, depthwise=depthwise)\n","        self.head       = YOLOXHead(num_classes, width, depthwise=depthwise)\n","\n","    def forward(self, x):\n","        # Mendapatkan fitur dari backbone dan output dari kepala (head)\n","        fpn_outs    = self.backbone.forward(x)\n","        outputs     = self.head.forward(fpn_outs)\n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"QYtefJ35vRBN"},"source":["### **yolo_training**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUe3TSvsAeg4"},"outputs":[],"source":["import math\n","from copy import deepcopy\n","from functools import partial\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Kelas untuk menghitung IOU (Intersection over Union) loss\n","class IOUloss(nn.Module):\n","    def __init__(self, reduction=\"none\", loss_type=\"iou\"):\n","        super(IOUloss, self).__init__()\n","        self.reduction = reduction # Metode reduksi loss: \"mean\", \"sum\", atau \"none\"\n","        self.loss_type = loss_type # Jenis IOU loss: \"iou\" atau \"giou\"\n","\n","    def forward(self, pred, target):\n","        # Prediksi dan target berbentuk tensor [N, 4] (N = jumlah bounding box)\n","        assert pred.shape[0] == target.shape[0]\n","\n","        # Mengubah bounding box menjadi format [x_center, y_center, width, height]\n","        pred = pred.view(-1, 4)\n","        target = target.view(-1, 4)\n","        # Menghitung sudut atas kiri dan sudut bawah kanan dari IOU\n","        tl = torch.max(\n","            (pred[:, :2] - pred[:, 2:] / 2), (target[:, :2] - target[:, 2:] / 2)\n","        )\n","        br = torch.min(\n","            (pred[:, :2] + pred[:, 2:] / 2), (target[:, :2] + target[:, 2:] / 2)\n","        )\n","\n","        # Luas dari prediksi dan target\n","        area_p = torch.prod(pred[:, 2:], 1)\n","        area_g = torch.prod(target[:, 2:], 1)\n","\n","        # Luas intersection dan union\n","        en = (tl < br).type(tl.type()).prod(dim=1) # Memastikan bahwa kotak overlap\n","        area_i = torch.prod(br - tl, 1) * en\n","        area_u = area_p + area_g - area_i\n","        iou = (area_i) / (area_u + 1e-16) # IOU = intersection / union\n","\n","        # IOU atau GIOU loss\n","        if self.loss_type == \"iou\":\n","            loss = 1 - iou ** 2 # Menggunakan IOU kuadrat\n","        elif self.loss_type == \"giou\":\n","            # Menghitung GIOU loss\n","            c_tl = torch.min((pred[:, :2] - pred[:, 2:] / 2), (target[:, :2] - target[:, 2:] / 2))\n","            c_br = torch.max((pred[:, :2] + pred[:, 2:] / 2), (target[:, :2] + target[:, 2:] / 2))\n","            area_c = torch.prod(c_br - c_tl, 1) # Luas dari kotak terluar\n","            giou = iou - (area_c - area_u) / area_c.clamp(1e-16)\n","            loss = 1 - giou.clamp(min=-1.0, max=1.0)\n","        # Reduksi hasil loss\n","        if self.reduction == \"mean\":\n","            loss = loss.mean()\n","        elif self.reduction == \"sum\":\n","            loss = loss.sum()\n","\n","        return loss # Mengembalikan nilai loss\n","\n","################################# YOLO LOSS ################################\n","\n","# Kelas utama YOLO untuk perhitungan loss dalam object detection\n","class YOLOLoss(nn.Module):\n","    def __init__(self, num_classes, fp16, strides=[8, 16, 32]):\n","        super().__init__()\n","        self.num_classes        = num_classes # Jumlah kelas yang akan dideteksi\n","        self.strides            = strides # Ukuran stride untuk setiap FPN level\n","\n","        # Loss BCE untuk klasifikasi dan IOU untuk regression\n","        self.bcewithlog_loss    = nn.BCEWithLogitsLoss(reduction=\"none\")\n","        self.iou_loss           = IOUloss(reduction=\"none\")\n","        self.grids              = [torch.zeros(1)] * len(strides) # Placeholder grid untuk deteksi\n","        self.fp16               = fp16 # Indikasi apakah model menggunakan float16\n","\n","    # Fungsi utama untuk menghitung loss\n","    def forward(self, inputs, labels=None):\n","        outputs             = [] # Menyimpan output dari setiap level FPN\n","        x_shifts            = [] # Offset grid sumbu X\n","        y_shifts            = [] # Offset grid sumbu Y\n","        expanded_strides    = [] # Stride yang diperbesar\n","\n","        #-----------------------------------------------#\n","        # inputs    [[batch_size, num_classes + 5, 20, 20]\n","        #            [batch_size, num_classes + 5, 40, 40]\n","        #            [batch_size, num_classes + 5, 80, 80]]\n","        # outputs   [[batch_size, 400, num_classes + 5]\n","        #            [batch_size, 1600, num_classes + 5]\n","        #            [batch_size, 6400, num_classes + 5]]\n","        # x_shifts  [[batch_size, 400]\n","        #            [batch_size, 1600]\n","        #            [batch_size, 6400]]\n","        #-----------------------------------------------#\n","\n","        # Mengiterasi setiap level FPN (inputs berupa list tensor dari berbagai level)\n","        for k, (stride, output) in enumerate(zip(self.strides, inputs)):\n","            output, grid = self.get_output_and_grid(output, k, stride)\n","            x_shifts.append(grid[:, :, 0])\n","            y_shifts.append(grid[:, :, 1])\n","            expanded_strides.append(torch.ones_like(grid[:, :, 0]) * stride)\n","            outputs.append(output)\n","        # Menggabungkan hasil dari semua level FPN untuk dihitung loss-nya\n","        return self.get_losses(x_shifts, y_shifts, expanded_strides, labels, torch.cat(outputs, 1))\n","\n","    def get_output_and_grid(self, output, k, stride):\n","        # Grid dari anchor pada FPN level k\n","        grid            = self.grids[k]\n","        hsize, wsize    = output.shape[-2:] # Dimensi grid (height, width)\n","\n","        # Jika ukuran grid belum sesuai dengan ukuran output\n","        if grid.shape[2:4] != output.shape[2:4]:\n","            # Membuat meshgrid (koordinat anchor) dengan dimensi height x width\n","            yv, xv          = torch.meshgrid([torch.arange(hsize), torch.arange(wsize)])\n","            grid            = torch.stack((xv, yv), 2).view(1, hsize, wsize, 2).type(output.type())\n","            self.grids[k]   = grid # Menyimpan grid untuk penggunaan berikutnya\n","        # Mengubah grid ke format tensor 1D untuk setiap anchor\n","        grid                = grid.view(1, -1, 2)\n","\n","        # Memproses output untuk setiap anchor\n","        output              = output.flatten(start_dim=2).permute(0, 2, 1) # [batch, anchors, channels]\n","        output[..., :2]     = (output[..., :2] + grid.type_as(output)) * stride # Koordinat x, y dalam skala asli\n","        output[..., 2:4]    = torch.exp(output[..., 2:4]) * stride # Skala width dan height\n","        return output, grid # Mengembalikan output yang diproses dan grid anchor\n","\n","    def get_losses(self, x_shifts, y_shifts, expanded_strides, labels, outputs):\n","        # Membagi outputs menjadi prediksi bounding box, objectness, dan kelas\n","        #-----------------------------------------------#\n","        #   [batch, n_anchors_all, 4] -> bounding box prediksi\n","        #-----------------------------------------------#\n","        bbox_preds  = outputs[:, :, :4]\n","        #-----------------------------------------------#\n","        #   [batch, n_anchors_all, 1] -> confidence score\n","        #-----------------------------------------------#\n","        obj_preds   = outputs[:, :, 4:5]\n","        #-----------------------------------------------#\n","        #   [batch, n_anchors_all, n_cls] -> prediksi kelas\n","        #-----------------------------------------------#\n","        cls_preds   = outputs[:, :, 5:]\n","        # Total anchor di semua level FPN\n","        total_num_anchors   = outputs.shape[1]\n","        #-----------------------------------------------#\n","        #   x_shifts            [1, n_anchors_all]\n","        #   y_shifts            [1, n_anchors_all]\n","        #   expanded_strides    [1, n_anchors_all]\n","        #-----------------------------------------------#\n","\n","        # Menggabungkan informasi grid dari semua FPN level\n","        x_shifts            = torch.cat(x_shifts, 1).type_as(outputs)\n","        y_shifts            = torch.cat(y_shifts, 1).type_as(outputs)\n","        expanded_strides    = torch.cat(expanded_strides, 1).type_as(outputs)\n","\n","        # Inisialisasi variabel target dan mask\n","        cls_targets = []\n","        reg_targets = []\n","        obj_targets = []\n","        fg_masks    = []\n","\n","        num_fg  = 0.0 # Counter foreground anchor\n","\n","        # Mengiterasi untuk setiap batch\n","        for batch_idx in range(outputs.shape[0]):\n","            num_gt          = len(labels[batch_idx]) # Jumlah ground truth untuk batch ini\n","\n","            # Jika tidak ada ground truth, buat tensor kosong\n","            if num_gt == 0:\n","                cls_target  = outputs.new_zeros((0, self.num_classes))\n","                reg_target  = outputs.new_zeros((0, 4))\n","                obj_target  = outputs.new_zeros((total_num_anchors, 1))\n","                fg_mask     = outputs.new_zeros(total_num_anchors).bool()\n","            else:\n","            # Memisahkan ground truth untuk bounding box dan kelas\n","                #-----------------------------------------------#\n","                #   gt_bboxes_per_image     [num_gt, num_classes]\n","                #   gt_classes              [num_gt]\n","                #   bboxes_preds_per_image  [n_anchors_all, 4]\n","                #   cls_preds_per_image     [n_anchors_all, num_classes]\n","                #   obj_preds_per_image     [n_anchors_all, 1]\n","                #-----------------------------------------------#\n","                gt_bboxes_per_image     = labels[batch_idx][..., :4].type_as(outputs) # [num_gt, 4]\n","                gt_classes              = labels[batch_idx][..., 4].type_as(outputs) # [num_gt]\n","                bboxes_preds_per_image  = bbox_preds[batch_idx] # Prediksi bbox untuk batch ini\n","                cls_preds_per_image     = cls_preds[batch_idx] # Prediksi kelas\n","                obj_preds_per_image     = obj_preds[batch_idx] # Prediksi objectness\n","\n","                # Proses assignment untuk mencocokkan anchor dan ground truth\n","                gt_matched_classes, fg_mask, pred_ious_this_matching, matched_gt_inds, num_fg_img = self.get_assignments(\n","                    num_gt, total_num_anchors, gt_bboxes_per_image, gt_classes, bboxes_preds_per_image, cls_preds_per_image, obj_preds_per_image,\n","                    expanded_strides, x_shifts, y_shifts,\n","                )\n","                torch.cuda.empty_cache() # Membersihkan cache GPU\n","\n","                # Menambahkan jumlah foreground anchor\n","                num_fg      += num_fg_img\n","                # Membuat target untuk kelas, objectness, dan bounding box\n","                cls_target  = F.one_hot(gt_matched_classes.to(torch.int64), self.num_classes).float() * pred_ious_this_matching.unsqueeze(-1)\n","                obj_target  = fg_mask.unsqueeze(-1) # Objectness target\n","                reg_target  = gt_bboxes_per_image[matched_gt_inds] # Target bounding box\n","\n","            # Menambahkan target ke list untuk batch ini\n","            cls_targets.append(cls_target)\n","            reg_targets.append(reg_target)\n","            obj_targets.append(obj_target.type(cls_target.type()))\n","            fg_masks.append(fg_mask)\n","\n","        # Menggabungkan semua target dari seluruh batch\n","        cls_targets = torch.cat(cls_targets, 0)\n","        reg_targets = torch.cat(reg_targets, 0)\n","        obj_targets = torch.cat(obj_targets, 0)\n","        fg_masks    = torch.cat(fg_masks, 0)\n","\n","        # Jika tidak ada foreground anchor, set num_fg ke 1 untuk menghindari pembagian nol\n","        num_fg      = max(num_fg, 1)\n","\n","         # Menghitung komponen loss\n","        loss_iou    = (self.iou_loss(bbox_preds.view(-1, 4)[fg_masks], reg_targets)).sum()\n","        loss_obj    = (self.bcewithlog_loss(obj_preds.view(-1, 1), obj_targets)).sum()\n","        loss_cls    = (self.bcewithlog_loss(cls_preds.view(-1, self.num_classes)[fg_masks], cls_targets)).sum()\n","\n","        reg_weight  = 5.0 # Bobot loss regresi\n","        loss = reg_weight * loss_iou + loss_obj + loss_cls\n","\n","        return loss / num_fg # Normalisasi dengan jumlah foreground anchor\n","\n","    @torch.no_grad()\n","\n","    def get_assignments(self, num_gt, total_num_anchors, gt_bboxes_per_image, gt_classes, bboxes_preds_per_image, cls_preds_per_image, obj_preds_per_image, expanded_strides, x_shifts, y_shifts):\n","        #-------------------------------------------------------#\n","        #   fg_mask                 [n_anchors_all]\n","        #   is_in_boxes_and_center  [num_gt, len(fg_mask)]\n","        #-------------------------------------------------------#\n","        fg_mask, is_in_boxes_and_center = self.get_in_boxes_info(gt_bboxes_per_image, expanded_strides, x_shifts, y_shifts, total_num_anchors, num_gt)\n","\n","        #-------------------------------------------------------#\n","        #   Memfilter prediksi berdasarkan fg_mask.\n","        #   fg_mask                 [n_anchors_all]\n","        #   bboxes_preds_per_image  [fg_mask, 4] - bboxes_preds_per_image: bounding box prediksi.\n","        #   cls_preds_              [fg_mask, num_classes] - cls_preds_: prediksi kelas.\n","        #   obj_preds_              [fg_mask, 1] - obj_preds_: prediksi confidence objectness.\n","        #-------------------------------------------------------#\n","        bboxes_preds_per_image  = bboxes_preds_per_image[fg_mask]\n","        cls_preds_              = cls_preds_per_image[fg_mask]\n","        obj_preds_              = obj_preds_per_image[fg_mask]\n","        num_in_boxes_anchor     = bboxes_preds_per_image.shape[0]\n","\n","        #-------------------------------------------------------#\n","        #   Menghitung IoU (Intersection over Union) antara\n","        #   bounding box ground truth dan prediksi.\n","        #   pair_wise_ious      [num_gt, fg_mask]\n","        #-------------------------------------------------------#\n","        pair_wise_ious      = self.bboxes_iou(gt_bboxes_per_image, bboxes_preds_per_image, False)\n","        pair_wise_ious_loss = -torch.log(pair_wise_ious + 1e-8)\n","\n","        #-------------------------------------------------------#\n","        #   cls_preds_          [num_gt, fg_mask, num_classes]\n","        #   gt_cls_per_image    [num_gt, fg_mask, num_classes]\n","        #   Menghitung pair-wise class loss.\n","        #   - cls_preds_: prediksi kelas setelah sigmoid.\n","        #   - gt_cls_per_image: representasi ground truth kelas\n","        #     dalam format one-hot.\n","        #-------------------------------------------------------#\n","        if self.fp16:\n","            with torch.cuda.amp.autocast(enabled=False):\n","                cls_preds_          = cls_preds_.float().unsqueeze(0).repeat(num_gt, 1, 1).sigmoid_() * obj_preds_.unsqueeze(0).repeat(num_gt, 1, 1).sigmoid_()\n","                gt_cls_per_image    = F.one_hot(gt_classes.to(torch.int64), self.num_classes).float().unsqueeze(1).repeat(1, num_in_boxes_anchor, 1)\n","                pair_wise_cls_loss  = F.binary_cross_entropy(cls_preds_.sqrt_(), gt_cls_per_image, reduction=\"none\").sum(-1)\n","        else:\n","            cls_preds_          = cls_preds_.float().unsqueeze(0).repeat(num_gt, 1, 1).sigmoid_() * obj_preds_.unsqueeze(0).repeat(num_gt, 1, 1).sigmoid_()\n","            gt_cls_per_image    = F.one_hot(gt_classes.to(torch.int64), self.num_classes).float().unsqueeze(1).repeat(1, num_in_boxes_anchor, 1)\n","            pair_wise_cls_loss  = F.binary_cross_entropy(cls_preds_.sqrt_(), gt_cls_per_image, reduction=\"none\").sum(-1)\n","            del cls_preds_\n","\n","        #-------------------------------------------------------#\n","        #   Menghitung total biaya (cost) untuk proses matching.\n","        #   Biaya dihitung dari kombinasi:\n","        #   - Loss prediksi kelas.\n","        #   - Loss IoU.\n","        #   - Anchor yang tidak berada di dalam area dipenalti.\n","        #-------------------------------------------------------#\n","        cost = pair_wise_cls_loss + 3.0 * pair_wise_ious_loss + 100000.0 * (~is_in_boxes_and_center).float()\n","\n","        #-------------------------------------------------------#\n","        #   Melakukan dynamic k-matching untuk menentukan\n","        #   assignment antara ground truth dan prediksi.\n","        #-------------------------------------------------------#\n","        num_fg, gt_matched_classes, pred_ious_this_matching, matched_gt_inds = self.dynamic_k_matching(cost, pair_wise_ious, gt_classes, num_gt, fg_mask)\n","        del pair_wise_cls_loss, cost, pair_wise_ious, pair_wise_ious_loss\n","        return gt_matched_classes, fg_mask, pred_ious_this_matching, matched_gt_inds, num_fg\n","\n","    def bboxes_iou(self, bboxes_a, bboxes_b, xyxy=True):\n","        # Menghitung IoU antara dua set bounding box.\n","        if bboxes_a.shape[1] != 4 or bboxes_b.shape[1] != 4:\n","            raise IndexError\n","\n","        if xyxy:\n","             # Koordinat bounding box dalam format (x1, y1, x2, y2).\n","            tl = torch.max(bboxes_a[:, None, :2], bboxes_b[:, :2]) # Titik kiri atas\n","            br = torch.min(bboxes_a[:, None, 2:], bboxes_b[:, 2:]) # Titik kanan bawah\n","            area_a = torch.prod(bboxes_a[:, 2:] - bboxes_a[:, :2], 1)\n","            area_b = torch.prod(bboxes_b[:, 2:] - bboxes_b[:, :2], 1)\n","        else:\n","            # Koordinat bounding box dalam format (cx, cy, w, h).\n","            tl = torch.max(\n","                (bboxes_a[:, None, :2] - bboxes_a[:, None, 2:] / 2),\n","                (bboxes_b[:, :2] - bboxes_b[:, 2:] / 2),\n","            )\n","            br = torch.min(\n","                (bboxes_a[:, None, :2] + bboxes_a[:, None, 2:] / 2),\n","                (bboxes_b[:, :2] + bboxes_b[:, 2:] / 2),\n","            )\n","\n","            area_a = torch.prod(bboxes_a[:, 2:], 1)\n","            area_b = torch.prod(bboxes_b[:, 2:], 1)\n","        en = (tl < br).type(tl.type()).prod(dim=2) # Validitas overlap\n","        area_i = torch.prod(br - tl, 2) * en # Area overlap\n","        return area_i / (area_a[:, None] + area_b - area_i) # Rasio IoU\n","\n","    def get_in_boxes_info(self, gt_bboxes_per_image, expanded_strides, x_shifts, y_shifts, total_num_anchors, num_gt, center_radius = 2.5):\n","        #-------------------------------------------------------#\n","        #   Menghitung pusat anchor berdasarkan stride.\n","        #   expanded_strides_per_image  [n_anchors_all]\n","        #   x_centers_per_image         [num_gt, n_anchors_all]\n","        #   x_centers_per_image         [num_gt, n_anchors_all]\n","        #-------------------------------------------------------#\n","        expanded_strides_per_image  = expanded_strides[0]\n","        x_centers_per_image         = ((x_shifts[0] + 0.5) * expanded_strides_per_image).unsqueeze(0).repeat(num_gt, 1)\n","        y_centers_per_image         = ((y_shifts[0] + 0.5) * expanded_strides_per_image).unsqueeze(0).repeat(num_gt, 1)\n","\n","        #-------------------------------------------------------#\n","        #   Mendefinisikan bounding box ground truth.\n","        #   gt_bboxes_per_image_x       [num_gt, n_anchors_all]\n","        #-------------------------------------------------------#\n","        gt_bboxes_per_image_l = (gt_bboxes_per_image[:, 0] - 0.5 * gt_bboxes_per_image[:, 2]).unsqueeze(1).repeat(1, total_num_anchors)\n","        gt_bboxes_per_image_r = (gt_bboxes_per_image[:, 0] + 0.5 * gt_bboxes_per_image[:, 2]).unsqueeze(1).repeat(1, total_num_anchors)\n","        gt_bboxes_per_image_t = (gt_bboxes_per_image[:, 1] - 0.5 * gt_bboxes_per_image[:, 3]).unsqueeze(1).repeat(1, total_num_anchors)\n","        gt_bboxes_per_image_b = (gt_bboxes_per_image[:, 1] + 0.5 * gt_bboxes_per_image[:, 3]).unsqueeze(1).repeat(1, total_num_anchors)\n","\n","        #-------------------------------------------------------#\n","        #   Menghitung jarak anchor ke bounding box.\n","        #   bbox_deltas     [num_gt, n_anchors_all, 4]\n","        #-------------------------------------------------------#\n","        b_l = x_centers_per_image - gt_bboxes_per_image_l\n","        b_r = gt_bboxes_per_image_r - x_centers_per_image\n","        b_t = y_centers_per_image - gt_bboxes_per_image_t\n","        b_b = gt_bboxes_per_image_b - y_centers_per_image\n","        bbox_deltas = torch.stack([b_l, b_t, b_r, b_b], 2)\n","\n","        #-------------------------------------------------------#\n","        #   Memeriksa apakah anchor berada di dalam bounding box.\n","        #   is_in_boxes     [num_gt, n_anchors_all]\n","        #   is_in_boxes_all [n_anchors_all]\n","        #-------------------------------------------------------#\n","        is_in_boxes     = bbox_deltas.min(dim=-1).values > 0.0\n","        is_in_boxes_all = is_in_boxes.sum(dim=0) > 0\n","\n","        gt_bboxes_per_image_l = (gt_bboxes_per_image[:, 0]).unsqueeze(1).repeat(1, total_num_anchors) - center_radius * expanded_strides_per_image.unsqueeze(0)\n","        gt_bboxes_per_image_r = (gt_bboxes_per_image[:, 0]).unsqueeze(1).repeat(1, total_num_anchors) + center_radius * expanded_strides_per_image.unsqueeze(0)\n","        gt_bboxes_per_image_t = (gt_bboxes_per_image[:, 1]).unsqueeze(1).repeat(1, total_num_anchors) - center_radius * expanded_strides_per_image.unsqueeze(0)\n","        gt_bboxes_per_image_b = (gt_bboxes_per_image[:, 1]).unsqueeze(1).repeat(1, total_num_anchors) + center_radius * expanded_strides_per_image.unsqueeze(0)\n","\n","        #-------------------------------------------------------#\n","        #   Mendefinisikan area pusat bounding box.\n","        #   center_deltas   [num_gt, n_anchors_all, 4]\n","        #-------------------------------------------------------#\n","        c_l = x_centers_per_image - gt_bboxes_per_image_l\n","        c_r = gt_bboxes_per_image_r - x_centers_per_image\n","        c_t = y_centers_per_image - gt_bboxes_per_image_t\n","        c_b = gt_bboxes_per_image_b - y_centers_per_image\n","        center_deltas       = torch.stack([c_l, c_t, c_r, c_b], 2)\n","\n","        #-------------------------------------------------------#\n","        #   Memeriksa apakah anchor berada di pusat bounding box.\n","        #   is_in_centers       [num_gt, n_anchors_all]\n","        #   is_in_centers_all   [n_anchors_all]\n","        #-------------------------------------------------------#\n","        is_in_centers       = center_deltas.min(dim=-1).values > 0.0\n","        is_in_centers_all   = is_in_centers.sum(dim=0) > 0\n","\n","        #-------------------------------------------------------#\n","        #   Menggabungkan informasi apakah anchor berada di dalam bounding box atau area pusatnya.\n","        #   is_in_boxes_anchor      [n_anchors_all]\n","        #   is_in_boxes_and_center  [num_gt, is_in_boxes_anchor]\n","        #-------------------------------------------------------#\n","        is_in_boxes_anchor      = is_in_boxes_all | is_in_centers_all\n","        is_in_boxes_and_center  = is_in_boxes[:, is_in_boxes_anchor] & is_in_centers[:, is_in_boxes_anchor]\n","        return is_in_boxes_anchor, is_in_boxes_and_center\n","\n","    def dynamic_k_matching(self, cost, pair_wise_ious, gt_classes, num_gt, fg_mask):\n","        #-------------------------------------------------------#\n","        #   cost                : [num_gt, fg_mask] - Biaya antara GT dan anchor\n","        #   pair_wise_ious      : [num_gt, fg_mask] - IoU antara GT dan anchor\n","        #   gt_classes          : [num_gt]          - Kelas ground truth\n","        #   fg_mask             : [n_anchors_all]   - Mask untuk anchor foreground\n","        #   matching_matrix     : [num_gt, fg_mask] - Matriks pencocokan\n","        #-------------------------------------------------------#\n","        matching_matrix         = torch.zeros_like(cost)\n","\n","        #-------------------------------------------------------#\n","        #   Menghitung jumlah kandidat anchor berdasarkan IoU.\n","        #   Top-k IoU dihitung untuk setiap ground truth.\n","        #-------------------------------------------------------#\n","        n_candidate_k           = min(10, pair_wise_ious.size(1))\n","        topk_ious, _            = torch.topk(pair_wise_ious, n_candidate_k, dim=1)\n","        dynamic_ks              = torch.clamp(topk_ious.sum(1).int(), min=1)\n","\n","        #-------------------------------------------------------#\n","        #   Pilih anchor terbaik untuk setiap ground truth\n","        #   berdasarkan nilai cost yang terendah.\n","        #-------------------------------------------------------#\n","        for gt_idx in range(num_gt):\n","            _, pos_idx = torch.topk(cost[gt_idx], k=dynamic_ks[gt_idx].item(), largest=False)\n","            matching_matrix[gt_idx][pos_idx] = 1.0\n","        del topk_ious, dynamic_ks, pos_idx\n","\n","        #-------------------------------------------------------#\n","        #   Jika ada anchor yang cocok dengan lebih dari satu GT,\n","        #   pilih GT dengan biaya terendah untuk anchor tersebut.\n","        #-------------------------------------------------------#\n","        anchor_matching_gt = matching_matrix.sum(0)\n","        if (anchor_matching_gt > 1).sum() > 0: # Kasus banyak GT untuk satu anchor\n","\n","            _, cost_argmin = torch.min(cost[:, anchor_matching_gt > 1], dim=0)\n","            matching_matrix[:, anchor_matching_gt > 1] *= 0.0 # Hapus pencocokan lama\n","            matching_matrix[cost_argmin, anchor_matching_gt > 1] = 1.0\n","\n","        #-------------------------------------------------------#\n","        #   Hitung anchor yang benar-benar digunakan sebagai\n","        #   foreground (fg_mask_inboxes).\n","        #-------------------------------------------------------#\n","        fg_mask_inboxes = matching_matrix.sum(0) > 0.0\n","        num_fg          = fg_mask_inboxes.sum().item()\n","\n","        # Update fg_mask dengan fg_mask_inboxes\n","        fg_mask[fg_mask.clone()] = fg_mask_inboxes\n","\n","        #-------------------------------------------------------#\n","        #   Mendapatkan indeks GT yang cocok dengan setiap anchor,\n","        #   kelas GT, dan IoU untuk anchor yang terpilih.\n","        #-------------------------------------------------------#\n","        matched_gt_inds     = matching_matrix[:, fg_mask_inboxes].argmax(0)\n","        gt_matched_classes  = gt_classes[matched_gt_inds]\n","\n","        pred_ious_this_matching = (matching_matrix * pair_wise_ious).sum(0)[fg_mask_inboxes]\n","        return num_fg, gt_matched_classes, pred_ious_this_matching, matched_gt_inds\n","\n","def is_parallel(model):\n","    # Mengembalikan True jika model adalah tipe DataParallel atau DistributedDataParallel (berjalan di beberapa GPU).\n","    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\n","\n","def de_parallel(model):\n","    #-------------------------------------------------------#\n","    #   Mengembalikan model tanpa parallelism:\n","    #   - Jika model tipe DP atau DDP, ambil atribut 'module'.\n","    #   - Jika bukan tipe DP atau DDP, kembalikan model apa adanya.\n","    #-------------------------------------------------------#\n","    return model.module if is_parallel(model) else model\n","\n","def copy_attr(a, b, include=(), exclude=()):\n","    #-------------------------------------------------------#\n","    #   Menyalin atribut dari objek `b` ke `a`.\n","    #   - `include`: Hanya atribut tertentu yang disalin.\n","    #   - `exclude`: Daftar atribut yang tidak disalin.\n","    #   - Atribut yang diawali '_' juga tidak disalin.\n","    #-------------------------------------------------------#\n","    for k, v in b.__dict__.items():\n","        if (len(include) and k not in include) or k.startswith('_') or k in exclude:\n","            continue\n","        else:\n","            setattr(a, k, v)\n","\n","\n","########################################## CLASS EMA ###################################################\n","\n","class ModelEMA:\n","    \"\"\" Updated Exponential Moving Average (EMA) from https://github.com/rwightman/pytorch-image-models\n","    Keeps a moving average of everything in the model state_dict (parameters and buffers)\n","    For EMA details see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n","    \"\"\"\n","\n","    def __init__(self, model, decay=0.9999, tau=2000, updates=0):\n","        # Create EMA\n","        self.ema = deepcopy(de_parallel(model)).eval()  # FP32 EMA\n","        # if next(model.parameters()).device.type != 'cpu':\n","        #     self.ema.half()  # FP16 EMA\n","        self.updates = updates  # number of EMA updates\n","        self.decay = lambda x: decay * (1 - math.exp(-x / tau))  # decay exponential ramp (to help early epochs)\n","        for p in self.ema.parameters():\n","            p.requires_grad_(False)\n","\n","    def update(self, model):\n","        # Update EMA parameters\n","        with torch.no_grad():\n","            self.updates += 1\n","            d = self.decay(self.updates)\n","\n","            msd = de_parallel(model).state_dict()  # model state_dict\n","            for k, v in self.ema.state_dict().items():\n","                if v.dtype.is_floating_point:\n","                    v *= d\n","                    v += (1 - d) * msd[k].detach()\n","\n","    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):\n","        # Update EMA attributes\n","        copy_attr(self.ema, model, include, exclude)\n","\n","def weights_init(net, init_type='normal', init_gain = 0.02):\n","    # Fungsi inisialisasi bobot jaringan\n","    def init_func(m):\n","        classname = m.__class__.__name__\n","        # Inisialisasi hanya untuk layer dengan atribut 'weight' (misal: Convolutional Layer)\n","        if hasattr(m, 'weight') and classname.find('Conv') != -1:\n","            if init_type == 'normal':\n","                torch.nn.init.normal_(m.weight.data, 0.0, init_gain)\n","            elif init_type == 'xavier':\n","                torch.nn.init.xavier_normal_(m.weight.data, gain=init_gain)\n","            elif init_type == 'kaiming':\n","                torch.nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","            elif init_type == 'orthogonal':\n","                torch.nn.init.orthogonal_(m.weight.data, gain=init_gain)\n","            else:\n","                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n","        # Inisialisasi layer BatchNorm2d\n","        elif classname.find('BatchNorm2d') != -1:\n","            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","            torch.nn.init.constant_(m.bias.data, 0.0)\n","    print('initialize network with %s type' % init_type)\n","    net.apply(init_func)\n","\n","# Scheduler learning rate dengan dua metode: Cosine Decay dan Step Decay\n","def get_lr_scheduler(lr_decay_type, lr, min_lr, total_iters, warmup_iters_ratio = 0.05, warmup_lr_ratio = 0.1, no_aug_iter_ratio = 0.05, step_num = 10):\n","    \"\"\"\n","    Fungsi untuk mendapatkan fungsi scheduler learning rate (LR).\n","\n","    Parameter:\n","    - lr_decay_type: Tipe decay LR (cosine decay atau step decay).\n","    - lr: Learning rate awal.\n","    - min_lr: Learning rate minimum.\n","    - total_iters: Total jumlah iterasi.\n","    - warmup_iters_ratio: Rasio warmup terhadap total iterasi.\n","    - warmup_lr_ratio: Rasio LR selama warmup terhadap LR awal.\n","    - no_aug_iter_ratio: Rasio iterasi tanpa augmentasi terhadap total iterasi.\n","    - step_num: Jumlah langkah penurunan untuk step decay.\n","\n","    Returns:\n","    - func: Fungsi scheduler LR.\n","    \"\"\"\n","\n","    # Scheduler dengan Warmup dan Cosine Decay\n","    def yolox_warm_cos_lr(lr, min_lr, total_iters, warmup_total_iters, warmup_lr_start, no_aug_iter, iters):\n","        # Jika iterasi dalam fase warmup\n","        if iters <= warmup_total_iters:\n","            # lr = (lr - warmup_lr_start) * iters / float(warmup_total_iters) + warmup_lr_start\n","            # LR naik dari warmup_lr_start ke lr menggunakan kuadrat\n","            lr = (lr - warmup_lr_start) * pow(iters / float(warmup_total_iters), 2) + warmup_lr_start\n","        # Jika iterasi dalam fase no augmentation\n","        elif iters >= total_iters - no_aug_iter:\n","            # Tetapkan LR ke nilai minimum\n","            lr = min_lr\n","        else:\n","            # LR mengikuti kurva cosine decay\n","            lr = min_lr + 0.5 * (lr - min_lr) * (\n","                1.0 + math.cos(math.pi* (iters - warmup_total_iters) / (total_iters - warmup_total_iters - no_aug_iter))\n","            )\n","        return lr\n","\n","    # Scheduler dengan Step Decay\n","    def step_lr(lr, decay_rate, step_size, iters):\n","        # Pastikan ukuran langkah valid\n","        if step_size < 1:\n","            raise ValueError(\"step_size must above 1.\")\n","        # Hitung jumlah langkah yang telah dilalui\n","        n       = iters // step_size\n","        # LR turun dengan rate decay_rate setiap langkah\n","        out_lr  = lr * decay_rate ** n\n","        return out_lr\n","\n","    if lr_decay_type == \"cos\": # Jika memilih cosine decay\n","        # Hitung jumlah iterasi warmup\n","        warmup_total_iters  = min(max(warmup_iters_ratio * total_iters, 1), 3)\n","         # Hitung nilai LR awal saat warmup\n","        warmup_lr_start     = max(warmup_lr_ratio * lr, 1e-6)\n","        # Hitung iterasi tanpa augmentasi\n","        no_aug_iter         = min(max(no_aug_iter_ratio * total_iters, 1), 15)\n","        # Scheduler berbasis cosine decay\n","        func = partial(yolox_warm_cos_lr ,lr, min_lr, total_iters, warmup_total_iters, warmup_lr_start, no_aug_iter)\n","    else: # Jika memilih step decay\n","        # Hitung decay rate untuk step decay\n","        decay_rate  = (min_lr / lr) ** (1 / (step_num - 1))\n","        # Hitung ukuran langkah\n","        step_size   = total_iters / step_num\n","        # Scheduler berbasis step decay\n","        func = partial(step_lr, lr, decay_rate, step_size)\n","\n","    return func\n","\n","# Fungsi untuk mengatur LR optimizer pada setiap epoch\n","def set_optimizer_lr(optimizer, lr_scheduler_func, epoch):\n","    \"\"\"\n","    Parameter:\n","    - optimizer: Optimizer PyTorch (misalnya SGD atau Adam).\n","    - lr_scheduler_func: Fungsi scheduler untuk menghitung LR.\n","    - epoch: Epoch saat ini.\n","    \"\"\"\n","    # Hitung LR untuk epoch saat ini\n","    lr = lr_scheduler_func(epoch)\n","    # Perbarui LR untuk setiap kelompok parameter di optimizer\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"]},{"cell_type":"markdown","metadata":{"id":"ba1NiXs3hFvQ"},"source":["# **TRAINING**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiTBvprTmbb2"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/210411100054-SitiNurAini')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1732781449952,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-540},"id":"TIbqUwcryc6C","outputId":"8a9586d6-4ed1-42f2-e7ab-3c58519f5f25"},"outputs":[{"name":"stdout","output_type":"stream","text":[" COBA.ipynb\t\t    dataset\t\t       DatasetProcessing.ipynb\n","'conf Training_8:2.ipynb'   DATASET-CXR-AL3\t       _logs_9:1\n","'conf Training_9:1.ipynb'   DatasetPreparation.ipynb   model_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2884,"status":"ok","timestamp":1732781452835,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-540},"id":"jMECeRLwAOin","outputId":"476ec4c2-5480-4833-81fa-1209fe24a451"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"]}],"source":["pip install pycocotools"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939495,"status":"ok","timestamp":1732782392328,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-540},"id":"GEZ4O0VgLZVh","outputId":"aa6075ce-684f-4503-8cf6-766927a485ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["initialize network with normal type\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:1278: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n","  module._c._create_method_from_trace(\n","<ipython-input-15-8098304d7160>:121: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n"]},{"name":"stdout","output_type":"stream","text":["Configurations:\n","----------------------------------------------------------------------\n","|                     keys |                                   values|\n","----------------------------------------------------------------------\n","|             classes_path | /content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt|\n","|               model_path |                                         |\n","|              input_shape |                               [512, 512]|\n","|               Init_Epoch |                                        0|\n","|             Freeze_Epoch |                                    False|\n","|           UnFreeze_Epoch |                                       50|\n","|        Freeze_batch_size |                                    False|\n","|      Unfreeze_batch_size |                                       16|\n","|             Freeze_Train |                                    False|\n","|                  Init_lr |                                    0.001|\n","|                   Min_lr |                                    0.001|\n","|           optimizer_type |                                      sgd|\n","|                 momentum |                                    0.937|\n","|            lr_decay_type |                                      cos|\n","|              save_period |                                        1|\n","|                 save_dir |                                 logs_9:1|\n","|              num_workers |                                        8|\n","|                num_train |                                      924|\n","|                  num_val |                                      103|\n","----------------------------------------------------------------------\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch 1/50:   0%|          | 0/57 [00:00<?, ?it/s<class 'dict'>]<ipython-input-5-b775a6883131>:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","<ipython-input-11-59d4a2336af8>:260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=False):\n","Epoch 1/50: 100%|██████████| 57/57 [02:40<00:00,  2.82s/it, loss=472, lr=5e-5]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/50: 100%|██████████| 6/6 [00:21<00:00,  3.52s/it, val_loss=63.8]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:1/50\n","Total Loss: 472.299 || Val Loss: 63.834 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/50: 100%|██████████| 57/57 [00:12<00:00,  4.43it/s, loss=14.4, lr=0.000122]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/50: 100%|██████████| 6/6 [00:03<00:00,  1.71it/s, val_loss=14.6]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:2/50\n","Total Loss: 14.440 || Val Loss: 14.639 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/50: 100%|██████████| 57/57 [00:12<00:00,  4.41it/s, loss=13.2, lr=0.000338]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/50: 100%|██████████| 6/6 [00:01<00:00,  4.48it/s, val_loss=14.2]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:3/50\n","Total Loss: 13.229 || Val Loss: 14.231 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/50: 100%|██████████| 57/57 [00:13<00:00,  4.33it/s, loss=12.3, lr=0.0005]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/50: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s, val_loss=12]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:4/50\n","Total Loss: 12.305 || Val Loss: 12.008 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/50: 100%|██████████| 57/57 [00:12<00:00,  4.46it/s, loss=11.5, lr=0.000499]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/50: 100%|██████████| 6/6 [00:01<00:00,  4.58it/s, val_loss=11.1]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 22.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.02s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 0.00%\n","AP for Nodule_Mass: 0.00%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 0.00%\n","Get map done.\n","Epoch:5/50\n","Total Loss: 11.479 || Val Loss: 11.086 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/50: 100%|██████████| 57/57 [00:12<00:00,  4.50it/s, loss=11.1, lr=0.000498]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/50: 100%|██████████| 6/6 [00:01<00:00,  4.25it/s, val_loss=10.9]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:6/50\n","Total Loss: 11.141 || Val Loss: 10.894 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/50: 100%|██████████| 57/57 [00:12<00:00,  4.57it/s, loss=10.9, lr=0.000496]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/50: 100%|██████████| 6/6 [00:01<00:00,  4.36it/s, val_loss=10.8]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:7/50\n","Total Loss: 10.930 || Val Loss: 10.847 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/50: 100%|██████████| 57/57 [00:12<00:00,  4.55it/s, loss=10.7, lr=0.000494]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/50: 100%|██████████| 6/6 [00:01<00:00,  4.42it/s, val_loss=10.4]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:8/50\n","Total Loss: 10.685 || Val Loss: 10.384 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/50: 100%|██████████| 57/57 [00:12<00:00,  4.40it/s, loss=10.4, lr=0.000491]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/50: 100%|██████████| 6/6 [00:01<00:00,  4.31it/s, val_loss=10.7]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:9/50\n","Total Loss: 10.440 || Val Loss: 10.662 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/50: 100%|██████████| 57/57 [00:13<00:00,  4.38it/s, loss=10.2, lr=0.000487]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/50: 100%|██████████| 6/6 [00:01<00:00,  4.61it/s, val_loss=10.3]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 23.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.03s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.030\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 1.78%\n","AP for Nodule_Mass: 0.00%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 0.24%\n","Get map done.\n","Epoch:10/50\n","Total Loss: 10.244 || Val Loss: 10.317 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/50: 100%|██████████| 57/57 [00:13<00:00,  4.31it/s, loss=10.2, lr=0.000483]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/50: 100%|██████████| 6/6 [00:01<00:00,  4.17it/s, val_loss=10.1]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:11/50\n","Total Loss: 10.153 || Val Loss: 10.069 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/50: 100%|██████████| 57/57 [00:12<00:00,  4.49it/s, loss=9.8, lr=0.000479]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/50: 100%|██████████| 6/6 [00:01<00:00,  4.68it/s, val_loss=9.74]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:12/50\n","Total Loss: 9.798 || Val Loss: 9.739 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/50: 100%|██████████| 57/57 [00:12<00:00,  4.43it/s, loss=9.65, lr=0.000474]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/50: 100%|██████████| 6/6 [00:01<00:00,  4.07it/s, val_loss=9.95]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:13/50\n","Total Loss: 9.654 || Val Loss: 9.951 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/50: 100%|██████████| 57/57 [00:12<00:00,  4.53it/s, loss=9.6, lr=0.000468]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/50: 100%|██████████| 6/6 [00:01<00:00,  4.58it/s, val_loss=9.77]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:14/50\n","Total Loss: 9.599 || Val Loss: 9.765 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/50: 100%|██████████| 57/57 [00:12<00:00,  4.43it/s, loss=9.51, lr=0.000462]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/50: 100%|██████████| 6/6 [00:01<00:00,  4.19it/s, val_loss=9.8]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 23.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.03s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.051\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.088\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.092\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 5.08%\n","AP for Nodule_Mass: 0.92%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 1.89%\n","Get map done.\n","Epoch:15/50\n","Total Loss: 9.505 || Val Loss: 9.801 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 16/50: 100%|██████████| 57/57 [00:13<00:00,  4.37it/s, loss=9.35, lr=0.000455]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 16/50: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s, val_loss=9.17]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:16/50\n","Total Loss: 9.348 || Val Loss: 9.170 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 17/50: 100%|██████████| 57/57 [00:12<00:00,  4.56it/s, loss=9.23, lr=0.000448]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 17/50: 100%|██████████| 6/6 [00:01<00:00,  4.23it/s, val_loss=8.97]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:17/50\n","Total Loss: 9.232 || Val Loss: 8.973 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 18/50: 100%|██████████| 57/57 [00:12<00:00,  4.40it/s, loss=9.15, lr=0.000441]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 18/50: 100%|██████████| 6/6 [00:01<00:00,  4.20it/s, val_loss=9.24]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:18/50\n","Total Loss: 9.145 || Val Loss: 9.238 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 19/50: 100%|██████████| 57/57 [00:12<00:00,  4.51it/s, loss=9.01, lr=0.000434]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 19/50: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s, val_loss=9.26]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:19/50\n","Total Loss: 9.013 || Val Loss: 9.261 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 20/50: 100%|██████████| 57/57 [00:12<00:00,  4.47it/s, loss=9.06, lr=0.000426]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 20/50: 100%|██████████| 6/6 [00:01<00:00,  4.67it/s, val_loss=8.72]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 22.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.03s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.134\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.042\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.103\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 13.36%\n","AP for Nodule_Mass: 0.97%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 4.29%\n","Get map done.\n","Epoch:20/50\n","Total Loss: 9.062 || Val Loss: 8.717 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 21/50: 100%|██████████| 57/57 [00:12<00:00,  4.50it/s, loss=8.99, lr=0.000418]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 21/50: 100%|██████████| 6/6 [00:01<00:00,  4.19it/s, val_loss=8.96]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:21/50\n","Total Loss: 8.986 || Val Loss: 8.956 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 22/50: 100%|██████████| 57/57 [00:13<00:00,  4.36it/s, loss=8.89, lr=0.000409]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 22/50: 100%|██████████| 6/6 [00:01<00:00,  4.69it/s, val_loss=8.88]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:22/50\n","Total Loss: 8.894 || Val Loss: 8.878 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 23/50: 100%|██████████| 57/57 [00:12<00:00,  4.48it/s, loss=8.72, lr=0.000401]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 23/50: 100%|██████████| 6/6 [00:01<00:00,  4.12it/s, val_loss=8.84]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:23/50\n","Total Loss: 8.723 || Val Loss: 8.837 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 24/50: 100%|██████████| 57/57 [00:12<00:00,  4.51it/s, loss=8.78, lr=0.000392]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 24/50: 100%|██████████| 6/6 [00:01<00:00,  4.26it/s, val_loss=8.72]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:24/50\n","Total Loss: 8.777 || Val Loss: 8.715 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 25/50: 100%|██████████| 57/57 [00:12<00:00,  4.47it/s, loss=8.79, lr=0.000384]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 25/50: 100%|██████████| 6/6 [00:01<00:00,  4.41it/s, val_loss=8.73]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 22.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.05s).\n","Accumulating evaluation results...\n","DONE (t=0.03s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.129\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.049\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.129\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.129\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 12.87%\n","AP for Nodule_Mass: 4.53%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 5.15%\n","Get map done.\n","Epoch:25/50\n","Total Loss: 8.792 || Val Loss: 8.730 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 26/50: 100%|██████████| 57/57 [00:12<00:00,  4.47it/s, loss=8.62, lr=0.000375]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 26/50: 100%|██████████| 6/6 [00:01<00:00,  4.39it/s, val_loss=8.6]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:26/50\n","Total Loss: 8.618 || Val Loss: 8.604 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 27/50: 100%|██████████| 57/57 [00:12<00:00,  4.49it/s, loss=8.56, lr=0.000366]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 27/50: 100%|██████████| 6/6 [00:01<00:00,  4.27it/s, val_loss=8.46]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:27/50\n","Total Loss: 8.558 || Val Loss: 8.456 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 28/50: 100%|██████████| 57/57 [00:12<00:00,  4.48it/s, loss=8.74, lr=0.000358]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 28/50: 100%|██████████| 6/6 [00:01<00:00,  4.12it/s, val_loss=8.23]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:28/50\n","Total Loss: 8.745 || Val Loss: 8.229 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 29/50: 100%|██████████| 57/57 [00:12<00:00,  4.54it/s, loss=8.59, lr=0.000349]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 29/50: 100%|██████████| 6/6 [00:01<00:00,  4.47it/s, val_loss=8.45]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:29/50\n","Total Loss: 8.591 || Val Loss: 8.455 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 30/50: 100%|██████████| 57/57 [00:12<00:00,  4.61it/s, loss=8.42, lr=0.000341]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 30/50: 100%|██████████| 6/6 [00:01<00:00,  4.24it/s, val_loss=8.39]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 21.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.078\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.150\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 17.44%\n","AP for Nodule_Mass: 4.37%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 7.48%\n","Get map done.\n","Epoch:30/50\n","Total Loss: 8.422 || Val Loss: 8.391 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 31/50: 100%|██████████| 57/57 [00:12<00:00,  4.51it/s, loss=8.42, lr=0.000332]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 31/50: 100%|██████████| 6/6 [00:01<00:00,  4.48it/s, val_loss=8.49]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:31/50\n","Total Loss: 8.421 || Val Loss: 8.495 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 32/50: 100%|██████████| 57/57 [00:12<00:00,  4.52it/s, loss=8.28, lr=0.000324]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 32/50: 100%|██████████| 6/6 [00:01<00:00,  4.33it/s, val_loss=8.21]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:32/50\n","Total Loss: 8.279 || Val Loss: 8.211 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 33/50: 100%|██████████| 57/57 [00:12<00:00,  4.42it/s, loss=8.2, lr=0.000316]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 33/50: 100%|██████████| 6/6 [00:01<00:00,  4.34it/s, val_loss=8.36]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:33/50\n","Total Loss: 8.196 || Val Loss: 8.364 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 34/50: 100%|██████████| 57/57 [00:12<00:00,  4.55it/s, loss=8.27, lr=0.000309]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 34/50: 100%|██████████| 6/6 [00:01<00:00,  4.59it/s, val_loss=8.37]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:34/50\n","Total Loss: 8.274 || Val Loss: 8.374 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 35/50: 100%|██████████| 57/57 [00:13<00:00,  4.38it/s, loss=8.28, lr=0.000302]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 35/50: 100%|██████████| 6/6 [00:01<00:00,  4.52it/s, val_loss=8.39]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 21.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.05s).\n","Accumulating evaluation results...\n","DONE (t=0.03s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.176\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.061\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.146\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.113\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 17.60%\n","AP for Nodule_Mass: 2.23%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 5.44%\n","Get map done.\n","Epoch:35/50\n","Total Loss: 8.276 || Val Loss: 8.390 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 36/50: 100%|██████████| 57/57 [00:10<00:00,  5.24it/s, loss=8.49, lr=0.000295]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 36/50: 100%|██████████| 6/6 [00:01<00:00,  4.38it/s, val_loss=8.55]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:36/50\n","Total Loss: 8.488 || Val Loss: 8.548 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 37/50: 100%|██████████| 57/57 [00:10<00:00,  5.28it/s, loss=8.34, lr=0.000288]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 37/50: 100%|██████████| 6/6 [00:01<00:00,  4.26it/s, val_loss=8.7]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:37/50\n","Total Loss: 8.341 || Val Loss: 8.701 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 38/50: 100%|██████████| 57/57 [00:10<00:00,  5.26it/s, loss=8.25, lr=0.000282]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 38/50: 100%|██████████| 6/6 [00:01<00:00,  4.31it/s, val_loss=8.16]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:38/50\n","Total Loss: 8.245 || Val Loss: 8.157 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 39/50: 100%|██████████| 57/57 [00:10<00:00,  5.33it/s, loss=8.22, lr=0.000276]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 39/50: 100%|██████████| 6/6 [00:01<00:00,  4.55it/s, val_loss=8.13]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:39/50\n","Total Loss: 8.223 || Val Loss: 8.133 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 40/50: 100%|██████████| 57/57 [00:10<00:00,  5.44it/s, loss=8.17, lr=0.000271]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 40/50: 100%|██████████| 6/6 [00:01<00:00,  4.27it/s, val_loss=8.36]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 22.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.03s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.212\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.068\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.140\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 21.25%\n","AP for Nodule_Mass: 0.97%\n","AP for Pneumothorax: 0.33%\n","\n","Mean Average Precision (mAP): 6.46%\n","Get map done.\n","Epoch:40/50\n","Total Loss: 8.169 || Val Loss: 8.355 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 41/50: 100%|██████████| 57/57 [00:10<00:00,  5.25it/s, loss=8.07, lr=0.000267]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 41/50: 100%|██████████| 6/6 [00:01<00:00,  4.51it/s, val_loss=8.22]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:41/50\n","Total Loss: 8.072 || Val Loss: 8.224 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 42/50: 100%|██████████| 57/57 [00:10<00:00,  5.35it/s, loss=8.1, lr=0.000263]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 42/50: 100%|██████████| 6/6 [00:01<00:00,  4.38it/s, val_loss=7.95]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:42/50\n","Total Loss: 8.103 || Val Loss: 7.949 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 43/50: 100%|██████████| 57/57 [00:10<00:00,  5.39it/s, loss=7.93, lr=0.000259]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 43/50: 100%|██████████| 6/6 [00:01<00:00,  4.57it/s, val_loss=8.06]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:43/50\n","Total Loss: 7.926 || Val Loss: 8.057 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 44/50: 100%|██████████| 57/57 [00:10<00:00,  5.31it/s, loss=7.93, lr=0.000256]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 44/50: 100%|██████████| 6/6 [00:01<00:00,  4.56it/s, val_loss=8.16]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:44/50\n","Total Loss: 7.926 || Val Loss: 8.156 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 45/50: 100%|██████████| 57/57 [00:10<00:00,  5.46it/s, loss=7.9, lr=0.000254]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 45/50: 100%|██████████| 6/6 [00:01<00:00,  4.30it/s, val_loss=8.04]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 22.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.30s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.237\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.123\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.168\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.148\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 23.69%\n","AP for Nodule_Mass: 1.24%\n","AP for Pneumothorax: 0.00%\n","\n","Mean Average Precision (mAP): 9.12%\n","Get map done.\n","Epoch:45/50\n","Total Loss: 7.904 || Val Loss: 8.036 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 46/50: 100%|██████████| 57/57 [00:10<00:00,  5.31it/s, loss=7.73, lr=0.000252]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 46/50: 100%|██████████| 6/6 [00:01<00:00,  4.27it/s, val_loss=8]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:46/50\n","Total Loss: 7.729 || Val Loss: 8.000 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 47/50: 100%|██████████| 57/57 [00:10<00:00,  5.24it/s, loss=7.82, lr=0.000251]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 47/50: 100%|██████████| 6/6 [00:01<00:00,  4.56it/s, val_loss=8.23]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:47/50\n","Total Loss: 7.821 || Val Loss: 8.225 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 48/50: 100%|██████████| 57/57 [00:10<00:00,  5.37it/s, loss=7.65, lr=0.00025]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 48/50: 100%|██████████| 6/6 [00:01<00:00,  3.97it/s, val_loss=8.06]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:48/50\n","Total Loss: 7.649 || Val Loss: 8.063 \n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 49/50: 100%|██████████| 57/57 [00:10<00:00,  5.41it/s, loss=7.72, lr=0.00025]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 49/50: 100%|██████████| 6/6 [00:01<00:00,  4.25it/s, val_loss=7.61]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Epoch:49/50\n","Total Loss: 7.721 || Val Loss: 7.608 \n","Save best model to best_epoch_weights.pth\n","Start Train\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 50/50: 100%|██████████| 57/57 [00:10<00:00,  5.26it/s, loss=7.65, lr=0.00025]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Train\n","Start Validation\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 50/50: 100%|██████████| 6/6 [00:01<00:00,  4.44it/s, val_loss=7.95]\n"]},{"name":"stdout","output_type":"stream","text":["Finish Validation\n","Get map.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 103/103 [00:04<00:00, 23.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Calculate Map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.03s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.245\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.101\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.199\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n","\n","Average Precision (AP) for each class (in %):\n","AP for Cardiomegaly: 24.48%\n","AP for Nodule_Mass: 5.47%\n","AP for Pneumothorax: 1.34%\n","\n","Mean Average Precision (mAP): 10.02%\n","Get map done.\n","Epoch:50/50\n","Total Loss: 7.647 || Val Loss: 7.948 \n"]}],"source":["import datetime\n","import os\n","\n","from random import shuffle\n","import numpy as np\n","import torch\n","import torch.backends.cudnn as cudnn\n","import torch.distributed as dist\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","\n","if __name__ == \"__main__\":\n","\n","    Cuda = True\n","\n","    distributed = False\n","\n","    sync_bn = False\n","\n","    fp16 = True\n","\n","    classes_path = '/content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt'  # Path ke file kelas (cari daftar kelas)\n","\n","    model_path      = ''\n","\n","    input_shape = [512, 512]\n","\n","    phi = 's'\n","    mosaic = True\n","    mosaic_prob = 0.5\n","    mixup = True\n","    mixup_prob = 0.5\n","    special_aug_ratio = 0.7\n","    Init_Epoch = 0\n","    Freeze_Epoch = False\n","    Freeze_batch_size = False\n","    UnFreeze_Epoch = 50\n","    Unfreeze_batch_size = 16\n","\n","    Freeze_Train = False\n","\n","    Init_lr = 1e-3\n","    Min_lr = Init_lr\n","\n","    optimizer_type = \"sgd\"\n","    momentum = 0.937\n","    weight_decay = 5e-4\n","\n","    lr_decay_type = \"cos\"\n","\n","    save_period = 1\n","\n","    save_dir = 'logs_9:1'\n","\n","    eval_flag = True\n","    eval_period = 5\n","\n","    num_workers = 8\n","\n","\n","    train_annotation_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/ImageSets/Main/2024_train_9:1.txt'  # Path ke anotasi data latih\n","    val_annotation_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/ImageSets/Main/2024_val_9:1.txt'  # Path ke anotasi data validasi\n","\n","\n","    ngpus_per_node = torch.cuda.device_count()\n","    if distributed:\n","        dist.init_process_group(backend=\"nccl\")\n","        local_rank = int(os.environ[\"LOCAL_RANK\"])\n","        rank = int(os.environ[\"RANK\"])\n","        device = torch.device(\"cuda\", local_rank)\n","        if local_rank == 0:\n","            print(f\"[{os.getpid()}] (rank = {rank}, local_rank = {local_rank}) training...\")\n","            print(\"Gpu Device Count : \", ngpus_per_node)\n","    else:\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        local_rank = 0\n","        rank = 0\n","\n","\n","    class_names, num_classes = get_classes(classes_path)\n","\n","    model = YoloBody(num_classes, phi)\n","    weights_init(model)\n","    if model_path != '':\n","\n","        if local_rank == 0:\n","            print('Load weights {}.'.format(model_path))\n","\n","        model_dict = model.state_dict()\n","        pretrained_dict = torch.load(model_path, map_location=device)\n","        load_key, no_load_key, temp_dict = [], [], {}\n","        for k, v in pretrained_dict.items():\n","            if k in model_dict.keys() and np.shape(model_dict[k]) == np.shape(v):\n","                temp_dict[k] = v\n","                load_key.append(k)\n","            else:\n","                no_load_key.append(k)\n","        model_dict.update(temp_dict)\n","        model.load_state_dict(model_dict)\n","\n","        if local_rank == 0:\n","            pass\n","\n","\n","    yolo_loss = YOLOLoss(num_classes, fp16)\n","\n","    if local_rank == 0:\n","        time_str = datetime.datetime.strftime(datetime.datetime.now(), '%Y_%m_%d_%H_%M_%S')\n","        log_dir = os.path.join(save_dir, \"loss_\" + str(time_str))\n","        loss_history = LossHistory(log_dir, model, input_shape=input_shape)\n","    else:\n","        loss_history = None\n","\n","    if fp16:\n","        from torch.cuda.amp import GradScaler as GradScaler\n","\n","        scaler = GradScaler()\n","    else:\n","        scaler = None\n","\n","    model_train = model.train()\n","\n","    if sync_bn and ngpus_per_node > 1 and distributed:\n","        model_train = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model_train)\n","    elif sync_bn:\n","        print(\"Sync_bn is not support in one gpu or not distributed.\")\n","\n","    if Cuda:\n","        if distributed:\n","\n","            model_train = model_train.cuda(local_rank)\n","            model_train = torch.nn.parallel.DistributedDataParallel(model_train, device_ids=[local_rank],\n","                                                                    find_unused_parameters=True)\n","        else:\n","            model_train = torch.nn.DataParallel(model)\n","            cudnn.benchmark = True\n","            model_train = model_train.cuda()\n","\n","\n","    ema = ModelEMA(model_train)\n","\n","    with open(train_annotation_path, encoding='utf-8') as f:\n","        train_lines = f.readlines()\n","    with open(val_annotation_path, encoding='utf-8') as f:\n","        val_lines = f.readlines()\n","    num_train = len(train_lines)\n","    num_val = len(val_lines)\n","\n","    if local_rank == 0:\n","        show_config(\n","            classes_path=classes_path, model_path=model_path, input_shape=input_shape, \\\n","            Init_Epoch=Init_Epoch, Freeze_Epoch=Freeze_Epoch, UnFreeze_Epoch=UnFreeze_Epoch,\n","            Freeze_batch_size=Freeze_batch_size, Unfreeze_batch_size=Unfreeze_batch_size, Freeze_Train=Freeze_Train, \\\n","            Init_lr=Init_lr, Min_lr=Min_lr, optimizer_type=optimizer_type, momentum=momentum,\n","            lr_decay_type=lr_decay_type, \\\n","            save_period=save_period, save_dir=save_dir, num_workers=num_workers, num_train=num_train, num_val=num_val\n","        )\n","        wanted_step = 5e4 if optimizer_type == \"sgd\" else 1.5e4\n","        total_step = num_train // Unfreeze_batch_size * UnFreeze_Epoch\n","        if total_step <= wanted_step:\n","            if num_train // Unfreeze_batch_size == 0:\n","                raise ValueError(\"The dataset is too small to continue training. Please expand the dataset.\"\n","\n",")\n","            wanted_epoch = wanted_step // (num_train // Unfreeze_batch_size) + 1\n","\n","\n","    if True:\n","        UnFreeze_flag = False\n","\n","        if Freeze_Train:\n","            for param in model.backbone.parameters():\n","                param.requires_grad = False\n","\n","        batch_size = Freeze_batch_size if Freeze_Train else Unfreeze_batch_size\n","\n","\n","        nbs = 64\n","        lr_limit_max = 1e-3 if optimizer_type == 'adam' else 5e-2\n","        lr_limit_min = 3e-4 if optimizer_type == 'adam' else 5e-4\n","        Init_lr_fit = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n","        Min_lr_fit = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n","\n","\n","        pg0, pg1, pg2 = [], [], []\n","        for k, v in model.named_modules():\n","            if hasattr(v, \"bias\") and isinstance(v.bias, nn.Parameter):\n","                pg2.append(v.bias)\n","            if isinstance(v, nn.BatchNorm2d) or \"bn\" in k:\n","                pg0.append(v.weight)\n","            elif hasattr(v, \"weight\") and isinstance(v.weight, nn.Parameter):\n","                pg1.append(v.weight)\n","        optimizer = {\n","            'adam': optim.Adam(pg0, Init_lr_fit, betas=(momentum, 0.999)),\n","            'sgd': optim.SGD(pg0, Init_lr_fit, momentum=momentum, nesterov=True)\n","        }[optimizer_type]\n","        optimizer.add_param_group({\"params\": pg1, \"weight_decay\": weight_decay})\n","        optimizer.add_param_group({\"params\": pg2})\n","\n","        lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n","\n","        epoch_step = num_train // batch_size\n","        epoch_step_val = num_val // batch_size\n","\n","        if epoch_step == 0 or epoch_step_val == 0:\n","            raise ValueError(\"The dataset is too small to continue training. Please expand the dataset.\"\n","\n",")\n","\n","        if ema:\n","            ema.updates = epoch_step * Init_Epoch\n","\n","        # ---------------------------------------#\n","        #   构建数据集加载器。\n","        # ---------------------------------------#\n","        train_dataset = YoloDataset(train_lines, input_shape, num_classes, epoch_length=UnFreeze_Epoch, \\\n","                                    mosaic=mosaic, mixup=mixup, mosaic_prob=mosaic_prob, mixup_prob=mixup_prob,\n","                                    train=True, special_aug_ratio=special_aug_ratio)\n","        val_dataset = YoloDataset(val_lines, input_shape, num_classes, epoch_length=UnFreeze_Epoch, \\\n","                                  mosaic=False, mixup=False, mosaic_prob=0, mixup_prob=0, train=False,\n","                                  special_aug_ratio=0)\n","\n","        if distributed:\n","            train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, shuffle=True, )\n","            val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False, )\n","            batch_size = batch_size // ngpus_per_node\n","            shuffle = False\n","        else:\n","            train_sampler = None\n","            val_sampler = None\n","            # shuffle = True\n","            my_shuffle = True\n","\n","        gen = DataLoader(train_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers,\n","                         pin_memory=True,\n","                         drop_last=True, collate_fn=yolo_dataset_collate, sampler=train_sampler)\n","        gen_val = DataLoader(val_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers,\n","                             pin_memory=True,\n","                             drop_last=True, collate_fn=yolo_dataset_collate, sampler=val_sampler)\n","\n","        if local_rank == 0:\n","            eval_callback = EvalCallback(model, input_shape, class_names, num_classes, val_lines, log_dir, Cuda, \\\n","                                         eval_flag=eval_flag, period=eval_period)\n","        else:\n","            eval_callback = None\n","\n","        for epoch in range(Init_Epoch, UnFreeze_Epoch):\n","\n","            if epoch >= Freeze_Epoch and not UnFreeze_flag and Freeze_Train:\n","                batch_size = Unfreeze_batch_size\n","\n","\n","                nbs = 64\n","                lr_limit_max = 1e-3 if optimizer_type == 'adam' else 5e-2\n","                lr_limit_min = 3e-4 if optimizer_type == 'adam' else 5e-4\n","                Init_lr_fit = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n","                Min_lr_fit = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n","\n","                lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n","\n","                for param in model.backbone.parameters():\n","                    param.requires_grad = True\n","\n","                epoch_step = num_train // batch_size\n","                epoch_step_val = num_val // batch_size\n","\n","                if epoch_step == 0 or epoch_step_val == 0:\n","                    raise ValueError(\"The dataset is too small to continue training. Please expand the dataset.\"\n","\n",")\n","\n","                if distributed:\n","                    batch_size = batch_size // ngpus_per_node\n","\n","                if ema:\n","                    ema.updates = epoch_step * epoch\n","\n","                gen = DataLoader(train_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers,\n","                                 pin_memory=True,\n","                                 drop_last=True, collate_fn=yolo_dataset_collate, sampler=train_sampler)\n","                gen_val = DataLoader(val_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers,\n","                                     pin_memory=True,\n","                                     drop_last=True, collate_fn=yolo_dataset_collate, sampler=val_sampler)\n","\n","                UnFreeze_flag = True\n","\n","            gen.dataset.epoch_now = epoch\n","            gen_val.dataset.epoch_now = epoch\n","\n","            if distributed:\n","                train_sampler.set_epoch(epoch)\n","\n","            set_optimizer_lr(optimizer, lr_scheduler_func, epoch)\n","\n","            fit_one_epoch(model_train, model, ema, yolo_loss, loss_history, eval_callback, optimizer, epoch, epoch_step,\n","                          epoch_step_val, gen, gen_val, UnFreeze_Epoch, Cuda, fp16, scaler, save_period, save_dir,\n","                          local_rank)\n","\n","            if distributed:\n","                dist.barrier()\n","\n","        if local_rank == 0:\n","            loss_history.writer.close()"]},{"cell_type":"markdown","metadata":{"id":"2BQ1xbYuhK4w"},"source":["# **PREDIKSI HASIL TRAINING**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-lEtFYfmJFS"},"outputs":[],"source":["import colorsys\n","import os\n","import time\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from PIL import ImageDraw, ImageFont\n","\n","\n","class YOLO(object):\n","    _defaults = {\n","        \"model_path\": '/content/drive/MyDrive/210411100054-SitiNurAini/logs_9:1/best_epoch_weights.pth',\n","        \"classes_path\": '/content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt',\n","        \"input_shape\": [512, 512],\n","        \"phi\": 's',\n","        \"confidence\": 0.01,\n","        \"nms_iou\": 0.5,\n","        \"letterbox_image\": True,\n","        \"cuda\": False,\n","    }\n","\n","    @classmethod\n","    def get_defaults(cls, n):\n","        if n in cls._defaults:\n","            return cls._defaults[n]\n","        else:\n","            return \"Unrecognized attribute name '\" + n + \"'\"\n","\n","    def __init__(self, **kwargs):\n","        self.__dict__.update(self._defaults)\n","        for name, value in kwargs.items():\n","            setattr(self, name, value)\n","            self._defaults[name] = value\n","\n","\n","        self.class_names, self.num_classes = get_classes(self.classes_path)\n","\n","\n","        hsv_tuples = [(x / self.num_classes, 1., 1.) for x in range(self.num_classes)]\n","        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","        self.colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), self.colors))\n","        self.generate()\n","\n","        show_config(**self._defaults)\n","\n","    def generate(self, onnx=False):\n","        self.net = YoloBody(self.num_classes, self.phi)\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.net.load_state_dict(torch.load(self.model_path, map_location=device))\n","        self.net = self.net.eval()\n","        print('{} model, and classes loaded.'.format(self.model_path))\n","        if not onnx:\n","            if self.cuda:\n","                self.net = nn.DataParallel(self.net)\n","                self.net = self.net.cuda()\n","\n","\n","    def detect_image(self, image, crop=False, count=False):\n","        image_shape = np.array(np.shape(image)[0:2])\n","\n","        # Konversi warna gambar\n","        image = cvtColor(image)\n","\n","        # Resize gambar sesuai dengan input shape model\n","        image_data = resize_image(image, (self.input_shape[1], self.input_shape[0]), self.letterbox_image)\n","        image_data = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, dtype='float32')), (2, 0, 1)), 0)\n","\n","        with torch.no_grad():\n","            images = torch.from_numpy(image_data)\n","            if self.cuda:\n","                images = images.cuda()\n","\n","            # Forward pass ke model\n","            outputs = self.net(images)\n","            outputs = decode_outputs(outputs, self.input_shape)\n","\n","            # Non-Maximum Suppression\n","            results = non_max_suppression(outputs, self.num_classes, self.input_shape,\n","                                        image_shape, self.letterbox_image, conf_thres=self.confidence,\n","                                        nms_thres=self.nms_iou)\n","\n","            if results[0] is None:\n","                return image\n","\n","            # Ekstrak label, confidence, dan bounding box\n","            top_label = np.array(results[0][:, 6], dtype='int32')\n","            top_conf = results[0][:, 4] * results[0][:, 5]\n","            top_boxes = results[0][:, :4]\n","\n","        # Pilih hasil dengan confidence tertinggi untuk setiap kelas\n","        unique_labels = np.unique(top_label)\n","        selected_indices = []\n","\n","        for label in unique_labels:\n","            label_indices = np.where(top_label == label)[0]\n","            if len(label_indices) > 0:\n","                max_idx = label_indices[np.argmax(top_conf[label_indices])]\n","                selected_indices.append(max_idx)\n","\n","        # Ambil data berdasarkan indeks yang dipilih\n","        selected_indices = np.array(selected_indices)\n","        top_label = top_label[selected_indices]\n","        top_conf = top_conf[selected_indices]\n","        top_boxes = top_boxes[selected_indices]\n","\n","        # Visualisasi hasil\n","        font = ImageFont.truetype(font='/content/drive/MyDrive/210411100054-SitiNurAini/model_data/arial.ttf',\n","                                size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n","        thickness = int(max((image.size[0] + image.size[1]) // np.mean(self.input_shape), 1))\n","\n","        for i, c in list(enumerate(top_label)):\n","            predicted_class = self.class_names[int(c)]\n","            box = top_boxes[i]\n","            score = top_conf[i]\n","\n","            top, left, bottom, right = box\n","            top = max(0, np.floor(top).astype('int32'))\n","            left = max(0, np.floor(left).astype('int32'))\n","            bottom = min(image.size[1], np.floor(bottom).astype('int32'))\n","            right = min(image.size[0], np.floor(right).astype('int32'))\n","\n","            label = '{} {:.2f}'.format(predicted_class, score)\n","            draw = ImageDraw.Draw(image)\n","            label_size = draw.textbbox((0, 0), label, font)\n","            label = label.encode('utf-8')\n","            print(label, top, left, bottom, right)\n","\n","            if top - label_size[1] >= 0:\n","                text_origin = np.array([left, top - label_size[1]])\n","            else:\n","                text_origin = np.array([left, top + 1])\n","\n","            for i in range(thickness):\n","                draw.rectangle([left + i, top + i, right - i, bottom - i], outline=self.colors[c])\n","\n","            right_bottom = (text_origin[0] + label_size[2], text_origin[1] + label_size[3])\n","            draw.rectangle([tuple(text_origin), right_bottom], fill=self.colors[c])\n","            draw.text(text_origin, str(label, 'UTF-8'), fill=(0, 0, 0), font=font)\n","            del draw\n","\n","        return image\n","\n","\n","    # def detect_image(self, image, crop=False, count=False):\n","\n","    #     image_shape = np.array(np.shape(image)[0:2])\n","\n","    #     image = cvtColor(image)\n","\n","    #     image_data = resize_image(image, (self.input_shape[1], self.input_shape[0]), self.letterbox_image)\n","\n","    #     image_data = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, dtype='float32')), (2, 0, 1)), 0)\n","\n","    #     with torch.no_grad():\n","    #         images = torch.from_numpy(image_data)\n","    #         if self.cuda:\n","    #             images = images.cuda()\n","\n","    #         outputs = self.net(images)\n","    #         outputs = decode_outputs(outputs, self.input_shape)\n","\n","    #         results = non_max_suppression(outputs, self.num_classes, self.input_shape,\n","    #                                       image_shape, self.letterbox_image, conf_thres=self.confidence,\n","    #                                       nms_thres=self.nms_iou)\n","\n","    #         if results[0] is None:\n","    #             return image\n","\n","    #         top_label = np.array(results[0][:, 6], dtype='int32')\n","    #         top_conf = results[0][:, 4] * results[0][:, 5]\n","    #         top_boxes = results[0][:, :4]\n","\n","    #     font = ImageFont.truetype(font='/content/drive/MyDrive/210411100054-SitiNurAini/model_data/arial.ttf',\n","    #                               size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n","    #     thickness = int(max((image.size[0] + image.size[1]) // np.mean(self.input_shape), 1))\n","\n","    #     if count:\n","    #         print(\"top_label:\", top_label)\n","    #         classes_nums = np.zeros([self.num_classes])\n","    #         for i in range(self.num_classes):\n","    #             num = np.sum(top_label == i)\n","    #             if num > 0:\n","    #                 print(self.class_names[i], \" : \", num)\n","    #             classes_nums[i] = num\n","    #         print(\"classes_nums:\", classes_nums)\n","\n","    #     if crop:\n","    #         for i, c in list(enumerate(top_label)):\n","    #             top, left, bottom, right = top_boxes[i]\n","    #             top = max(0, np.floor(top).astype('int32'))\n","    #             left = max(0, np.floor(left).astype('int32'))\n","    #             bottom = min(image.size[1], np.floor(bottom).astype('int32'))\n","    #             right = min(image.size[0], np.floor(right).astype('int32'))\n","\n","    #             dir_save_path = \"img_crop\"\n","    #             if not os.path.exists(dir_save_path):\n","    #                 os.makedirs(dir_save_path)\n","    #             crop_image = image.crop([left, top, right, bottom])\n","    #             crop_image.save(os.path.join(dir_save_path, \"crop_\" + str(i) + \".png\"), quality=95, subsampling=0)\n","    #             print(\"save crop_\" + str(i) + \".png to \" + dir_save_path)\n","\n","\n","    #     for i, c in list(enumerate(top_label)):\n","    #           predicted_class = self.class_names[int(c)]\n","    #           box = top_boxes[i]\n","    #           score = top_conf[i]\n","\n","    #           top, left, bottom, right = box\n","\n","    #           top = max(0, np.floor(top).astype('int32'))\n","    #           left = max(0, np.floor(left).astype('int32'))\n","    #           bottom = min(image.size[1], np.floor(bottom).astype('int32'))\n","    #           right = min(image.size[0], np.floor(right).astype('int32'))\n","\n","    #           label = '{} {:.2f}'.format(predicted_class, score)\n","    #           draw = ImageDraw.Draw(image)\n","    #           label_size = draw.textbbox((0, 0), label, font)\n","    #           label = label.encode('utf-8')\n","    #           print(label, top, left, bottom, right)\n","\n","    #           if top - label_size[1] >= 0:\n","    #               text_origin = np.array([left, top - label_size[1]])\n","    #           else:\n","    #               text_origin = np.array([left, top + 1])\n","\n","    #           for i in range(thickness):\n","    #               draw.rectangle([left + i, top + i, right - i, bottom - i], outline=self.colors[c])\n","\n","    #           # Menghitung sudut kanan bawah dari kotak label\n","    #           right_bottom = (text_origin[0] + label_size[2], text_origin[1] + label_size[3])\n","\n","    #           # Gambar persegi panjang berisi latar belakang label\n","    #           draw.rectangle([tuple(text_origin), right_bottom], fill=self.colors[c])\n","\n","    #           # Gambar teks pada gambar\n","    #           draw.text(text_origin, str(label, 'UTF-8'), fill=(0, 0, 0), font=font)\n","    #           del draw\n","\n","\n","    #     return image\n","\n","\n","    def detect_heatmap(self, image, heatmap_save_path):\n","        import cv2\n","        import matplotlib\n","        matplotlib.use('Agg')\n","        import matplotlib.pyplot as plt\n","        def sigmoid(x):\n","            y = 1.0 / (1.0 + np.exp(-x))\n","            return y\n","\n","        image_shape = np.array(np.shape(image)[0:2])\n","\n","        image = cvtColor(image)\n","\n","        image_data = resize_image(image, (self.input_shape[1], self.input_shape[0]), self.letterbox_image)\n","\n","        image_data = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, dtype='float32')), (2, 0, 1)), 0)\n","\n","        with torch.no_grad():\n","            images = torch.from_numpy(image_data)\n","            if self.cuda:\n","                images = images.cuda()\n","            outputs = self.net(images)\n","\n","        outputs = [output.cpu().numpy() for output in outputs]\n","        plt.imshow(image, alpha=1)\n","        plt.axis('off')\n","        mask = np.zeros((image.size[1], image.size[0]))\n","        for sub_output in outputs:\n","            b, c, h, w = np.shape(sub_output)\n","            sub_output = np.transpose(sub_output, [0, 2, 3, 1])[0]\n","            score = np.max(sigmoid(sub_output[..., 5:]), -1) * sigmoid(sub_output[..., 4])\n","            score = cv2.resize(score, (image.size[0], image.size[1]))\n","            normed_score = (score * 255).astype('uint8')\n","            mask = np.maximum(mask, normed_score)\n","\n","        plt.imshow(mask, alpha=0.5, interpolation='nearest', cmap=\"jet\")\n","\n","        plt.axis('off')\n","        plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n","        plt.margins(0, 0)\n","        plt.savefig(heatmap_save_path, dpi=200)\n","        print(\"Save to the \" + heatmap_save_path)\n","        plt.cla()\n","\n","\n","    def get_map_txt(self, image_id, image, class_names, map_out_path):\n","        f = open(os.path.join(map_out_path, \"detection-results/\" + image_id + \".txt\"), \"w\")\n","        image_shape = np.array(np.shape(image)[0:2])\n","\n","        image = cvtColor(image)\n","\n","        image_data = resize_image(image, (self.input_shape[1], self.input_shape[0]), self.letterbox_image)\n","\n","        image_data = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, dtype='float32')), (2, 0, 1)), 0)\n","\n","        with torch.no_grad():\n","            images = torch.from_numpy(image_data)\n","            if self.cuda:\n","                images = images.cuda()\n","\n","            outputs = self.net(images)\n","            outputs = decode_outputs(outputs, self.input_shape)\n","\n","            results = non_max_suppression(outputs, self.num_classes, self.input_shape,\n","                                          image_shape, self.letterbox_image, conf_thres=self.confidence,\n","                                          nms_thres=self.nms_iou)\n","\n","            if results[0] is None:\n","                return\n","\n","            top_label = np.array(results[0][:, 6], dtype='int32')\n","            top_conf = results[0][:, 4] * results[0][:, 5]\n","            top_boxes = results[0][:, :4]\n","\n","        objects = []\n","        for i, c in list(enumerate(top_label)):\n","            predicted_class = self.class_names[int(c)]\n","            box = top_boxes[i]\n","            score = str(top_conf[i])\n","\n","            top, left, bottom, right = box\n","            if predicted_class not in class_names:\n","                continue\n","            f.write(\"%s %s %s %s %s %s\\n\" % (\n","                predicted_class, score[:6], str(int(left)), str(int(top)), str(int(right)), str(int(bottom))))\n","            objects.append(\n","                [predicted_class, score[:6], str(int(left)), str(int(top)), str(int(right)), str(int(bottom))])\n","        f.close()\n","        save_path = os.path.join(map_out_path, \"xmls/\" + image_id + \".xml\")\n","        self.create_xml(objects, save_path)\n","        return\n","\n","    def create_xml(self, objects, save_path):\n","        with open(save_path, 'w', encoding=\"utf-8\") as xml_files:\n","            xml_files.write('<annotation>\\n')\n","            xml_files.write('   <folder>folder</folder>\\n')\n","            xml_files.write(f'   <filename></filename>\\n')\n","            xml_files.write('   <source>\\n')\n","            xml_files.write('   <database>XinQiao</database>\\n')\n","            xml_files.write('   </source>\\n')\n","            xml_files.write('   <size>\\n')\n","            xml_files.write(f'     <width>0</width>\\n')\n","            xml_files.write(f'     <height>0</height>\\n')\n","            xml_files.write(f'     <depth>3</depth>\\n')\n","            xml_files.write('   </size>\\n')\n","            xml_files.write('   <segmented>0</segmented>\\n')\n","            for ob in objects:\n","                xml_files.write('   <object>\\n')\n","                xml_files.write(f'      <name>{ob[0]}</name>\\n')\n","                xml_files.write('      <pose>Unspecified</pose>\\n')\n","                xml_files.write(f'      <truncated>{ob[1]}</truncated>\\n')\n","                xml_files.write('      <difficult>0</difficult>\\n')\n","                xml_files.write('      <bndbox>\\n')\n","                xml_files.write(f'         <xmin>{int(ob[2])}</xmin>\\n')\n","                xml_files.write(f'         <ymin>{int(ob[3])}</ymin>\\n')\n","                xml_files.write(f'         <xmax>{int(ob[4])}</xmax>\\n')\n","                xml_files.write(f'         <ymax>{int(ob[5])}</ymax>\\n')\n","                xml_files.write('      </bndbox>\\n')\n","                xml_files.write('   </object>\\n')\n","            xml_files.write('</annotation>', )\n","        pass"]},{"cell_type":"markdown","metadata":{"id":"jiSB7IE63LIP"},"source":["## predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":9162,"status":"ok","timestamp":1732848190774,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"x_ltd1A35VHZ","outputId":"e6417230-6b8c-40bc-af84-8feba609c9c0"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-25-2d7cf8aa471e>:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.net.load_state_dict(torch.load(self.model_path, map_location=device))\n"]},{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/210411100054-SitiNurAini/logs_9:1/best_epoch_weights.pth model, and classes loaded.\n","Configurations:\n","----------------------------------------------------------------------\n","|                     keys |                                   values|\n","----------------------------------------------------------------------\n","|               model_path | /content/drive/MyDrive/210411100054-SitiNurAini/logs_9:1/best_epoch_weights.pth|\n","|             classes_path | /content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt|\n","|              input_shape |                               [512, 512]|\n","|                      phi |                                        s|\n","|               confidence |                                     0.01|\n","|                  nms_iou |                                      0.5|\n","|          letterbox_image |                                     True|\n","|                     cuda |                                    False|\n","----------------------------------------------------------------------\n","Input image filename: /content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/00001946_029.jpg\n","b'Cardiomegaly 0.02' 343 173 434 336\n","b'Nodule_Mass 0.01' 251 296 279 328\n","b'Pneumothorax 0.07' 232 78 432 185\n"]}],"source":["import time\n","from PIL import Image\n","\n","# from yolo import YOLO\n","\n","if __name__ == \"__main__\":\n","    yolo = YOLO()\n","\n","    crop  = False\n","    count = False\n","\n","    # Minta input untuk gambar\n","    img = input('Input image filename: ')\n","    try:\n","        image = Image.open(img)\n","    except:\n","        print('Open Error! Try again!')\n","    else:\n","        # Proses gambar\n","        r_image = yolo.detect_image(image, crop=crop, count=count)\n","        r_image.show()\n","        # Program akan berhenti setelah memproses gambar pertama\n"]},{"cell_type":"markdown","metadata":{"id":"BslofXeThe8x"},"source":["# **EVALUASI**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28620,"status":"ok","timestamp":1732800877948,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"iuBHTNwqN7aA","outputId":"0cc5e660-5812-4917-a6f6-8a9ba2d0b1c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Jumlah setiap kelas:\n","Cardiomegaly: 43\n","Nodule_Mass: 39\n","Pneumothorax: 33\n"]}],"source":["import os\n","import xml.etree.ElementTree as ET\n","from collections import defaultdict\n","\n","# Langkah 1: Baca isi file test.txt\n","test_file_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/ImageSets/Main/test_9:1.txt'\n","with open(test_file_path, 'r') as file:\n","    test_ids = file.read().splitlines()\n","\n","# Langkah 2: Tentukan path ke direktori XML\n","xml_dir_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/annotations/'\n","\n","# Dictionary untuk menyimpan jumlah setiap kelas\n","class_count = defaultdict(int)\n","\n","# Langkah 3: Iterasi melalui semua ID di test_ids\n","for image_id in test_ids:\n","    # Buat nama file XML yang sesuai dengan ID\n","    xml_file_name = f\"{image_id}.xml\"\n","    xml_file_path = os.path.join(xml_dir_path, xml_file_name)\n","\n","    # Cek apakah file XML ada\n","    if os.path.exists(xml_file_path):\n","        # Baca file XML\n","        tree = ET.parse(xml_file_path)\n","        root = tree.getroot()\n","\n","        # Ambil kelas objek\n","        object_name = root.find('object/name').text\n","\n","        # Hitung jumlah kelas\n","        class_count[object_name] += 1\n","\n","# Menampilkan jumlah setiap kelas\n","print(\"\\nJumlah setiap kelas:\")\n","for class_name, count in class_count.items():\n","    print(f\"{class_name}: {count}\")"]},{"cell_type":"markdown","metadata":{"id":"2ypwCFAhFqkO"},"source":["## **MODE 0 = 1-2**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25600,"status":"ok","timestamp":1732849298153,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"vhjRefcSFykK","outputId":"db0ed5fe-2fd4-4f8a-fe91-27c343ace530"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folder runs_9:1 telah dibuat di: /content/drive/MyDrive/210411100054-SitiNurAini/runs_9:1/2024_test_9:1_iou=0.5\n","Load model.\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-25-2d7cf8aa471e>:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.net.load_state_dict(torch.load(self.model_path, map_location=device))\n"]},{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/210411100054-SitiNurAini/logs_9:1/best_epoch_weights.pth model, and classes loaded.\n","Configurations:\n","----------------------------------------------------------------------\n","|                     keys |                                   values|\n","----------------------------------------------------------------------\n","|               model_path | /content/drive/MyDrive/210411100054-SitiNurAini/logs_9:1/best_epoch_weights.pth|\n","|             classes_path | /content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt|\n","|              input_shape |                               [512, 512]|\n","|                      phi |                                        s|\n","|               confidence |                                     0.01|\n","|                  nms_iou |                                      0.5|\n","|          letterbox_image |                                     True|\n","|                     cuda |                                    False|\n","----------------------------------------------------------------------\n","Load model done.\n","Get predict result.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 115/115 [00:23<00:00,  4.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Get predict result | MODE 1 done.\n","Get ground truth result.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 115/115 [00:01<00:00, 94.33it/s]"]},{"name":"stdout","output_type":"stream","text":["Get ground truth result | MODE 2 done.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import datetime\n","import os\n","import xml.etree.ElementTree as ET\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","if __name__ == \"__main__\":\n","\n","    map_mode = 0\n","\n","    classes_path = '/content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt'\n","\n","    MINOVERLAP = 0.5\n","\n","    confidence = 0.01\n","\n","    nms_iou = 0.5\n","\n","    map_vis = True\n","\n","    base_output_dir = '/content/drive/MyDrive/210411100054-SitiNurAini/'\n","\n","    VOCdevkit_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3'\n","    txtNmae = \"test_9:1\"\n","\n","    map_out_path = os.path.join(base_output_dir, f'runs_9:1/2024_{txtNmae}_iou={MINOVERLAP}')\n","\n","    image_ids = open(\n","        os.path.join(VOCdevkit_path, \"ImageSets/Main/%s.txt\") % txtNmae).read().strip().split()\n","\n","    if not os.path.exists(map_out_path):\n","        os.makedirs(map_out_path)\n","    print(\"Folder runs_9:1 telah dibuat di:\", map_out_path)\n","\n","    if not os.path.exists(os.path.join(map_out_path, 'ground-truth')):\n","        os.makedirs(os.path.join(map_out_path, 'ground-truth'))\n","    if not os.path.exists(os.path.join(map_out_path, 'detection-results')):\n","        os.makedirs(os.path.join(map_out_path, 'detection-results'))\n","    if not os.path.exists(os.path.join(map_out_path, 'images-optional')):\n","        os.makedirs(os.path.join(map_out_path, 'images-optional'))\n","    if not os.path.exists(os.path.join(map_out_path, 'xmls')):\n","        os.makedirs(os.path.join(map_out_path, 'xmls'))\n","    class_names, _ = get_classes(classes_path)\n","\n","    if map_mode == 0 or map_mode == 1:\n","        print(\"Load model.\")\n","        yolo = YOLO(confidence=confidence, nms_iou=nms_iou)\n","        print(\"Load model done.\")\n","\n","        print(\"Get predict result.\")\n","        for image_id in tqdm(image_ids):\n","            image_path = os.path.join(VOCdevkit_path, \"JPGImages/\" + image_id + \".jpg\")\n","            image = Image.open(image_path)\n","            if map_vis:\n","                image.save(os.path.join(map_out_path, \"images-optional/\" + image_id + \".jpg\"))\n","            yolo.get_map_txt(image_id, image, class_names, map_out_path)\n","        print(\"Get predict result | MODE 1 done.\")\n","\n","    if map_mode == 0 or map_mode == 2:\n","        print(\"Get ground truth result.\")\n","        for image_id in tqdm(image_ids):\n","            with open(os.path.join(map_out_path, \"ground-truth/\" + image_id + \".txt\"), \"w\") as new_f:\n","                root = ET.parse(\n","                    os.path.join(VOCdevkit_path, \"annotations/\" + image_id + \".xml\")).getroot()\n","                for obj in root.findall('object'):\n","                    difficult_flag = False\n","                    if obj.find('difficult') != None:\n","                        difficult = obj.find('difficult').text\n","                        if int(difficult) == 1:\n","                            difficult_flag = True\n","                    obj_name = obj.find('name').text\n","                    if obj_name not in class_names:\n","                        continue\n","                    bndbox = obj.find('bndbox')\n","                    left = bndbox.find('xmin').text\n","                    top = bndbox.find('ymin').text\n","                    right = bndbox.find('xmax').text\n","                    bottom = bndbox.find('ymax').text\n","\n","                    if difficult_flag:\n","                        new_f.write(\"%s %s %s %s %s difficult\\n\" % (obj_name, left, top, right, bottom))\n","                    else:\n","                        new_f.write(\"%s %s %s %s %s\\n\" % (obj_name, left, top, right, bottom))\n","        print(\"Get ground truth result | MODE 2 done.\")\n","\n","    if map_mode == 3:\n","        print(\"Get map.\")\n","        get_map(MINOVERLAP, False, path=map_out_path)\n","        print(\"Get map done | MODE 3.\")\n","\n","    if map_mode == 4:\n","        print(\"Get map.\")\n","        get_coco_map(class_names=class_names, path=map_out_path)\n","        print(\"Get map | MODE 4 done.\")"]},{"cell_type":"markdown","metadata":{"id":"pLl32T87ISkF"},"source":["1. hijau = TP\n","2. merah = FP\n","3. biru = GT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wqOuiPJ6U7RZ"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n"]},{"cell_type":"markdown","metadata":{"id":"DZnGEFUE6X0o"},"source":["## **MODE 3**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1nt6QazJgTeUXQEBBvg83gPR9Hitwpnqq"},"id":"S0ej9QI0CpET","outputId":"ad92f407-38d9-4636-ad9c-68ad0fb4d6b3"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import datetime\n","import os\n","import xml.etree.ElementTree as ET\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","if __name__ == \"__main__\":\n","\n","    map_mode = 3\n","\n","    classes_path = '/content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt'\n","\n","    MINOVERLAP = 0.5\n","\n","    confidence = 0.01\n","\n","    nms_iou = 0.5\n","\n","    map_vis = True\n","\n","    base_output_dir = '/content/drive/MyDrive/210411100054-SitiNurAini/'\n","\n","    VOCdevkit_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3'\n","    txtNmae = \"test_9:1\"\n","\n","    map_out_path = os.path.join(base_output_dir, f'runs_9:1/2024_{txtNmae}_iou={MINOVERLAP}')\n","\n","    image_ids = open(\n","        os.path.join(VOCdevkit_path, \"ImageSets/Main/%s.txt\") % txtNmae).read().strip().split()\n","\n","    if not os.path.exists(map_out_path):\n","        os.makedirs(map_out_path)\n","    print(\"Folder runs_9:1 telah dibuat di:\", map_out_path)\n","\n","    if not os.path.exists(os.path.join(map_out_path, 'ground-truth')):\n","        os.makedirs(os.path.join(map_out_path, 'ground-truth'))\n","    if not os.path.exists(os.path.join(map_out_path, 'detection-results')):\n","        os.makedirs(os.path.join(map_out_path, 'detection-results'))\n","    if not os.path.exists(os.path.join(map_out_path, 'images-optional')):\n","        os.makedirs(os.path.join(map_out_path, 'images-optional'))\n","    if not os.path.exists(os.path.join(map_out_path, 'xmls')):\n","        os.makedirs(os.path.join(map_out_path, 'xmls'))\n","    class_names, _ = get_classes(classes_path)\n","\n","    if map_mode == 0 or map_mode == 1:\n","        print(\"Load model.\")\n","        yolo = YOLO(confidence=confidence, nms_iou=nms_iou)\n","        print(\"Load model done.\")\n","\n","        print(\"Get predict result.\")\n","        for image_id in tqdm(image_ids):\n","            image_path = os.path.join(VOCdevkit_path, \"JPGImages/\" + image_id + \".jpg\")\n","            image = Image.open(image_path)\n","            if map_vis:\n","                image.save(os.path.join(map_out_path, \"images-optional/\" + image_id + \".jpg\"))\n","            yolo.get_map_txt(image_id, image, class_names, map_out_path)\n","        print(\"Get predict result | MODE 1 done.\")\n","\n","    if map_mode == 0 or map_mode == 2:\n","        print(\"Get ground truth result.\")\n","        for image_id in tqdm(image_ids):\n","            with open(os.path.join(map_out_path, \"ground-truth/\" + image_id + \".txt\"), \"w\") as new_f:\n","                root = ET.parse(\n","                    os.path.join(VOCdevkit_path, \"annotations/\" + image_id + \".xml\")).getroot()\n","                for obj in root.findall('object'):\n","                    difficult_flag = False\n","                    if obj.find('difficult') != None:\n","                        difficult = obj.find('difficult').text\n","                        if int(difficult) == 1:\n","                            difficult_flag = True\n","                    obj_name = obj.find('name').text\n","                    if obj_name not in class_names:\n","                        continue\n","                    bndbox = obj.find('bndbox')\n","                    left = bndbox.find('xmin').text\n","                    top = bndbox.find('ymin').text\n","                    right = bndbox.find('xmax').text\n","                    bottom = bndbox.find('ymax').text\n","\n","                    if difficult_flag:\n","                        new_f.write(\"%s %s %s %s %s difficult\\n\" % (obj_name, left, top, right, bottom))\n","                    else:\n","                        new_f.write(\"%s %s %s %s %s\\n\" % (obj_name, left, top, right, bottom))\n","        print(\"Get ground truth result | MODE 2 done.\")\n","\n","    if map_mode == 3:\n","        print(\"Get map.\")\n","        get_map(MINOVERLAP, False, path=map_out_path)\n","        print(\"Get map done | MODE 3.\")\n","\n","    if map_mode == 4:\n","        print(\"Get map.\")\n","        get_coco_map(class_names=class_names, path=map_out_path)\n","        print(\"Get map | MODE 4 done.\")"]},{"cell_type":"markdown","metadata":{"id":"QueBGbbI5eEz"},"source":["## **MODE 4**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Bjr8nD15j7n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732856487618,"user_tz":-420,"elapsed":1360,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"}},"outputId":"ced20c00-40f2-49fc-8527-252820fafba9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Folder runs_9:1 telah dibuat di: /content/drive/MyDrive/210411100054-SitiNurAini/runs_9:1/2024_test_9:1_iou=0.5\n","Get map.\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.10s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.231\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n","\n","mAP untuk IoU=0.50: 23.12%\n","mAP untuk IoU=0.50:0.95: 9.43%\n","Get map | MODE 4 done.\n"]}],"source":["import datetime\n","import os\n","import xml.etree.ElementTree as ET\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","if __name__ == \"__main__\":\n","\n","    map_mode = 4\n","\n","    classes_path = '/content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt'\n","\n","    MINOVERLAP = 0.5\n","\n","    confidence = 0.01\n","\n","    nms_iou = 0.5\n","\n","    map_vis = True\n","\n","    base_output_dir = '/content/drive/MyDrive/210411100054-SitiNurAini/'\n","\n","    VOCdevkit_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3'\n","    txtNmae = \"test_9:1\"\n","\n","    map_out_path = os.path.join(base_output_dir, f'runs_9:1/2024_{txtNmae}_iou={MINOVERLAP}')\n","\n","    image_ids = open(\n","        os.path.join(VOCdevkit_path, \"ImageSets/Main/%s.txt\") % txtNmae).read().strip().split()\n","\n","    if not os.path.exists(map_out_path):\n","        os.makedirs(map_out_path)\n","    print(\"Folder runs_9:1 telah dibuat di:\", map_out_path)\n","\n","    if not os.path.exists(os.path.join(map_out_path, 'ground-truth')):\n","        os.makedirs(os.path.join(map_out_path, 'ground-truth'))\n","    if not os.path.exists(os.path.join(map_out_path, 'detection-results')):\n","        os.makedirs(os.path.join(map_out_path, 'detection-results'))\n","    if not os.path.exists(os.path.join(map_out_path, 'images-optional')):\n","        os.makedirs(os.path.join(map_out_path, 'images-optional'))\n","    if not os.path.exists(os.path.join(map_out_path, 'xmls')):\n","        os.makedirs(os.path.join(map_out_path, 'xmls'))\n","    class_names, _ = get_classes(classes_path)\n","\n","    if map_mode == 0 or map_mode == 1:\n","        print(\"Load model.\")\n","        yolo = YOLO(confidence=confidence, nms_iou=nms_iou)\n","        print(\"Load model done.\")\n","\n","        print(\"Get predict result.\")\n","        for image_id in tqdm(image_ids):\n","            image_path = os.path.join(VOCdevkit_path, \"JPGImages/\" + image_id + \".jpg\")\n","            image = Image.open(image_path)\n","            if map_vis:\n","                image.save(os.path.join(map_out_path, \"images-optional/\" + image_id + \".jpg\"))\n","            yolo.get_map_txt(image_id, image, class_names, map_out_path)\n","        print(\"Get predict result | MODE 1 done.\")\n","\n","    if map_mode == 0 or map_mode == 2:\n","        print(\"Get ground truth result.\")\n","        for image_id in tqdm(image_ids):\n","            with open(os.path.join(map_out_path, \"ground-truth/\" + image_id + \".txt\"), \"w\") as new_f:\n","                root = ET.parse(\n","                    os.path.join(VOCdevkit_path, \"annotations/\" + image_id + \".xml\")).getroot()\n","                for obj in root.findall('object'):\n","                    difficult_flag = False\n","                    if obj.find('difficult') != None:\n","                        difficult = obj.find('difficult').text\n","                        if int(difficult) == 1:\n","                            difficult_flag = True\n","                    obj_name = obj.find('name').text\n","                    if obj_name not in class_names:\n","                        continue\n","                    bndbox = obj.find('bndbox')\n","                    left = bndbox.find('xmin').text\n","                    top = bndbox.find('ymin').text\n","                    right = bndbox.find('xmax').text\n","                    bottom = bndbox.find('ymax').text\n","\n","                    if difficult_flag:\n","                        new_f.write(\"%s %s %s %s %s difficult\\n\" % (obj_name, left, top, right, bottom))\n","                    else:\n","                        new_f.write(\"%s %s %s %s %s\\n\" % (obj_name, left, top, right, bottom))\n","        print(\"Get ground truth result | MODE 2 done.\")\n","\n","    if map_mode == 3:\n","        print(\"Get map.\")\n","        get_map(MINOVERLAP, False, path=map_out_path)\n","        print(\"Get map done | MODE 3.\")\n","\n","    if map_mode == 4:\n","        print(\"Get map.\")\n","        get_coco_map(class_names=class_names, path=map_out_path)\n","        print(\"Get map | MODE 4 done.\")"]}],"metadata":{"colab":{"machine_shape":"hm","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}