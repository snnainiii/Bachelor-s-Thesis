{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32675,"status":"ok","timestamp":1732672936626,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"yAkDTa9f6upj","outputId":"1d600308-2fcd-49f7-f025-cc058ba11832"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"zkqF9i3sglUS"},"source":["# **2. DATASET PROCESSING**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Bc42G1pMinll","executionInfo":{"status":"ok","timestamp":1732671038988,"user_tz":-420,"elapsed":348,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"}}},"outputs":[],"source":["import os\n","os.makedirs('/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/ImageSets/Main', exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"EX2NNchc18yW"},"source":["## **MODE 0 [9:1]**\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2566,"status":"ok","timestamp":1732673936794,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"jaYNEcYAhqy8","outputId":"5950371b-f938-4096-cdf9-f5185726d9f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generate txt in ImageSets.\n","train and val size 1027\n","train size 924\n","Generate txt in ImageSets done.\n","Generate 2024_train_9:1.txt and 2024_val_9:1.txt for train.\n","Generate 2024_train_9:1.txt and 2024_val_9:1.txt for train done.\n","| Cardiomegaly | 357 | \n","|  Nodule_Mass | 360 | \n","| Pneumothorax | 336 | \n"]}],"source":["import os\n","import random\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","\n","# Define get_classes function if utils module is missing\n","def get_classes(classes_path):\n","    with open(classes_path, 'r') as f:\n","        classes = [line.strip() for line in f.readlines()]\n","    return classes, len(classes)\n","\n","annotation_mode     = 0\n","classes_path        = '/content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt'\n","trainval_percent    = 0.9\n","train_percent       = 0.9\n","CXR_AL3_path        = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3'\n","\n","CXR_AL3_sets        = [('2024', 'train'), ('2024', 'val')]\n","classes, _          = get_classes(classes_path)\n","\n","photo_nums  = np.zeros(len(CXR_AL3_sets))\n","nums        = np.zeros(len(classes))\n","\n","# Fungsi untuk mengonversi anotasi\n","def convert_annotation(year, image_id, list_file):\n","    in_file = open(os.path.join(CXR_AL3_path, 'annotations', f'{image_id}.xml'), encoding='utf-8')\n","    tree = ET.parse(in_file)\n","    root = tree.getroot()\n","\n","    for obj in root.iter('object'):\n","        difficult = 0\n","        if obj.find('difficult') is not None:\n","            difficult = obj.find('difficult').text\n","        cls = obj.find('name').text\n","        if cls not in classes or int(difficult) == 1:\n","            continue\n","        cls_id = classes.index(cls)\n","        xmlbox = obj.find('bndbox')\n","        b = (int(float(xmlbox.find('xmin').text)), int(float(xmlbox.find('ymin').text)),\n","             int(float(xmlbox.find('xmax').text)), int(float(xmlbox.find('ymax').text)))\n","        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n","\n","        nums[classes.index(cls)] += 1\n","\n","if __name__ == \"__main__\":\n","    random.seed(0)\n","\n","    if annotation_mode == 0 or annotation_mode == 1:\n","        print(\"Generate txt in ImageSets.\")\n","        xmlfilepath = os.path.join(CXR_AL3_path, 'annotations')\n","        saveBasePath = os.path.join(CXR_AL3_path, 'ImageSets/Main')\n","        total_xml = [xml for xml in os.listdir(xmlfilepath) if xml.endswith(\".xml\")]\n","\n","        num = len(total_xml)\n","        list_indices = range(num)\n","        tv = int(num * trainval_percent)\n","        tr = int(tv * train_percent)\n","        trainval = random.sample(list_indices, tv)\n","        train = random.sample(trainval, tr)\n","\n","        print(\"train and val size\", tv)\n","        print(\"train size\", tr)\n","        ftrainval = open(os.path.join(saveBasePath, 'trainval_9:1.txt'), 'w')\n","        ftest = open(os.path.join(saveBasePath, 'test_9:1.txt'), 'w')\n","        ftrain = open(os.path.join(saveBasePath, 'train_9:1.txt'), 'w')\n","        fval = open(os.path.join(saveBasePath, 'val_9:1.txt'), 'w')\n","\n","        for i in list_indices:\n","            name = total_xml[i][:-4] + '\\n'\n","            if i in trainval:\n","                ftrainval.write(name)\n","                if i in train:\n","                    ftrain.write(name)\n","                else:\n","                    fval.write(name)\n","            else:\n","                ftest.write(name)\n","\n","        ftrainval.close()\n","        ftrain.close()\n","        fval.close()\n","        ftest.close()\n","        print(\"Generate txt in ImageSets done.\")\n","\n","\n","    if annotation_mode == 0 or annotation_mode == 2:\n","        print(\"Generate 2024_train_9:1.txt and 2024_val_9:1.txt for train.\")\n","        saveBasePath = os.path.join(CXR_AL3_path, 'ImageSets/Main')\n","\n","        type_index = 0\n","        for year, image_set in CXR_AL3_sets:\n","            input_file_path = os.path.join(saveBasePath, f'{image_set}_9:1.txt')\n","            image_ids = open(input_file_path, encoding='utf-8').read().strip().split()\n","\n","            output_file_path = os.path.join(saveBasePath, f'{year}_{image_set}_9:1.txt')\n","            list_file = open(output_file_path, 'w', encoding='utf-8')\n","\n","            for image_id in image_ids:\n","                list_file.write(f'{os.path.abspath(CXR_AL3_path)}/JPGImages/{image_id}.jpg')\n","                convert_annotation(year, image_id, list_file)\n","                list_file.write('\\n')\n","\n","            photo_nums[type_index] = len(image_ids)\n","            type_index += 1\n","            list_file.close()\n","\n","        print(\"Generate 2024_train_9:1.txt and 2024_val_9:1.txt for train done.\")\n","\n","        def printTable(List1, List2):\n","            for i in range(len(List1[0])):\n","                print(\"|\", end=' ')\n","                for j in range(len(List1)):\n","                    print(List1[j][i].rjust(int(List2[j])), end=' ')\n","                    print(\"|\", end=' ')\n","                print()\n","\n","        str_nums = [str(int(x)) for x in nums]\n","        tableData = [\n","            classes, str_nums\n","        ]\n","        colWidths = [max(len(item) for item in col) for col in tableData]\n","        printTable(tableData, colWidths)\n"]},{"cell_type":"markdown","source":["menampilkan isi train.txt dan val.txt [9:1]"],"metadata":{"id":"ipJyKo1AbjnK"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":438,"status":"ok","timestamp":1732674159772,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"VVxPWPQSVMIQ","outputId":"52bfa0bc-f57b-4886-8849-1b45cad20799"},"outputs":[{"output_type":"stream","name":"stdout","text":["Isi file 2024_train_9:1.txt:\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/d4a67043b09bca469a46c16b763c0391.jpg 168,235,412,304,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/f6349590bcca0313c865a6658b41cde4.jpg 182,292,442,392,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/1ed4cf45940bbfbcdc31cf4289c1c1e4.jpg 155,261,360,320,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/5f4eff3b76151906fe87be784d191a1f.jpg 154,282,358,322,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/281070333d103fe4a02065d7f986b062.jpg 184,276,439,338,0\n","Isi file 2024_val_9:1.txt:\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/221d68705e17ec11935e410fcc483b0f.jpg 130,209,452,334,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/cdeda235172891a9886537799cd57d76.jpg 186,284,420,371,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/2dd5e1ec060f1389e24a4caffa6d534e.jpg 434,350,440,356,1\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/8be5bfabd547e1ef91f0b0b7b4d597d4.jpg 360,107,370,116,1\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/b7e9e8a42a7581a9f40b67f4ed3bab72.jpg 300,137,359,228,1\n"]}],"source":["# Fungsi untuk membaca dan menampilkan isi file\n","def display_file_content(file_path, label, max_lines=5):\n","    try:\n","        with open(file_path, 'r') as file:\n","            print(f\"Isi file {label}:\")\n","            print(''.join(file.readlines()[:max_lines]).strip())  # Gabung semua baris yang dipilih\n","    except FileNotFoundError:\n","        print(f\"File {label} tidak ditemukan.\")\n","    except Exception as e:\n","        print(f\"Error pada file {label}: {e}\")\n","\n","# Base path untuk file\n","base_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/ImageSets/Main'\n","\n","# Membaca dan menampilkan file\n","for label in ['2024_train_9:1.txt', '2024_val_9:1.txt']:\n","    display_file_content(f\"{base_path}/{label}\", label)\n"]},{"cell_type":"markdown","metadata":{"id":"bnS7PoZtivFS"},"source":["##**MODE 0 [8:2]**\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2483,"status":"ok","timestamp":1732673943697,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"},"user_tz":-420},"id":"5HhxxHmTitX5","outputId":"21a9ca06-1091-408c-cd2d-9041a7bd68f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generate txt in ImageSets.\n","train and val size 913\n","train size 821\n","Generate txt in ImageSets done.\n","Generate 2024_train_8:2.txt and 2024_val_8:2.txt for train.\n","Generate 2024_train_8:2.txt and 2024_val_8:2.txt for train done.\n","| Cardiomegaly | 325 | \n","|  Nodule_Mass | 311 | \n","| Pneumothorax | 298 | \n"]}],"source":["import os\n","import random\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","\n","# Define get_classes function if utils module is missing\n","def get_classes(classes_path):\n","    with open(classes_path, 'r') as f:\n","        classes = [line.strip() for line in f.readlines()]\n","    return classes, len(classes)\n","\n","annotation_mode     = 0\n","classes_path        = '/content/drive/MyDrive/210411100054-SitiNurAini/model_data/cxr_classes.txt'\n","trainval_percent    = 0.8\n","train_percent       = 0.9\n","CXR_AL3_path        = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3'\n","\n","CXR_AL3_sets        = [('2024', 'train'), ('2024', 'val')]\n","classes, _          = get_classes(classes_path)\n","\n","photo_nums  = np.zeros(len(CXR_AL3_sets))\n","nums        = np.zeros(len(classes))\n","\n","# Fungsi untuk mengonversi anotasi\n","def convert_annotation(year, image_id, list_file):\n","    in_file = open(os.path.join(CXR_AL3_path, 'annotations', f'{image_id}.xml'), encoding='utf-8')\n","    tree = ET.parse(in_file)\n","    root = tree.getroot()\n","\n","    for obj in root.iter('object'):\n","        difficult = 0\n","        if obj.find('difficult') is not None:\n","            difficult = obj.find('difficult').text\n","        cls = obj.find('name').text\n","        if cls not in classes or int(difficult) == 1:\n","            continue\n","        cls_id = classes.index(cls)\n","        xmlbox = obj.find('bndbox')\n","        b = (int(float(xmlbox.find('xmin').text)), int(float(xmlbox.find('ymin').text)),\n","             int(float(xmlbox.find('xmax').text)), int(float(xmlbox.find('ymax').text)))\n","        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n","\n","        nums[classes.index(cls)] += 1\n","\n","if __name__ == \"__main__\":\n","    random.seed(0)\n","\n","    if annotation_mode == 0 or annotation_mode == 1:\n","        print(\"Generate txt in ImageSets.\")\n","        xmlfilepath = os.path.join(CXR_AL3_path, 'annotations')\n","        saveBasePath = os.path.join(CXR_AL3_path, 'ImageSets/Main')\n","        total_xml = [xml for xml in os.listdir(xmlfilepath) if xml.endswith(\".xml\")]\n","\n","        num = len(total_xml)\n","        list_indices = range(num)\n","        tv = int(num * trainval_percent)\n","        tr = int(tv * train_percent)\n","        trainval = random.sample(list_indices, tv)\n","        train = random.sample(trainval, tr)\n","\n","        print(\"train and val size\", tv)\n","        print(\"train size\", tr)\n","        ftrainval = open(os.path.join(saveBasePath, 'trainval_8:2.txt'), 'w')\n","        ftest = open(os.path.join(saveBasePath, 'test_8:2.txt'), 'w')\n","        ftrain = open(os.path.join(saveBasePath, 'train_8:2.txt'), 'w')\n","        fval = open(os.path.join(saveBasePath, 'val_8:2.txt'), 'w')\n","\n","        for i in list_indices:\n","            name = total_xml[i][:-4] + '\\n'\n","            if i in trainval:\n","                ftrainval.write(name)\n","                if i in train:\n","                    ftrain.write(name)\n","                else:\n","                    fval.write(name)\n","            else:\n","                ftest.write(name)\n","\n","        ftrainval.close()\n","        ftrain.close()\n","        fval.close()\n","        ftest.close()\n","        print(\"Generate txt in ImageSets done.\")\n","\n","\n","    if annotation_mode == 0 or annotation_mode == 2:\n","        print(\"Generate 2024_train_8:2.txt and 2024_val_8:2.txt for train.\")\n","        saveBasePath = os.path.join(CXR_AL3_path, 'ImageSets/Main')\n","\n","        type_index = 0\n","        for year, image_set in CXR_AL3_sets:\n","            input_file_path = os.path.join(saveBasePath, f'{image_set}_8:2.txt')\n","            image_ids = open(input_file_path, encoding='utf-8').read().strip().split()\n","\n","            output_file_path = os.path.join(saveBasePath, f'{year}_{image_set}_8:2.txt')\n","            list_file = open(output_file_path, 'w', encoding='utf-8')\n","\n","            for image_id in image_ids:\n","                list_file.write(f'{os.path.abspath(CXR_AL3_path)}/JPGImages/{image_id}.jpg')\n","                convert_annotation(year, image_id, list_file)\n","                list_file.write('\\n')\n","\n","            photo_nums[type_index] = len(image_ids)\n","            type_index += 1\n","            list_file.close()\n","\n","        print(\"Generate 2024_train_8:2.txt and 2024_val_8:2.txt for train done.\")\n","\n","        def printTable(List1, List2):\n","            for i in range(len(List1[0])):\n","                print(\"|\", end=' ')\n","                for j in range(len(List1)):\n","                    print(List1[j][i].rjust(int(List2[j])), end=' ')\n","                    print(\"|\", end=' ')\n","                print()\n","\n","        str_nums = [str(int(x)) for x in nums]\n","        tableData = [\n","            classes, str_nums\n","        ]\n","        colWidths = [max(len(item) for item in col) for col in tableData]\n","        printTable(tableData, colWidths)\n"]},{"cell_type":"markdown","metadata":{"id":"Khd53N_QUB9T"},"source":["menampilkan isi train.txt dan val.txt [8:2]"]},{"cell_type":"code","source":["# Fungsi untuk membaca dan menampilkan isi file\n","def display_file_content(file_path, label, max_lines=5):\n","    try:\n","        with open(file_path, 'r') as file:\n","            print(f\"Isi file {label}:\")\n","            print(''.join(file.readlines()[:max_lines]).strip())  # Gabung semua baris yang dipilih\n","    except FileNotFoundError:\n","        print(f\"File {label} tidak ditemukan.\")\n","    except Exception as e:\n","        print(f\"Error pada file {label}: {e}\")\n","\n","# Base path untuk file\n","base_path = '/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/ImageSets/Main'\n","\n","# Membaca dan menampilkan file\n","for label in ['2024_train_8:2.txt', '2024_val_8:2.txt']:\n","    display_file_content(f\"{base_path}/{label}\", label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFOQhqb3bJzp","executionInfo":{"status":"ok","timestamp":1732674181184,"user_tz":-420,"elapsed":3,"user":{"displayName":"Al Qunnah","userId":"06050257527007666949"}},"outputId":"33240806-94a3-40dd-a0d9-d83d77bd3b17"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Isi file 2024_train_8:2.txt:\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/d4a67043b09bca469a46c16b763c0391.jpg 168,235,412,304,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/f6349590bcca0313c865a6658b41cde4.jpg 182,292,442,392,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/1ed4cf45940bbfbcdc31cf4289c1c1e4.jpg 155,261,360,320,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/5f4eff3b76151906fe87be784d191a1f.jpg 154,282,358,322,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/281070333d103fe4a02065d7f986b062.jpg 184,276,439,338,0\n","Isi file 2024_val_8:2.txt:\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/5ccbe9cf1b033cccdd76fd99cc6ccd01.jpg 185,286,410,370,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/2e02414c9f4b2b23a7761fe8c2b3bc93.jpg 189,302,392,378,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/659c6031ed4b7d875e5e14662eb50bf2.jpg 198,274,408,366,0\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/f7b3fa818839a04913e45fa796203462.jpg 149,174,182,197,1\n","/content/drive/MyDrive/210411100054-SitiNurAini/DATASET-CXR-AL3/JPGImages/1d2c0ac10d4b141cda8b549c34848b4f.jpg 296,131,301,135,1\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"16PAfpY-JNBJJK76LmnBylMUzTEGoJ42M","timestamp":1732088344488}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}